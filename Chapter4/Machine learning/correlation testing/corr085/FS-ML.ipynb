{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe732f0-5622-4970-93bc-8d39d1036328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import sort\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.cluster import hierarchy\n",
    "import scipy.cluster\n",
    "from numpy import absolute, mean, sort, std\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import re\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "\n",
    "from sklearn import datasets, metrics, preprocessing, model_selection\n",
    "import sklearn.neighbors._base\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold,RepeatedKFold, cross_val_score, cross_validate, cross_val_predict, GridSearchCV, RandomizedSearchCV, validation_curve, learning_curve\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, mean_absolute_error, max_error\n",
    "\n",
    "import skopt\n",
    "from skopt import BayesSearchCV \n",
    "\n",
    "from missingpy import MissForest\n",
    "\n",
    "import shap\n",
    "from BorutaShap import BorutaShap\n",
    "\n",
    "import xgboost\n",
    "import lightgbm\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, VotingRegressor, StackingRegressor, BaggingRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "\n",
    "seed = 0\n",
    "\n",
    "data = pd.read_csv(\"training_cleaned.csv\", header=0, sep=\",\")\n",
    "\n",
    "data[\"BPlabel_encoded\"] = data[\"BPlabel\"].map(\n",
    "    {\"most likely\": 1, \"probable\": 0.75, \"least likely\": 0.1}\n",
    ")\n",
    "Y = data[\"BPlabel_encoded\"]\n",
    "data = data.drop([\"BPlabel\"], 1)\n",
    "\n",
    "\n",
    "xgbr = xgboost.XGBRegressor(random_state=seed, objective='reg:squarederror') \n",
    "xgbr_params = {\n",
    "    'max_depth':  (1, 4), \n",
    "    'learning_rate': (0.01, 0.2, 'log-uniform'),  \n",
    "    'n_estimators':  (10, 50), \n",
    "    'reg_alpha':  (1, 10, 'log-uniform'), \n",
    "    'reg_lambda':  (1, 10, 'log-uniform')} \n",
    "\n",
    "lgbm = LGBMRegressor(random_state=seed)\n",
    "lgbm_params = {\n",
    "    \"max_depth\": (1, 4),\n",
    "    \"learning_rate\": (0.01, 0.2, \"log-uniform\"),\n",
    "    \"n_estimators\": (10, 50),\n",
    "    \"reg_alpha\": (1, 10, \"log-uniform\"),\n",
    "    \"reg_lambda\": (1, 10, \"log-uniform\"),\n",
    "}\n",
    "\n",
    "catboost = CatBoostRegressor(random_seed=seed, verbose=False)\n",
    "cat_params = {\n",
    "     \"iterations\": (10, 50),\n",
    "     'learning_rate': (0.01, 0.2, 'log-uniform'), \n",
    "     'depth':  (1, 4), \n",
    "}\n",
    "\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=seed)\n",
    "gbr_params = {\n",
    "    'learning_rate': (0.01, 0.2),\n",
    "    'max_depth': (1, 4),\n",
    "    \"max_features\":[\"log2\",\"sqrt\", \"auto\"],\n",
    "    \"criterion\": [\"friedman_mse\", \"mse\", \"mae\"],\n",
    "    'n_estimators': (10, 50)\n",
    "    }\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=seed)\n",
    "rfr_params={'n_estimators': (10, 50), \n",
    "             'max_features': ['auto', 'sqrt', 'log2'],\n",
    "             'max_depth' : (1, 4),\n",
    "             'criterion' :['mse', 'mae']} \n",
    "\n",
    "dt = DecisionTreeRegressor(random_state=seed)\n",
    "dt_params= {\"criterion\": [\"mse\", \"mae\"],\n",
    "            'max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'max_depth' : (1, 4)}\n",
    "\n",
    "extra = ExtraTreesRegressor(random_state=seed)\n",
    "extra_params ={'n_estimators': (10, 50), \n",
    "             'max_features': ['auto', 'sqrt', 'log2'],\n",
    "             'max_depth' : (1, 4),\n",
    "             'criterion' :['mse', 'mae']}\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr_params = {\n",
    "    'n_neighbors':[7,9,11,13,15,17],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['euclidean','manhattan']}\n",
    "\n",
    "\n",
    "lasso = Lasso(random_state=seed)\n",
    "lasso_params =  {\"alpha\": (0.001, 0.01, 0.1),\n",
    "                \"max_iter\": (500, 1000, 5000),}\n",
    "\n",
    "elastic = ElasticNet(random_state=seed, tol=1)\n",
    "elastic_params = {\n",
    "    \"max_iter\": (500, 1000, 5000),\n",
    "    \"alpha\": (0.001, 0.01, 0.1),\n",
    "    \"l1_ratio\": np.arange(0.0, 1.0)}\n",
    "\n",
    "svr = SVR()\n",
    "svr_params = {\n",
    "    'kernel': ['rbf'],\n",
    "   'C': (1e0, 1e3),\n",
    "   'gamma': (1e-4, 1e-3)}\n",
    "\n",
    "inner_cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=seed)\n",
    "outer_cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=seed)\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append(('XGBR', BayesSearchCV(xgbr, xgbr_params, cv=inner_cv,iid=False,n_jobs=1, random_state=seed))) \n",
    "models.append((\"LGBM\", BayesSearchCV(lgbm, lgbm_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n",
    "models.append((\"CB\", BayesSearchCV(catboost, cat_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n",
    "models.append(('GBR', BayesSearchCV(gbr, gbr_params, cv=inner_cv,iid=False, n_jobs=1, random_state=seed)))\n",
    "models.append(('RFR', BayesSearchCV(rfr, rfr_params, cv=inner_cv,iid=False, n_jobs=1, random_state=seed)))\n",
    "models.append(('DT', BayesSearchCV(dt, dt_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n",
    "models.append(('ExtraTrees', BayesSearchCV(extra, extra_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n",
    "\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "medians =[]\n",
    "scoring = ['r2', 'neg_mean_squared_error', 'max_error', 'neg_mean_absolute_error',\n",
    "          'explained_variance','neg_root_mean_squared_error',\n",
    "           'neg_median_absolute_error'] \n",
    "\n",
    "models_list_r2 = []\n",
    "models_list_predr2 = []\n",
    "\n",
    "def press_statistic(Y, y_pred2, xs):\n",
    "    res = y_pred2 - Y\n",
    "    hat = xs.dot(np.linalg.pinv(xs))\n",
    "    den = 1 - np.diagonal(hat)\n",
    "    sqr = np.square(res / den)\n",
    "    return sqr.sum()\n",
    "\n",
    "\n",
    "def predicted_r2(Y, y_pred2, xs):\n",
    "    press = press_statistic(Y=Y, y_pred2=y_pred2, xs=xs)\n",
    "    sst = np.square(Y - Y.mean()).sum()\n",
    "    return 1 - press / sst\n",
    "\n",
    "\n",
    "def r2(Y, y_pred2):\n",
    "    sse = np.square(y_pred2 - Y).sum()\n",
    "    sst = np.square(Y - Y.mean()).sum()\n",
    "    return 1 - sse / sst\n",
    "\n",
    "\n",
    "\n",
    "X_boruta_sel = pd.read_csv(\"selected_features_training_data.csv\", header=0)\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "FSmodels_list_r2 = []\n",
    "FSmodels_list_predr2 = []\n",
    "\n",
    "X_boruta_sel.columns = [\n",
    "    regex.sub(\"_\", col) if any(x in str(col) for x in set((\"[\", \"]\", \"<\"))) else col\n",
    "    for col in X_boruta_sel.columns.values\n",
    "]\n",
    "\n",
    "X_train_boruta, X_test_boruta, Y_train_boruta, Y_test_boruta = train_test_split(\n",
    "    X_boruta_sel, Y, test_size=0.2, random_state=0\n",
    ")\n",
    "\n",
    "df3 = pd.DataFrame(data= X_boruta_sel, columns= X_boruta_sel.columns)\n",
    "df3.columns = [\n",
    "    regex.sub(\"_\", col) if any(x in str(col) for x in set((\"[\", \"]\", \"<\"))) else col\n",
    "    for col in  X_boruta_sel.columns.values\n",
    "]\n",
    "X_importance = X_test_boruta\n",
    "\n",
    "for name, model in models:\n",
    "    nested_cv_results = model_selection.cross_validate(model, X_boruta_sel, Y, cv=outer_cv, scoring=scoring)\n",
    "    nested_cv_results2 = model_selection.cross_val_score(model, X_boruta_sel, Y, cv=outer_cv, scoring='r2')\n",
    "    results.append(nested_cv_results2)\n",
    "    names.append(name)\n",
    "    print(name, 'Nested CV results for all scores:', '\\n', nested_cv_results, '\\n')\n",
    "    print(name, 'r2 Nested CV Median', np.median(nested_cv_results['test_r2']))\n",
    "    print(name, 'MSE Nested CV Median', np.median(nested_cv_results['test_neg_mean_squared_error'] ))\n",
    "    print(name, 'RMSE Nested CV Median', np.median(nested_cv_results['test_neg_root_mean_squared_error'] ))\n",
    "    print(name, 'Explained Variance Nested CV Median', np.median(nested_cv_results['test_explained_variance'] ))\n",
    "    print(name, 'MAE Nested CV Median', np.median(nested_cv_results['test_neg_mean_absolute_error'] ))\n",
    "    model.fit(X_boruta_sel, Y)\n",
    "    print('\\n')\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print(\"Best Estimator:\", model.best_estimator_)\n",
    "    best_model = model.best_estimator_\n",
    "    print('\\n')\n",
    "    print('Non-nested CV Results:')\n",
    "    best_model.fit(X_train_boruta, Y_train_boruta)\n",
    "    y_pred_train = best_model.predict(X_train_boruta)\n",
    "    y_pred = best_model.predict(X_test_boruta)\n",
    "    print(name, 'Train r2:', r2_score(Y_train_boruta, y_pred_train), 'Test r2:', r2_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train MSE:', mean_squared_error(Y_train_boruta, y_pred_train), 'Test MSE:', mean_squared_error(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train Explained Variance Score:', explained_variance_score(Y_train_boruta, y_pred_train), 'Test Explained Variance Score:', explained_variance_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train MAE:', mean_absolute_error(Y_train_boruta, y_pred_train),'Test MAE:', mean_absolute_error(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train Max Error:', max_error(Y_train_boruta, y_pred_train), 'Test Max Error:', max_error(Y_test_boruta, y_pred))\n",
    "    print('\\n')\n",
    "    best_model.fit(X_boruta_sel, Y)\n",
    "    y_pred2 = best_model.predict(X_boruta_sel)\n",
    "    print(name, \"Best model predicted r2:\", predicted_r2(Y, y_pred2, X_boruta_sel))\n",
    "    #explainer = shap.TreeExplainer(best_model)\n",
    "    #shap_values = explainer.shap_values(X_boruta_sel)\n",
    "    #X_importance = pd.DataFrame(data=X_boruta_sel, columns=df3.columns)\n",
    "    #print(name,'SELECTED FEATURES Ranked SHAP Importance:', X_boruta_sel.columns[np.argsort(np.abs(shap_values).mean(0))[::-1]])\n",
    "    #fig, ax = plt.subplots()\n",
    "    #shap.summary_plot(shap_values, X_boruta_sel)\n",
    "    #fig.savefig(\"shap_summary_selected_features\" + name +\".svg\", format='svg', dpi=1200, bbox_inches = \"tight\")\n",
    "    median_r2 = np.median(nested_cv_results['test_r2'])\n",
    "    FSmodels_list_r2.append((best_model,  median_r2))\n",
    "    predr2_score = predicted_r2(Y, y_pred2, X_boruta_sel)\n",
    "    FSmodels_list_predr2.append((best_model, predr2_score))\n",
    "    \n",
    "print('All r2 results:', results) \n",
    "\n",
    "results = []\n",
    "names = []\n",
    "othermodels = []\n",
    "\n",
    "othermodels.append(('KNR', BayesSearchCV(knr, knr_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n",
    "othermodels.append(('SVR', BayesSearchCV(svr, svr_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n",
    "othermodels.append(('Lasso', BayesSearchCV(lasso, lasso_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n",
    "othermodels.append(('ElasticNet', BayesSearchCV(elastic, elastic_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n",
    "\n",
    "X2_boruta_sel = MinMaxScaler().fit_transform(X_boruta_sel)\n",
    "X_train_boruta, X_test_boruta, Y_train_boruta, Y_test_boruta = train_test_split(\n",
    "    X2_boruta_sel, Y, test_size=0.2, random_state=seed)\n",
    "\n",
    "df3 = pd.DataFrame(data= X2_boruta_sel, columns= X_boruta_sel.columns)\n",
    "df3.columns = [\n",
    "    regex.sub(\"_\", col) if any(x in str(col) for x in set((\"[\", \"]\", \"<\"))) else col\n",
    "    for col in  X_boruta_sel.columns.values\n",
    "]\n",
    "X_importance = df3\n",
    "\n",
    "for name, model in othermodels:\n",
    "    nested_cv_results = model_selection.cross_validate(model, X2_boruta_sel, Y, cv=outer_cv, scoring=scoring, return_estimator=True, return_train_score=True)\n",
    "    nested_cv_results2 = model_selection.cross_val_score(model, X2_boruta_sel, Y, cv=outer_cv, scoring='r2')\n",
    "    results.append(nested_cv_results2)\n",
    "    names.append(name)\n",
    "    print('\\n')\n",
    "    print(name, 'Nested CV results for all scores:', '\\n', nested_cv_results, '\\n')\n",
    "    print(name, 'r2 Nested CV Median', np.median(nested_cv_results['test_r2']))\n",
    "    print(name, 'MSE Nested CV Median', np.median(nested_cv_results['test_neg_mean_squared_error'] ))\n",
    "    print(name, 'RMSE Nested CV Median', np.median(nested_cv_results['test_neg_root_mean_squared_error'] ))\n",
    "    print(name, 'Explained Variance Nested CV Median', np.median(nested_cv_results['test_explained_variance'] ))\n",
    "    print(name, 'MAE Nested CV Median', np.median(nested_cv_results['test_neg_mean_absolute_error'] ))\n",
    "    model.fit(X2_boruta_sel, Y)\n",
    "    print('\\n')\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print(\"Best Estimator:\", model.best_estimator_)\n",
    "    print('\\n')\n",
    "    best_model = model.best_estimator_\n",
    "    best_model.fit(X_train_boruta, Y_train_boruta)\n",
    "    print('Non-nested CV Results:')\n",
    "    y_pred_train = best_model.predict(X_train_boruta)\n",
    "    y_pred = best_model.predict(X_test_boruta)\n",
    "    print(name, 'Train r2:', r2_score(Y_train_boruta, y_pred_train), 'Test r2:', r2_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train MSE:', mean_squared_error(Y_train_boruta, y_pred_train), 'Test MSE:', mean_squared_error(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train Explained Variance Score:', explained_variance_score(Y_train_boruta, y_pred_train), 'Test Explained Variance Score:', explained_variance_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train MAE:', mean_absolute_error(Y_train_boruta, y_pred_train),'Test MAE:', mean_absolute_error(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train Max Error:', max_error(Y_train_boruta, y_pred_train), 'Test Max Error:', max_error(Y_test_boruta, y_pred))\n",
    "    print('\\n')\n",
    "    best_model.fit(X2_boruta_sel, Y)\n",
    "    y_pred2 = best_model.predict(X2_boruta_sel)\n",
    "    print(name, \"Best model predicted r2:\", predicted_r2(Y, y_pred2, X2_boruta_sel))\n",
    "    print('\\n')\n",
    "    #explainer = shap.KernelExplainer(best_model.predict, X_importance)\n",
    "    #shap_values = explainer.shap_values(X_importance)\n",
    "    #X_importance = pd.DataFrame(data=X_importance, columns=X_importance.columns)\n",
    "    #print(name,'SELECTED FEATURES Ranked SHAP Importance:', X_importance.columns[np.argsort(np.abs(shap_values).mean(0))[::-1]])\n",
    "    #fig, ax = plt.subplots()\n",
    "    #shap.summary_plot(shap_values, X_importance)\n",
    "    #fig.savefig(\"shap_summary_selected_features\" + name +\".svg\", format='svg', dpi=1200, bbox_inches = \"tight\")\n",
    "    median_r2 = np.median(nested_cv_results['test_r2'])\n",
    "    FSmodels_list_r2.append((best_model,  median_r2))\n",
    "    predr2_score = predicted_r2(Y, y_pred2, X2_boruta_sel)\n",
    "    FSmodels_list_predr2.append((best_model, predr2_score))\n",
    "\n",
    "print('All r2 results:', results)   \n",
    "\n",
    "best_FSmodel1, best_r2 = sorted(FSmodels_list_r2, key = lambda x: x[1], reverse=True)[0]\n",
    "best_FSmodel2, best_predr2 = sorted(FSmodels_list_predr2, key = lambda x: x[1], reverse=True)[0]\n",
    "print('Best model by median r2:',best_FSmodel1)\n",
    "print('Best model by predicted r2:',best_FSmodel2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256306c6-c8f4-4f5c-a2cf-f806c05e9107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
