{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fe732f0-5622-4970-93bc-8d39d1036328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBR Nested CV results for all scores: \n",
      " {'fit_time': array([ 64.09959602,  80.27769113,  86.63337898, 117.2380743 ,\n",
      "        91.80442595,  81.93441939,  66.99367499,  60.54786611,\n",
      "        57.11083412, 100.68427515, 115.41682816, 117.16283917,\n",
      "       133.75809312, 125.29867768, 118.33899188]), 'score_time': array([0.00276399, 0.00412703, 0.00341988, 0.00293183, 0.00355029,\n",
      "       0.00427079, 0.00275612, 0.00274682, 0.00321388, 0.00362992,\n",
      "       0.00376701, 0.00367093, 0.00352287, 0.00417519, 0.00369406]), 'test_r2': array([0.69580531, 0.56248189, 0.67688021, 0.74777011, 0.78461065,\n",
      "       0.67849521, 0.72231293, 0.77748539, 0.63068658, 0.84831107,\n",
      "       0.70086271, 0.64835297, 0.77904538, 0.71474875, 0.68326683]), 'test_neg_mean_squared_error': array([-0.03476261, -0.04721764, -0.03946638, -0.02740582, -0.02699874,\n",
      "       -0.03940212, -0.02925885, -0.024553  , -0.04338884, -0.02011141,\n",
      "       -0.03654184, -0.04073236, -0.02304694, -0.03528331, -0.03928753]), 'test_max_error': array([-0.55828747, -0.76696655, -0.62315342, -0.5953531 , -0.47047951,\n",
      "       -0.69509163, -0.56291883, -0.37760552, -0.70119622, -0.41403848,\n",
      "       -0.65334209, -0.60872953, -0.38036114, -0.53965099, -0.65579453]), 'test_neg_mean_absolute_error': array([-0.12522521, -0.15569618, -0.1401759 , -0.11460036, -0.1264722 ,\n",
      "       -0.13564483, -0.12577406, -0.11647702, -0.14303267, -0.10863257,\n",
      "       -0.13853709, -0.14592282, -0.11348763, -0.13169947, -0.1395861 ]), 'test_explained_variance': array([0.70865798, 0.58260343, 0.67892696, 0.76716675, 0.78998462,\n",
      "       0.6810141 , 0.72425232, 0.7780635 , 0.6364027 , 0.85190367,\n",
      "       0.70297229, 0.64971309, 0.78561709, 0.74253687, 0.68361657]), 'test_neg_root_mean_squared_error': array([-0.18644734, -0.21729621, -0.19866146, -0.16554703, -0.16431294,\n",
      "       -0.19849966, -0.17105219, -0.15669395, -0.20829987, -0.1418147 ,\n",
      "       -0.1911592 , -0.2018226 , -0.1518122 , -0.18783851, -0.19821082]), 'test_neg_median_absolute_error': array([-0.07802862, -0.115857  , -0.08870811, -0.07353908, -0.11871884,\n",
      "       -0.11192435, -0.10036051, -0.08230615, -0.08330321, -0.07513577,\n",
      "       -0.11416662, -0.09536213, -0.08830446, -0.0758087 , -0.08489522])} \n",
      "\n",
      "XGBR r2 Nested CV Median 0.7008627149616639\n",
      "XGBR MSE Nested CV Median -0.03528330706673053\n",
      "XGBR RMSE Nested CV Median -0.18783851326799447\n",
      "XGBR Explained Variance Nested CV Median 0.7086579801700916\n",
      "XGBR MAE Nested CV Median -0.1316994666282473\n",
      "\n",
      "\n",
      "Best Parameters: \n",
      "OrderedDict([('learning_rate', 0.1434824816690979), ('max_depth', 4), ('n_estimators', 48), ('reg_alpha', 1), ('reg_lambda', 10)])\n",
      "\n",
      "Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.1434824816690979, max_delta_step=0, max_depth=4,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=48, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=1, reg_lambda=10, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "\n",
      "\n",
      "Non-nested CV Results:\n",
      "XGBR Train r2: 0.9038109752712135 Test r2: 0.6991482679580217\n",
      "XGBR Train MSE: 0.01147473879688043 Test MSE: 0.034380585753030456\n",
      "XGBR Train Explained Variance Score: 0.9039427426723515 Test Explained Variance Score: 0.7128799625575343\n",
      "XGBR Train MAE: 0.07655371856740396 Test MAE: 0.12616249560299567\n",
      "XGBR Train Max Error: 0.4617172718048096 Test Max Error: 0.5484757661819458\n",
      "\n",
      "\n",
      "XGBR Best model predicted r2: -0.968153917157131\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-404e6094a7d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mnested_cv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_boruta_sel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mouter_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mnested_cv_results2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_boruta_sel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mouter_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_cv_results2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    402\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 242\u001b[0;31m     scores = parallel(\n\u001b[0m\u001b[1;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, callback)\u001b[0m\n\u001b[1;32m    690\u001b[0m                 \u001b[0mn_points_adjusted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                 optim_result = self._step(\n\u001b[0m\u001b[1;32m    693\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                     \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_points_adjusted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, X, y, search_space, optimizer, groups, n_points)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# get parameter values to evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;31m# convert parameters to python native types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/skopt/optimizer/optimizer.py\u001b[0m in \u001b[0;36mask\u001b[0;34m(self, n_points, strategy)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;31m# deletion of points with \"lie\" objective (the copy of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;31m# oiptimizer is simply discarded)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         opt = self.copy(random_state=self.rng.randint(0,\n\u001b[0m\u001b[1;32m    391\u001b[0m                                                       np.iinfo(np.int32).max))\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/skopt/optimizer/optimizer.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, random_state)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgains_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgains_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/skopt/optimizer/optimizer.py\u001b[0m in \u001b[0;36m_tell\u001b[0;34m(self, x, y, fit)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;31m# even with BFGS as optimizer we want to sample a large number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;31m# of points and then pick the best ones as starting points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m             X = self.space.transform(self.space.rvs(\n\u001b[0m\u001b[1;32m    553\u001b[0m                 n_samples=self.n_points, random_state=self.rng))\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/skopt/space/space.py\u001b[0m in \u001b[0;36mrvs\u001b[0;34m(self, n_samples, random_state)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;31m# Transpose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_transpose_list_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/skopt/space/space.py\u001b[0m in \u001b[0;36m_transpose_list_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import sort\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.cluster import hierarchy\n",
    "import scipy.cluster\n",
    "from numpy import absolute, mean, sort, std\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import re\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "\n",
    "from sklearn import datasets, metrics, preprocessing, model_selection\n",
    "import sklearn.neighbors._base\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold,RepeatedKFold, cross_val_score, cross_validate, cross_val_predict, GridSearchCV, RandomizedSearchCV, validation_curve, learning_curve\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, mean_absolute_error, max_error\n",
    "\n",
    "import skopt\n",
    "from skopt import BayesSearchCV \n",
    "\n",
    "from missingpy import MissForest\n",
    "\n",
    "import shap\n",
    "from BorutaShap import BorutaShap\n",
    "\n",
    "import xgboost\n",
    "import lightgbm\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, VotingRegressor, StackingRegressor, BaggingRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "\n",
    "seed = 0\n",
    "\n",
    "data = pd.read_csv(\"training_cleaned.csv\", header=0, sep=\",\")\n",
    "\n",
    "data[\"BPlabel_encoded\"] = data[\"BPlabel\"].map(\n",
    "    {\"most likely\": 1, \"probable\": 0.75, \"least likely\": 0.1}\n",
    ")\n",
    "Y = data[\"BPlabel_encoded\"]\n",
    "data = data.drop([\"BPlabel\"], 1)\n",
    "\n",
    "\n",
    "xgbr = xgboost.XGBRegressor(random_state=seed, objective='reg:squarederror') \n",
    "xgbr_params = {\n",
    "    'max_depth':  (1, 4), \n",
    "    'learning_rate': (0.01, 0.2, 'log-uniform'),  \n",
    "    'n_estimators':  (10, 50), \n",
    "    'reg_alpha':  (1, 10, 'log-uniform'), \n",
    "    'reg_lambda':  (1, 10, 'log-uniform')} \n",
    "\n",
    "lgbm = LGBMRegressor(random_state=seed)\n",
    "lgbm_params = {\n",
    "    \"max_depth\": (1, 4),\n",
    "    \"learning_rate\": (0.01, 0.2, \"log-uniform\"),\n",
    "    \"n_estimators\": (10, 50),\n",
    "    \"reg_alpha\": (1, 10, \"log-uniform\"),\n",
    "    \"reg_lambda\": (1, 10, \"log-uniform\"),\n",
    "}\n",
    "\n",
    "catboost = CatBoostRegressor(random_seed=seed, verbose=False)\n",
    "cat_params = {\n",
    "     \"iterations\": (10, 50),\n",
    "     'learning_rate': (0.01, 0.2, 'log-uniform'), \n",
    "     'depth':  (1, 4), \n",
    "}\n",
    "\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=seed)\n",
    "gbr_params = {\n",
    "    'learning_rate': (0.01, 0.2),\n",
    "    'max_depth': (1, 4),\n",
    "    \"max_features\":[\"log2\",\"sqrt\", \"auto\"],\n",
    "    \"criterion\": [\"friedman_mse\", \"mse\", \"mae\"],\n",
    "    'n_estimators': (10, 50)\n",
    "    }\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=seed)\n",
    "rfr_params={'n_estimators': (10, 50), \n",
    "             'max_features': ['auto', 'sqrt', 'log2'],\n",
    "             'max_depth' : (1, 4),\n",
    "             'criterion' :['mse', 'mae']} \n",
    "\n",
    "dt = DecisionTreeRegressor(random_state=seed)\n",
    "dt_params= {\"criterion\": [\"mse\", \"mae\"],\n",
    "            'max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'max_depth' : (1, 4)}\n",
    "\n",
    "extra = ExtraTreesRegressor(random_state=seed)\n",
    "extra_params ={'n_estimators': (10, 50), \n",
    "             'max_features': ['auto', 'sqrt', 'log2'],\n",
    "             'max_depth' : (1, 4),\n",
    "             'criterion' :['mse', 'mae']}\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr_params = {\n",
    "    'n_neighbors':[7,9,11,13,15,17],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['euclidean','manhattan']}\n",
    "\n",
    "\n",
    "lasso = Lasso(random_state=seed)\n",
    "lasso_params =  {\"alpha\": (0.001, 0.01, 0.1),\n",
    "                \"max_iter\": (500, 1000, 5000),}\n",
    "\n",
    "elastic = ElasticNet(random_state=seed, tol=1)\n",
    "elastic_params = {\n",
    "    \"max_iter\": (500, 1000, 5000),\n",
    "    \"alpha\": (0.001, 0.01, 0.1),\n",
    "    \"l1_ratio\": np.arange(0.0, 1.0)}\n",
    "\n",
    "svr = SVR()\n",
    "svr_params = {\n",
    "    'kernel': ['rbf'],\n",
    "   'C': (1e0, 1e3),\n",
    "   'gamma': (1e-4, 1e-3)}\n",
    "\n",
    "inner_cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=seed)\n",
    "outer_cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=seed)\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append(('XGBR', BayesSearchCV(xgbr, xgbr_params, cv=inner_cv,iid=False,n_jobs=1, random_state=seed))) \n",
    "models.append((\"LGBM\", BayesSearchCV(lgbm, lgbm_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n",
    "models.append((\"CB\", BayesSearchCV(catboost, cat_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n",
    "models.append(('GBR', BayesSearchCV(gbr, gbr_params, cv=inner_cv,iid=False, n_jobs=1, random_state=seed)))\n",
    "models.append(('RFR', BayesSearchCV(rfr, rfr_params, cv=inner_cv,iid=False, n_jobs=1, random_state=seed)))\n",
    "models.append(('DT', BayesSearchCV(dt, dt_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n",
    "models.append(('ExtraTrees', BayesSearchCV(extra, extra_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n",
    "\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "medians =[]\n",
    "scoring = ['r2', 'neg_mean_squared_error', 'max_error', 'neg_mean_absolute_error',\n",
    "          'explained_variance','neg_root_mean_squared_error',\n",
    "           'neg_median_absolute_error'] \n",
    "\n",
    "models_list_r2 = []\n",
    "models_list_predr2 = []\n",
    "\n",
    "def press_statistic(Y, y_pred2, xs):\n",
    "    res = y_pred2 - Y\n",
    "    hat = xs.dot(np.linalg.pinv(xs))\n",
    "    den = 1 - np.diagonal(hat)\n",
    "    sqr = np.square(res / den)\n",
    "    return sqr.sum()\n",
    "\n",
    "\n",
    "def predicted_r2(Y, y_pred2, xs):\n",
    "    press = press_statistic(Y=Y, y_pred2=y_pred2, xs=xs)\n",
    "    sst = np.square(Y - Y.mean()).sum()\n",
    "    return 1 - press / sst\n",
    "\n",
    "\n",
    "def r2(Y, y_pred2):\n",
    "    sse = np.square(y_pred2 - Y).sum()\n",
    "    sst = np.square(Y - Y.mean()).sum()\n",
    "    return 1 - sse / sst\n",
    "\n",
    "\n",
    "\n",
    "X_boruta_sel = pd.read_csv(\"selected_features_training_data.csv\", header=0)\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "FSmodels_list_r2 = []\n",
    "FSmodels_list_predr2 = []\n",
    "\n",
    "X_boruta_sel.columns = [\n",
    "    regex.sub(\"_\", col) if any(x in str(col) for x in set((\"[\", \"]\", \"<\"))) else col\n",
    "    for col in X_boruta_sel.columns.values\n",
    "]\n",
    "\n",
    "X_train_boruta, X_test_boruta, Y_train_boruta, Y_test_boruta = train_test_split(\n",
    "    X_boruta_sel, Y, test_size=0.2, random_state=0\n",
    ")\n",
    "\n",
    "df3 = pd.DataFrame(data= X_boruta_sel, columns= X_boruta_sel.columns)\n",
    "df3.columns = [\n",
    "    regex.sub(\"_\", col) if any(x in str(col) for x in set((\"[\", \"]\", \"<\"))) else col\n",
    "    for col in  X_boruta_sel.columns.values\n",
    "]\n",
    "X_importance = X_test_boruta\n",
    "\n",
    "for name, model in models:\n",
    "    nested_cv_results = model_selection.cross_validate(model, X_boruta_sel, Y, cv=outer_cv, scoring=scoring)\n",
    "    nested_cv_results2 = model_selection.cross_val_score(model, X_boruta_sel, Y, cv=outer_cv, scoring='r2')\n",
    "    results.append(nested_cv_results2)\n",
    "    names.append(name)\n",
    "    print(name, 'Nested CV results for all scores:', '\\n', nested_cv_results, '\\n')\n",
    "    print(name, 'r2 Nested CV Median', np.median(nested_cv_results['test_r2']))\n",
    "    print(name, 'MSE Nested CV Median', np.median(nested_cv_results['test_neg_mean_squared_error'] ))\n",
    "    print(name, 'RMSE Nested CV Median', np.median(nested_cv_results['test_neg_root_mean_squared_error'] ))\n",
    "    print(name, 'Explained Variance Nested CV Median', np.median(nested_cv_results['test_explained_variance'] ))\n",
    "    print(name, 'MAE Nested CV Median', np.median(nested_cv_results['test_neg_mean_absolute_error'] ))\n",
    "    model.fit(X_boruta_sel, Y)\n",
    "    print('\\n')\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print(\"Best Estimator:\", model.best_estimator_)\n",
    "    best_model = model.best_estimator_\n",
    "    print('\\n')\n",
    "    print('Non-nested CV Results:')\n",
    "    best_model.fit(X_train_boruta, Y_train_boruta)\n",
    "    y_pred_train = best_model.predict(X_train_boruta)\n",
    "    y_pred = best_model.predict(X_test_boruta)\n",
    "    print(name, 'Train r2:', r2_score(Y_train_boruta, y_pred_train), 'Test r2:', r2_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train MSE:', mean_squared_error(Y_train_boruta, y_pred_train), 'Test MSE:', mean_squared_error(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train Explained Variance Score:', explained_variance_score(Y_train_boruta, y_pred_train), 'Test Explained Variance Score:', explained_variance_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train MAE:', mean_absolute_error(Y_train_boruta, y_pred_train),'Test MAE:', mean_absolute_error(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train Max Error:', max_error(Y_train_boruta, y_pred_train), 'Test Max Error:', max_error(Y_test_boruta, y_pred))\n",
    "    print('\\n')\n",
    "    best_model.fit(X_boruta_sel, Y)\n",
    "    y_pred2 = best_model.predict(X_boruta_sel)\n",
    "    print(name, \"Best model predicted r2:\", predicted_r2(Y, y_pred2, X_boruta_sel))\n",
    "    #explainer = shap.TreeExplainer(best_model)\n",
    "    #shap_values = explainer.shap_values(X_boruta_sel)\n",
    "    #X_importance = pd.DataFrame(data=X_boruta_sel, columns=df3.columns)\n",
    "    #print(name,'SELECTED FEATURES Ranked SHAP Importance:', X_boruta_sel.columns[np.argsort(np.abs(shap_values).mean(0))[::-1]])\n",
    "    #fig, ax = plt.subplots()\n",
    "    #shap.summary_plot(shap_values, X_boruta_sel)\n",
    "    #fig.savefig(\"shap_summary_selected_features\" + name +\".svg\", format='svg', dpi=1200, bbox_inches = \"tight\")\n",
    "    median_r2 = np.median(nested_cv_results['test_r2'])\n",
    "    FSmodels_list_r2.append((best_model,  median_r2))\n",
    "    predr2_score = predicted_r2(Y, y_pred2, X_boruta_sel)\n",
    "    FSmodels_list_predr2.append((best_model, predr2_score))\n",
    "    \n",
    "print('All r2 results:', results) \n",
    "\n",
    "results = []\n",
    "names = []\n",
    "othermodels = []\n",
    "\n",
    "othermodels.append(('KNR', BayesSearchCV(knr, knr_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n",
    "othermodels.append(('SVR', BayesSearchCV(svr, svr_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n",
    "othermodels.append(('Lasso', BayesSearchCV(lasso, lasso_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n",
    "othermodels.append(('ElasticNet', BayesSearchCV(elastic, elastic_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n",
    "\n",
    "X2_boruta_sel = MinMaxScaler().fit_transform(X_boruta_sel)\n",
    "X_train_boruta, X_test_boruta, Y_train_boruta, Y_test_boruta = train_test_split(\n",
    "    X2_boruta_sel, Y, test_size=0.2, random_state=seed)\n",
    "\n",
    "df3 = pd.DataFrame(data= X2_boruta_sel, columns= X_boruta_sel.columns)\n",
    "df3.columns = [\n",
    "    regex.sub(\"_\", col) if any(x in str(col) for x in set((\"[\", \"]\", \"<\"))) else col\n",
    "    for col in  X_boruta_sel.columns.values\n",
    "]\n",
    "X_importance = df3\n",
    "\n",
    "for name, model in othermodels:\n",
    "    nested_cv_results = model_selection.cross_validate(model, X2_boruta_sel, Y, cv=outer_cv, scoring=scoring, return_estimator=True, return_train_score=True)\n",
    "    nested_cv_results2 = model_selection.cross_val_score(model, X2_boruta_sel, Y, cv=outer_cv, scoring='r2')\n",
    "    results.append(nested_cv_results2)\n",
    "    names.append(name)\n",
    "    print('\\n')\n",
    "    print(name, 'Nested CV results for all scores:', '\\n', nested_cv_results, '\\n')\n",
    "    print(name, 'r2 Nested CV Median', np.median(nested_cv_results['test_r2']))\n",
    "    print(name, 'MSE Nested CV Median', np.median(nested_cv_results['test_neg_mean_squared_error'] ))\n",
    "    print(name, 'RMSE Nested CV Median', np.median(nested_cv_results['test_neg_root_mean_squared_error'] ))\n",
    "    print(name, 'Explained Variance Nested CV Median', np.median(nested_cv_results['test_explained_variance'] ))\n",
    "    print(name, 'MAE Nested CV Median', np.median(nested_cv_results['test_neg_mean_absolute_error'] ))\n",
    "    model.fit(X2_boruta_sel, Y)\n",
    "    print('\\n')\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print(\"Best Estimator:\", model.best_estimator_)\n",
    "    print('\\n')\n",
    "    best_model = model.best_estimator_\n",
    "    best_model.fit(X_train_boruta, Y_train_boruta)\n",
    "    print('Non-nested CV Results:')\n",
    "    y_pred_train = best_model.predict(X_train_boruta)\n",
    "    y_pred = best_model.predict(X_test_boruta)\n",
    "    print(name, 'Train r2:', r2_score(Y_train_boruta, y_pred_train), 'Test r2:', r2_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train MSE:', mean_squared_error(Y_train_boruta, y_pred_train), 'Test MSE:', mean_squared_error(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train Explained Variance Score:', explained_variance_score(Y_train_boruta, y_pred_train), 'Test Explained Variance Score:', explained_variance_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train MAE:', mean_absolute_error(Y_train_boruta, y_pred_train),'Test MAE:', mean_absolute_error(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train Max Error:', max_error(Y_train_boruta, y_pred_train), 'Test Max Error:', max_error(Y_test_boruta, y_pred))\n",
    "    print('\\n')\n",
    "    best_model.fit(X2_boruta_sel, Y)\n",
    "    y_pred2 = best_model.predict(X2_boruta_sel)\n",
    "    print(name, \"Best model predicted r2:\", predicted_r2(Y, y_pred2, X2_boruta_sel))\n",
    "    print('\\n')\n",
    "    #explainer = shap.KernelExplainer(best_model.predict, X_importance)\n",
    "    #shap_values = explainer.shap_values(X_importance)\n",
    "    #X_importance = pd.DataFrame(data=X_importance, columns=X_importance.columns)\n",
    "    #print(name,'SELECTED FEATURES Ranked SHAP Importance:', X_importance.columns[np.argsort(np.abs(shap_values).mean(0))[::-1]])\n",
    "    #fig, ax = plt.subplots()\n",
    "    #shap.summary_plot(shap_values, X_importance)\n",
    "    #fig.savefig(\"shap_summary_selected_features\" + name +\".svg\", format='svg', dpi=1200, bbox_inches = \"tight\")\n",
    "    median_r2 = np.median(nested_cv_results['test_r2'])\n",
    "    FSmodels_list_r2.append((best_model,  median_r2))\n",
    "    predr2_score = predicted_r2(Y, y_pred2, X2_boruta_sel)\n",
    "    FSmodels_list_predr2.append((best_model, predr2_score))\n",
    "\n",
    "print('All r2 results:', results)   \n",
    "\n",
    "best_FSmodel1, best_r2 = sorted(FSmodels_list_r2, key = lambda x: x[1], reverse=True)[0]\n",
    "best_FSmodel2, best_predr2 = sorted(FSmodels_list_predr2, key = lambda x: x[1], reverse=True)[0]\n",
    "print('Best model by median r2:',best_FSmodel1)\n",
    "print('Best model by predicted r2:',best_FSmodel2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256306c6-c8f4-4f5c-a2cf-f806c05e9107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
