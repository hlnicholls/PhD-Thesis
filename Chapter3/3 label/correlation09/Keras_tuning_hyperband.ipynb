{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46bd4eaa-4a3c-4939-9d74-286ac25eec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import sort\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.mpl.rcParams[\"figure.figsize\"] = (15.0, 9.0)\n",
    "\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "from warnings import filterwarnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "seed = 0\n",
    "\n",
    "\n",
    "#import keras\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "#from keras.layers import Dropout\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "#from keras.constraints import maxnorm\n",
    "#from keras.layers import LeakyReLU\n",
    "#from keras.optimizers import *\n",
    "#from keras.utils import np_utils\n",
    "#from keras import regularizers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a094a9f3-e576-418f-9c12-eaf41fb71424",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"training_cleaned.csv\", header=0, sep=\",\")\n",
    "\n",
    "data['BPlabel_encoded'] = data['BPlabel'].map( {'most likely':0,'probable':1, 'least likely':2})\n",
    "Y = data[\"BPlabel_encoded\"] \n",
    "data = data.drop([\"BPlabel\"],1)\n",
    "\n",
    "X = pd.read_csv(\"selected_features_training_data.csv\", header=0)\n",
    "X.columns = [\n",
    "    regex.sub(\"_\", col) if any(x in str(col) for x in set((\"[\", \"]\", \"<\"))) else col\n",
    "    for col in X.columns.values\n",
    "]\n",
    "\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ade8cfd-8695-4e52-b867-b3a0a33a8b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 00s]\n",
      "val_accuracy: 0.3191489279270172\n",
      "\n",
      "Best val_accuracy So Far: 0.7872340679168701\n",
      "Total elapsed time: 00h 00m 16s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(units=10))\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10))\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3)\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(X_train, Y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3466db13-5b52-4746-88ff-5bb6e13f753a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 160 and the optimal learning rate for the optimizer\n",
      "is 0.01.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd089f8c-5f0a-4c24-9501-313e1bde6ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.8506 - accuracy: 0.4385 - val_loss: 1.4006 - val_accuracy: 0.4043\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.1146 - accuracy: 0.5241 - val_loss: 1.0004 - val_accuracy: 0.4255\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8936 - accuracy: 0.5401 - val_loss: 0.8526 - val_accuracy: 0.6383\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8692 - accuracy: 0.5508 - val_loss: 0.8281 - val_accuracy: 0.4255\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8263 - accuracy: 0.6310 - val_loss: 0.6985 - val_accuracy: 0.7234\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8360 - accuracy: 0.5668 - val_loss: 0.7612 - val_accuracy: 0.6809\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8084 - accuracy: 0.6417 - val_loss: 0.6270 - val_accuracy: 0.8085\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7712 - accuracy: 0.6364 - val_loss: 0.7332 - val_accuracy: 0.7021\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7543 - accuracy: 0.6684 - val_loss: 0.6239 - val_accuracy: 0.7447\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7547 - accuracy: 0.6898 - val_loss: 0.5898 - val_accuracy: 0.8085\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7201 - accuracy: 0.7005 - val_loss: 0.6579 - val_accuracy: 0.7021\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7124 - accuracy: 0.7005 - val_loss: 0.5789 - val_accuracy: 0.8085\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7072 - accuracy: 0.7059 - val_loss: 0.5865 - val_accuracy: 0.7872\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.6791 - val_loss: 0.6020 - val_accuracy: 0.8085\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6635 - accuracy: 0.7166 - val_loss: 0.5630 - val_accuracy: 0.8085\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6649 - accuracy: 0.7326 - val_loss: 0.6007 - val_accuracy: 0.8085\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.7326 - val_loss: 0.5616 - val_accuracy: 0.8298\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.7487 - val_loss: 0.5915 - val_accuracy: 0.7872\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6182 - accuracy: 0.7487 - val_loss: 0.5727 - val_accuracy: 0.8085\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6075 - accuracy: 0.7594 - val_loss: 0.5895 - val_accuracy: 0.7872\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.7487 - val_loss: 0.6420 - val_accuracy: 0.7872\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6037 - accuracy: 0.7540 - val_loss: 0.5923 - val_accuracy: 0.7872\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.7273 - val_loss: 0.6098 - val_accuracy: 0.7872\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6100 - accuracy: 0.7701 - val_loss: 0.6747 - val_accuracy: 0.7872\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.7380 - val_loss: 0.6148 - val_accuracy: 0.8085\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.7594 - val_loss: 0.7188 - val_accuracy: 0.7660\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.7487 - val_loss: 0.6613 - val_accuracy: 0.8085\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.7754 - val_loss: 0.7365 - val_accuracy: 0.7872\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5921 - accuracy: 0.7380 - val_loss: 0.7069 - val_accuracy: 0.7872\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.7594 - val_loss: 0.7404 - val_accuracy: 0.8085\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5825 - accuracy: 0.7647 - val_loss: 0.7974 - val_accuracy: 0.7872\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6036 - accuracy: 0.7380 - val_loss: 0.7529 - val_accuracy: 0.7872\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5973 - accuracy: 0.7380 - val_loss: 0.8658 - val_accuracy: 0.7447\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.7647 - val_loss: 0.8456 - val_accuracy: 0.7660\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5711 - accuracy: 0.7807 - val_loss: 0.8227 - val_accuracy: 0.7872\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5672 - accuracy: 0.7701 - val_loss: 0.9061 - val_accuracy: 0.7872\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5515 - accuracy: 0.7861 - val_loss: 0.8762 - val_accuracy: 0.7872\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5448 - accuracy: 0.7861 - val_loss: 0.9556 - val_accuracy: 0.7872\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5488 - accuracy: 0.7807 - val_loss: 0.9243 - val_accuracy: 0.7872\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5504 - accuracy: 0.7754 - val_loss: 0.9920 - val_accuracy: 0.7872\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5392 - accuracy: 0.7914 - val_loss: 0.9679 - val_accuracy: 0.7872\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5371 - accuracy: 0.7754 - val_loss: 1.0274 - val_accuracy: 0.7872\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5378 - accuracy: 0.7968 - val_loss: 1.0219 - val_accuracy: 0.7872\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5436 - accuracy: 0.7914 - val_loss: 1.0659 - val_accuracy: 0.7872\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5588 - accuracy: 0.7754 - val_loss: 1.1107 - val_accuracy: 0.7872\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5397 - accuracy: 0.8021 - val_loss: 1.1340 - val_accuracy: 0.7872\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.7861 - val_loss: 1.1329 - val_accuracy: 0.7872\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7968 - val_loss: 1.1991 - val_accuracy: 0.7872\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7968 - val_loss: 1.1801 - val_accuracy: 0.7872\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7701 - val_loss: 1.2272 - val_accuracy: 0.7872\n",
      "Best epoch: 17\n",
      "Epoch 1/17\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8833 - accuracy: 0.4492 - val_loss: 1.4179 - val_accuracy: 0.4255\n",
      "Epoch 2/17\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.0679 - accuracy: 0.5294 - val_loss: 0.9595 - val_accuracy: 0.4255\n",
      "Epoch 3/17\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8924 - accuracy: 0.5561 - val_loss: 0.7964 - val_accuracy: 0.7021\n",
      "Epoch 4/17\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8399 - accuracy: 0.5882 - val_loss: 0.7450 - val_accuracy: 0.7021\n",
      "Epoch 5/17\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7913 - accuracy: 0.6096 - val_loss: 0.6500 - val_accuracy: 0.7234\n",
      "Epoch 6/17\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7733 - accuracy: 0.6203 - val_loss: 0.6356 - val_accuracy: 0.7021\n",
      "Epoch 7/17\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7590 - accuracy: 0.6364 - val_loss: 0.6047 - val_accuracy: 0.7234\n",
      "Epoch 8/17\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7620 - accuracy: 0.6150 - val_loss: 0.6800 - val_accuracy: 0.7021\n",
      "Epoch 9/17\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7326 - accuracy: 0.6524 - val_loss: 0.5837 - val_accuracy: 0.7872\n",
      "Epoch 10/17\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7265 - accuracy: 0.6952 - val_loss: 0.6537 - val_accuracy: 0.6809\n",
      "Epoch 11/17\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7505 - accuracy: 0.6471 - val_loss: 0.6287 - val_accuracy: 0.7021\n",
      "Epoch 12/17\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7545 - accuracy: 0.6684 - val_loss: 0.5863 - val_accuracy: 0.8085\n",
      "Epoch 13/17\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7271 - accuracy: 0.6738 - val_loss: 0.6976 - val_accuracy: 0.7234\n",
      "Epoch 14/17\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7028 - accuracy: 0.7059 - val_loss: 0.6074 - val_accuracy: 0.7872\n",
      "Epoch 15/17\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.7487 - val_loss: 0.6374 - val_accuracy: 0.7447\n",
      "Epoch 16/17\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6676 - accuracy: 0.7166 - val_loss: 0.6161 - val_accuracy: 0.7872\n",
      "Epoch 17/17\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6621 - accuracy: 0.7433 - val_loss: 0.6250 - val_accuracy: 0.7660\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.7458\n",
      "[test loss, test accuracy]: [0.6046973466873169, 0.7457627058029175]\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, Y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))\n",
    "\n",
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(X_train, Y_train, epochs=best_epoch, validation_split=0.2)\n",
    "\n",
    "eval_result = hypermodel.evaluate(X_test, Y_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3bb942f-4633-4d24-bb14-b86b73dd5948",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<keras.engine.sequential.Sequential object at 0x7fdc04eb5a60>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m                 \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8f51c42862ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m           'precision_weighted','recall_weighted']\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnested_cv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mouter_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mnested_cv_results2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mouter_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 242\u001b[0;31m     scores = parallel(\n\u001b[0m\u001b[1;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    836\u001b[0m                 \u001b[0mbig_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 \u001b[0mislice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    242\u001b[0m     scores = parallel(\n\u001b[1;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BPGWAS/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     76\u001b[0m                                 \"scikit-learn estimator instead of a class.\")\n\u001b[1;32m     77\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 raise TypeError(\"Cannot clone object '%s' (type %s): \"\n\u001b[0m\u001b[1;32m     79\u001b[0m                                 \u001b[0;34m\"it does not seem to be a scikit-learn \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                                 \u001b[0;34m\"estimator as it does not implement a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot clone object '<keras.engine.sequential.Sequential object at 0x7fdc04eb5a60>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "\n",
    "inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "\n",
    "scoring = ['accuracy', 'balanced_accuracy', 'f1_weighted', \n",
    "          'precision_weighted','recall_weighted']\n",
    "\n",
    "nested_cv_results = cross_validate(hypermodel, X , Y, cv=outer_cv, scoring=scoring, error_score=\"raise\")\n",
    "nested_cv_results2 = cross_val_score(hypermodel, X , Y, cv=outer_cv, scoring='balanced_accuracy', error_score=\"raise\")\n",
    "\n",
    "print( 'Nested CV results for all scores:', '\\n', nested_cv_results, '\\n')\n",
    "print( 'Accuracy Nested CV Average', np.median(nested_cv_results['test_accuracy']))\n",
    "print( 'Balanced Accuracy Nested CV Average', np.median(nested_cv_results['test_balanced_accuracy'] ))\n",
    "print( 'F1 Nested CV Average', np.median(nested_cv_results['test_f1_weighted'] ))\n",
    "print( 'Precision Nested CV Average', np.median(nested_cv_results['test_precision_weighted'] ))\n",
    "print( 'Recall Nested CV Average', np.median(nested_cv_results['test_recall_weighted'] ))\n",
    "hypermodel.fit(X_train, Y_train)\n",
    "print(\"Best Parameters: \\n{}\\n\".format(hypermodel.best_params_))\n",
    "print('Non-nested CV Results:')\n",
    "y_pred_train = hypermodel.predict(X_train)\n",
    "y_pred = hypermodel.predict(X_test)\n",
    "print( 'Train accuracy:', accuracy_score(Y_train, y_pred_train), 'Test accuracy:', accuracy_score(Y_test, y_pred))\n",
    "print( 'Train balanced accuracy:', balanced_accuracy_score(Y_train, y_pred_train), 'Test balanced accuracy:', balanced_accuracy_score(Y_test, y_pred))\n",
    "print( 'Train F1', f1_score(Y_train, y_pred_train, average='weighted'), 'Test F1:', f1_score(Y_test, y_pred, average='weighted'))\n",
    "print( 'Train recall:', recall_score(Y_train, y_pred_train, average='weighted'),'Test recall:', recall_score(Y_test, y_pred,average='weighted'))\n",
    "print( 'Train precision:', precision_score(Y_train, y_pred_train,average='weighted'), 'Test precision:', precision_score(Y_test, y_pred,average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e3767f-2a67-4d1a-8347-b4b61e4a6ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
