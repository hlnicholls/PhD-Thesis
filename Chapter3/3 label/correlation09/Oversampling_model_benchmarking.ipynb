{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Machine Learning for Prioritizing Blood Pressure Genes__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import sort\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import statsmodels.api as sm\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "import statsmodels.stats.api as sms\n",
    "import xgboost\n",
    "from sklearn import datasets, metrics, model_selection, preprocessing\n",
    "from sklearn.ensemble import (\n",
    "    BaggingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    KFold,\n",
    "    RandomizedSearchCV,\n",
    "    RepeatedKFold,\n",
    "    cross_val_predict,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    learning_curve,\n",
    "    train_test_split,\n",
    "    validation_curve,\n",
    ")\n",
    "\n",
    "\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, BorderlineSMOTE, SVMSMOTE, SMOTENC, RandomOverSampler\n",
    "from imblearn.base import BaseSampler\n",
    "from imblearn.datasets import make_imbalance\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.mpl.rcParams[\"figure.figsize\"] = (15.0, 9.0)\n",
    "\n",
    "import warnings\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "from warnings import filterwarnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"2021-11-19_training_cleaned.csv\", header=0, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(243, 103)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['BPlabel_encoded'] = data['BPlabel'].map( {'most likely':1,'probable':2, 'least likely':3})\n",
    "Y = data[\"BPlabel_encoded\"] \n",
    "Y2 = Y\n",
    "data = data.drop([\"BPlabel\"],1)\n",
    "data.shape  #Data has IPA and ensembl features without possible label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"2021-11-19_imputed_training_data.csv\", header=0)\n",
    "X.columns = [\n",
    "    regex.sub(\"_\", col) if any(x in str(col) for x in set((\"[\", \"]\", \"<\"))) else col\n",
    "    for col in X.columns.values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, the shape of X: (243, 101)\n",
      "Before OverSampling, the shape of y: (243,) \n",
      "\n",
      "After OverSampling, the shape of X: (447, 101)\n",
      "After OverSampling, the shape of y: (447,) \n",
      "\n",
      "After OverSampling, counts of label '1': 149\n",
      "After OverSampling, counts of label '2': 149\n",
      "After OverSampling, counts of label '3': 149\n"
     ]
    }
   ],
   "source": [
    "print('Before OverSampling, the shape of X: {}'.format(X.shape))\n",
    "print('Before OverSampling, the shape of y: {} \\n'.format(Y.shape))\n",
    "\n",
    "sm = SMOTE(random_state=seed)\n",
    "X, Y = sm.fit_resample(X, Y)\n",
    "\n",
    "print('After OverSampling, the shape of X: {}'.format(X.shape))\n",
    "print('After OverSampling, the shape of y: {} \\n'.format(Y.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(Y==1)))\n",
    "print(\"After OverSampling, counts of label '2': {}\".format(sum(Y==2)))\n",
    "print(\"After OverSampling, counts of label '3': {}\".format(sum(Y==3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models:\n",
    "- Parameter tuning with Bayesian optimization over hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier(random_state=seed, num_class=3, objective='multi:softmax', eval_metric='mlogloss') \n",
    "xgb_params = {\n",
    "    'max_depth':  (1, 4), #Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit.\n",
    "    'learning_rate': (0.01, 0.5, 'log-uniform'),  #Step size shrinkage used in update to prevents overfitting. After each boosting step, we can directly get the weights of new features\n",
    "    'n_estimators':  (10, 50), #Number of gradient boosted trees. Equivalent to number of boosting rounds.\n",
    "    'reg_alpha':  (1, 10, 'log-uniform'), #L1 regularization term on weights. Increasing this value will make model more conservative.\n",
    "    'reg_lambda':  (1, 10, 'log-uniform')} #L2 regularization term on weights. Increasing this value will make model more conservative.\n",
    "\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=seed)\n",
    "gb_params = {\n",
    "    'learning_rate': (0.01, 0.5),\n",
    "    'max_depth': (1, 4),\n",
    "    \"max_features\":[\"log2\",\"sqrt\", \"auto\"],\n",
    "    \"criterion\": [\"friedman_mse\", \"mse\", \"mae\"],\n",
    "    'n_estimators': (10, 50)\n",
    "    }\n",
    "\n",
    "rf = RandomForestClassifier(random_state=seed)\n",
    "rf_params={'n_estimators': (10, 50), \n",
    "             'max_features': ['auto', 'sqrt', 'log2'],\n",
    "             'max_depth' : (1, 4),\n",
    "             'criterion' :[\"gini\", \"entropy\"]} \n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=seed)\n",
    "dt_params= {\"criterion\": [\"gini\", \"entropy\"],\n",
    "            'max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'max_depth' : (1, 4)}\n",
    "\n",
    "extra = ExtraTreesClassifier(random_state=seed)\n",
    "extra_params ={'n_estimators': (10, 50), \n",
    "             'max_features': ['auto', 'sqrt', 'log2'],\n",
    "             'max_depth' : (1, 4),\n",
    "             'criterion' :[\"gini\", \"entropy\"]}\n",
    "\n",
    "\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append(('XGB', BayesSearchCV(xgb, xgb_params, cv=inner_cv, iid=False, n_jobs=1))) \n",
    "models.append(('RF', BayesSearchCV(rf, rf_params, cv=inner_cv,iid=False, n_jobs=1)))\n",
    "models.append(('GB', BayesSearchCV(gb, gb_params, cv=inner_cv,iid=False, n_jobs=1)))\n",
    "models.append(('DT', BayesSearchCV(dt, dt_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "models.append(('ExtraTrees', BayesSearchCV(extra, extra_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "#models.append(('KNN', BayesSearchCV(knn, knn_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "#models.append(('SVC', BayesSearchCV(svc, svc_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "\n",
    "results = []\n",
    "results1 = []\n",
    "results2 = []\n",
    "results3 = []\n",
    "names = []\n",
    "names2 =[]\n",
    "scoring = ['accuracy', 'balanced_accuracy', 'f1_weighted', \n",
    "          'precision_weighted','recall_weighted'] #https://scikit-learn.org/stable/modules/model_evaluation.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Benchmarking - all features:\n",
    "### Tree-based models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Nested CV results for all scores: \n",
      " {'fit_time': array([68.7247901 , 70.22632599, 81.06028295, 69.1443491 , 66.36307406]), 'score_time': array([0.00567508, 0.00560474, 0.00560713, 0.00544095, 0.00571179]), 'test_accuracy': array([0.87777778, 0.84444444, 0.85393258, 0.8988764 , 0.8988764 ]), 'test_balanced_accuracy': array([0.86517783, 0.86125966, 0.85490196, 0.90029762, 0.89402174]), 'test_f1_weighted': array([0.8742252 , 0.84151585, 0.85324681, 0.89896089, 0.89905719]), 'test_precision_weighted': array([0.88126984, 0.84284398, 0.85468433, 0.89936384, 0.9037659 ]), 'test_recall_weighted': array([0.87777778, 0.84444444, 0.85393258, 0.8988764 , 0.8988764 ])} \n",
      "\n",
      "XGB Accuracy Nested CV Average 0.8747815230961298\n",
      "XGB Balanced Accuracy Nested CV Average 0.8751317614518876\n",
      "XGB F1 Nested CV Average 0.8734011866417388\n",
      "XGB Precision Nested CV Average 0.8763855767439054\n",
      "XGB Recall Nested CV Average 0.8747815230961298\n",
      "Best Parameters: \n",
      "OrderedDict([('learning_rate', 0.49999999999999994), ('max_depth', 4), ('n_estimators', 50), ('reg_alpha', 1), ('reg_lambda', 10)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "XGB Train accuracy: 1.0 Test accuracy: 0.8888888888888888\n",
      "XGB Train balanced accuracy: 1.0 Test balanced accuracy: 0.8779983457402812\n",
      "XGB Train F1 1.0 Test F1: 0.886204229646032\n",
      "XGB Train recall: 1.0 Test recall: 0.8888888888888888\n",
      "XGB Train precision: 1.0 Test precision: 0.8907500778089013\n",
      "\n",
      "\n",
      "RF Nested CV results for all scores: \n",
      " {'fit_time': array([64.47174978, 68.47616887, 65.48174095, 63.04123712, 56.08573318]), 'score_time': array([0.00658107, 0.00662708, 0.00756192, 0.00681806, 0.00670385]), 'test_accuracy': array([0.85555556, 0.84444444, 0.80898876, 0.8988764 , 0.87640449]), 'test_balanced_accuracy': array([0.84780811, 0.85247617, 0.81045752, 0.90070813, 0.87318841]), 'test_f1_weighted': array([0.85573427, 0.84247814, 0.8157416 , 0.89876376, 0.87673282]), 'test_precision_weighted': array([0.85621399, 0.84657891, 0.83304639, 0.89897639, 0.88759106]), 'test_recall_weighted': array([0.85555556, 0.84444444, 0.80898876, 0.8988764 , 0.87640449])} \n",
      "\n",
      "RF Accuracy Nested CV Average 0.8568539325842697\n",
      "RF Balanced Accuracy Nested CV Average 0.8569276648842713\n",
      "RF F1 Nested CV Average 0.8578901182226202\n",
      "RF Precision Nested CV Average 0.8644813486508329\n",
      "RF Recall Nested CV Average 0.8568539325842697\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'gini'), ('max_depth', 4), ('max_features', 'auto'), ('n_estimators', 34)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "RF Train accuracy: 0.9663865546218487 Test accuracy: 0.8777777777777778\n",
      "RF Train balanced accuracy: 0.9671351798263745 Test balanced accuracy: 0.8672456575682382\n",
      "RF Train F1 0.9662920274693676 Test F1: 0.8758553110298847\n",
      "RF Train recall: 0.9663865546218487 Test recall: 0.8777777777777778\n",
      "RF Train precision: 0.966890487693931 Test precision: 0.8763478777545275\n",
      "\n",
      "\n",
      "GB Nested CV results for all scores: \n",
      " {'fit_time': array([115.01377678, 155.39575505, 173.53538799, 134.04441023,\n",
      "       180.30846   ]), 'score_time': array([0.00391293, 0.00420022, 0.00411797, 0.0040729 , 0.00368118]), 'test_accuracy': array([0.91111111, 0.86666667, 0.88764045, 0.93258427, 0.91011236]), 'test_balanced_accuracy': array([0.90363937, 0.88027332, 0.88653595, 0.93303571, 0.90036232]), 'test_f1_weighted': array([0.91003354, 0.86577958, 0.88853664, 0.93258427, 0.90956956]), 'test_precision_weighted': array([0.91004902, 0.86700617, 0.88980121, 0.93258427, 0.90934604]), 'test_recall_weighted': array([0.91111111, 0.86666667, 0.88764045, 0.93258427, 0.91011236])} \n",
      "\n",
      "GB Accuracy Nested CV Average 0.9016229712858926\n",
      "GB Balanced Accuracy Nested CV Average 0.9007693347339621\n",
      "GB F1 Nested CV Average 0.9013007163452285\n",
      "GB Precision Nested CV Average 0.9017573416969548\n",
      "GB Recall Nested CV Average 0.9016229712858926\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'mse'), ('learning_rate', 0.5), ('max_depth', 4), ('max_features', 'sqrt'), ('n_estimators', 50)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "GB Train accuracy: 1.0 Test accuracy: 0.9333333333333333\n",
      "GB Train balanced accuracy: 1.0 Test balanced accuracy: 0.9272125723738626\n",
      "GB Train F1 1.0 Test F1: 0.9330416666666667\n",
      "GB Train recall: 1.0 Test recall: 0.9333333333333333\n",
      "GB Train precision: 1.0 Test precision: 0.9341750841750842\n",
      "\n",
      "\n",
      "DT Nested CV results for all scores: \n",
      " {'fit_time': array([40.15996695, 42.86011577, 36.4449389 , 41.63228273, 40.44260097]), 'score_time': array([0.00389791, 0.00378227, 0.00384283, 0.00409698, 0.004076  ]), 'test_accuracy': array([0.72222222, 0.61111111, 0.70786517, 0.69662921, 0.71910112]), 'test_balanced_accuracy': array([0.70702058, 0.63863701, 0.70287582, 0.70807677, 0.67742967]), 'test_f1_weighted': array([0.72192136, 0.60372812, 0.71461362, 0.68517295, 0.69463301]), 'test_precision_weighted': array([0.72184722, 0.60344951, 0.7370833 , 0.71462982, 0.72276515]), 'test_recall_weighted': array([0.72222222, 0.61111111, 0.70786517, 0.69662921, 0.71910112])} \n",
      "\n",
      "DT Accuracy Nested CV Average 0.6913857677902622\n",
      "DT Balanced Accuracy Nested CV Average 0.6868079674341598\n",
      "DT F1 Nested CV Average 0.6840138112683947\n",
      "DT Precision Nested CV Average 0.6999550011537783\n",
      "DT Recall Nested CV Average 0.6913857677902622\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'gini'), ('max_depth', 4), ('max_features', 'log2')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "DT Train accuracy: 0.8067226890756303 Test accuracy: 0.7222222222222222\n",
      "DT Train balanced accuracy: 0.8099773662844751 Test balanced accuracy: 0.6966814547459709\n",
      "DT Train F1 0.803247248719244 Test F1: 0.7004829551195264\n",
      "DT Train recall: 0.8067226890756303 Test recall: 0.7222222222222222\n",
      "DT Train precision: 0.8171526566369436 Test precision: 0.7055286865813181\n",
      "\n",
      "\n",
      "ExtraTrees Nested CV results for all scores: \n",
      " {'fit_time': array([55.3169086 , 51.39900398, 49.60404205, 53.65260625, 53.21199322]), 'score_time': array([0.00620627, 0.00647688, 0.00601888, 0.00680089, 0.00775194]), 'test_accuracy': array([0.73333333, 0.77777778, 0.73033708, 0.75280899, 0.76404494]), 'test_balanced_accuracy': array([0.73137078, 0.78718128, 0.75464052, 0.75990353, 0.78330136]), 'test_f1_weighted': array([0.73619492, 0.77884281, 0.72461966, 0.74988444, 0.77152177]), 'test_precision_weighted': array([0.74602665, 0.78165967, 0.79059377, 0.75973943, 0.82800346]), 'test_recall_weighted': array([0.73333333, 0.77777778, 0.73033708, 0.75280899, 0.76404494])} \n",
      "\n",
      "ExtraTrees Accuracy Nested CV Average 0.7516604244694133\n",
      "ExtraTrees Balanced Accuracy Nested CV Average 0.7632794945415113\n",
      "ExtraTrees F1 Nested CV Average 0.7522127217603923\n",
      "ExtraTrees Precision Nested CV Average 0.7812045931146226\n",
      "ExtraTrees Recall Nested CV Average 0.7516604244694133\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'gini'), ('max_depth', 4), ('max_features', 'sqrt'), ('n_estimators', 44)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "ExtraTrees Train accuracy: 0.8683473389355743 Test accuracy: 0.8444444444444444\n",
      "ExtraTrees Train balanced accuracy: 0.8676390928140725 Test balanced accuracy: 0.8430333107752462\n",
      "ExtraTrees Train F1 0.8679561630781143 Test F1: 0.8461337388219107\n",
      "ExtraTrees Train recall: 0.8683473389355743 Test recall: 0.8444444444444444\n",
      "ExtraTrees Train precision: 0.8777388514117168 Test precision: 0.851963601532567\n",
      "\n",
      "\n",
      "All balanced accuracy results: [array([0.86517783, 0.83184789, 0.84509804, 0.89880952, 0.89402174]), array([0.87138131, 0.84617272, 0.8130719 , 0.90070813, 0.87787724]), array([0.91645988, 0.83696298, 0.88875817, 0.93452381, 0.92934783]), array([0.70702058, 0.63863701, 0.70287582, 0.70807677, 0.67742967]), array([0.83434845, 0.78718128, 0.75464052, 0.74651067, 0.78330136])]\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    nested_cv_results = model_selection.cross_validate(model, X , Y, cv=outer_cv, scoring=scoring, error_score=\"raise\")\n",
    "    nested_cv_results2 = model_selection.cross_val_score(model, X , Y, cv=outer_cv, scoring='balanced_accuracy', error_score=\"raise\")\n",
    "    results.append(nested_cv_results2)\n",
    "    names.append(name)\n",
    "    print(name, 'Nested CV results for all scores:', '\\n', nested_cv_results, '\\n')\n",
    "    print(name, 'Accuracy Nested CV Average', np.mean(nested_cv_results['test_accuracy']))\n",
    "    print(name, 'Balanced Accuracy Nested CV Average', np.mean(nested_cv_results['test_balanced_accuracy'] ))\n",
    "    print(name, 'F1 Nested CV Average', np.mean(nested_cv_results['test_f1_weighted'] ))\n",
    "    print(name, 'Precision Nested CV Average', np.mean(nested_cv_results['test_precision_weighted'] ))\n",
    "    print(name, 'Recall Nested CV Average', np.mean(nested_cv_results['test_recall_weighted'] ))\n",
    "    model.fit(X_train, Y_train)\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print('Non-nested CV Results:')\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(name, 'Train accuracy:', accuracy_score(Y_train, y_pred_train), 'Test accuracy:', accuracy_score(Y_test, y_pred))\n",
    "    print(name, 'Train balanced accuracy:', balanced_accuracy_score(Y_train, y_pred_train), 'Test balanced accuracy:', balanced_accuracy_score(Y_test, y_pred))\n",
    "    print(name, 'Train F1', f1_score(Y_train, y_pred_train, average='weighted'), 'Test F1:', f1_score(Y_test, y_pred, average='weighted'))\n",
    "    print(name, 'Train recall:', recall_score(Y_train, y_pred_train, average='weighted'),'Test recall:', recall_score(Y_test, y_pred,average='weighted'))\n",
    "    print(name, 'Train precision:', precision_score(Y_train, y_pred_train,average='weighted'), 'Test precision:', precision_score(Y_test, y_pred,average='weighted'))\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "print('All balanced accuracy results:', results)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others models:\n",
    "- all other models require feature scaling before running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_params = {\n",
    "    'n_neighbors':[7,9,11,13,15,17],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['euclidean','manhattan', 'minkowski']}\n",
    "\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', solver='liblinear',multi_class='auto',random_state=seed)\n",
    "lr_params= {\n",
    "    'penalty':['l1', 'l2'], \n",
    "    'C': [0.5, 1, 5, 10], \n",
    "    'max_iter':[500, 1000, 2500]}\n",
    "\n",
    "svc = SVC()\n",
    "svc_params = {\n",
    "    'kernel': ['rbf'],\n",
    "   'C': (1e0, 1e3),\n",
    "   'gamma': ['scale', 'auto']}\n",
    "\n",
    "othermodels = []\n",
    "\n",
    "othermodels.append(('KNN', BayesSearchCV(knn, knn_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "othermodels.append(('SVC', BayesSearchCV(svc, svc_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "othermodels.append(('LR', BayesSearchCV(lr, lr_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "\n",
    "results = []\n",
    "results1 = []\n",
    "results2 = []\n",
    "results3 = []\n",
    "names = []\n",
    "names2 =[]\n",
    "scoring = ['accuracy', 'balanced_accuracy', 'f1_weighted', \n",
    "          'precision_weighted','recall_weighted'] #https://scikit-learn.org/stable/modules/model_evaluation.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = MinMaxScaler().fit_transform(X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X2, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Nested CV results for all scores: \n",
      " {'fit_time': array([51.11454415, 43.7562201 , 48.19915128, 49.96571183, 53.49711418]), 'score_time': array([0.00604296, 0.00554085, 0.00598884, 0.00545311, 0.00550771]), 'test_accuracy': array([0.8       , 0.71111111, 0.70786517, 0.78651685, 0.84269663]), 'test_balanced_accuracy': array([0.78163772, 0.74272133, 0.74156863, 0.80059524, 0.81748188]), 'test_f1_weighted': array([0.78905386, 0.69633279, 0.65682681, 0.76172256, 0.83694235]), 'test_precision_weighted': array([0.81866763, 0.72046176, 0.77165082, 0.82020501, 0.84197296]), 'test_recall_weighted': array([0.8       , 0.71111111, 0.70786517, 0.78651685, 0.84269663])} \n",
      "\n",
      "KNN Accuracy Nested CV Average 0.7696379525593009\n",
      "KNN Balanced Accuracy Nested CV Average 0.7768009595364805\n",
      "KNN F1 Nested CV Average 0.7481756714519485\n",
      "KNN Precision Nested CV Average 0.7945916362787007\n",
      "KNN Recall Nested CV Average 0.7696379525593009\n",
      "Best Parameters: \n",
      "OrderedDict([('metric', 'manhattan'), ('n_neighbors', 7), ('weights', 'distance')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "KNN Train accuracy: 1.0 Test accuracy: 0.8\n",
      "KNN Train balanced accuracy: 1.0 Test balanced accuracy: 0.7816377171215881\n",
      "KNN Train F1 1.0 Test F1: 0.7890538617886177\n",
      "KNN Train recall: 1.0 Test recall: 0.8\n",
      "KNN Train precision: 1.0 Test precision: 0.8186676286676287\n",
      "\n",
      "\n",
      "SVC Nested CV results for all scores: \n",
      " {'fit_time': array([44.59845996, 45.01340008, 44.97575784, 42.30410194, 46.73421907]), 'score_time': array([0.00559306, 0.00598598, 0.00617814, 0.00710607, 0.00579715]), 'test_accuracy': array([0.86666667, 0.78888889, 0.79775281, 0.83146067, 0.85393258]), 'test_balanced_accuracy': array([0.8502895 , 0.80873957, 0.80588235, 0.8422619 , 0.83727621]), 'test_f1_weighted': array([0.85900144, 0.77159924, 0.79273311, 0.819232  , 0.85183131]), 'test_precision_weighted': array([0.87037037, 0.81167356, 0.80225767, 0.85450656, 0.85107901]), 'test_recall_weighted': array([0.86666667, 0.78888889, 0.79775281, 0.83146067, 0.85393258])} \n",
      "\n",
      "SVC Accuracy Nested CV Average 0.8277403245942573\n",
      "SVC Balanced Accuracy Nested CV Average 0.8288899075193523\n",
      "SVC F1 Nested CV Average 0.8188794201617045\n",
      "SVC Precision Nested CV Average 0.8379774334278544\n",
      "SVC Recall Nested CV Average 0.8277403245942573\n",
      "Best Parameters: \n",
      "OrderedDict([('C', 101.03242561527094), ('gamma', 'scale'), ('kernel', 'rbf')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "SVC Train accuracy: 0.9859943977591037 Test accuracy: 0.9\n",
      "SVC Train balanced accuracy: 0.986449864498645 Test balanced accuracy: 0.8887510339123242\n",
      "SVC Train F1 0.9859262887327668 Test F1: 0.8968025202443225\n",
      "SVC Train recall: 0.9859943977591037 Test recall: 0.9\n",
      "SVC Train precision: 0.9862996178863701 Test precision: 0.9008807967631498\n",
      "\n",
      "\n",
      "LR Nested CV results for all scores: \n",
      " {'fit_time': array([76.30332685, 67.09636497, 73.10883784, 79.36726975, 75.91903019]), 'score_time': array([0.00243783, 0.00259805, 0.00261021, 0.00266433, 0.00361276]), 'test_accuracy': array([0.78888889, 0.78888889, 0.79775281, 0.78651685, 0.7752809 ]), 'test_balanced_accuracy': array([0.76261373, 0.81313131, 0.80104575, 0.79613095, 0.75274403]), 'test_f1_weighted': array([0.76380837, 0.7715275 , 0.79566788, 0.77642778, 0.7734788 ]), 'test_precision_weighted': array([0.7862798 , 0.81132861, 0.79907082, 0.79609751, 0.77196848]), 'test_recall_weighted': array([0.78888889, 0.78888889, 0.79775281, 0.78651685, 0.7752809 ])} \n",
      "\n",
      "LR Accuracy Nested CV Average 0.7874656679151061\n",
      "LR Balanced Accuracy Nested CV Average 0.7851331559794971\n",
      "LR F1 Nested CV Average 0.7761820663289545\n",
      "LR Precision Nested CV Average 0.792949044734027\n",
      "LR Recall Nested CV Average 0.7874656679151061\n",
      "Best Parameters: \n",
      "OrderedDict([('C', 10.0), ('max_iter', 1000), ('penalty', 'l1')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "LR Train accuracy: 0.927170868347339 Test accuracy: 0.7888888888888889\n",
      "LR Train balanced accuracy: 0.9286380648727586 Test balanced accuracy: 0.7626137303556658\n",
      "LR Train F1 0.926513945165308 Test F1: 0.7638083735909823\n",
      "LR Train recall: 0.927170868347339 Test recall: 0.7888888888888889\n",
      "LR Train precision: 0.9285235710179627 Test precision: 0.7862798020692756\n",
      "\n",
      "\n",
      "All balanced accuracy results: [array([0.78163772, 0.74272133, 0.74156863, 0.80059524, 0.81748188]), array([0.8502895 , 0.80873957, 0.81568627, 0.86309524, 0.83727621]), array([0.76261373, 0.81313131, 0.80104575, 0.79613095, 0.75274403])]\n"
     ]
    }
   ],
   "source": [
    "for name, model in othermodels:\n",
    "    nested_cv_results = model_selection.cross_validate(model, X2 , Y, cv=outer_cv, scoring=scoring, error_score=\"raise\")\n",
    "    nested_cv_results2 = model_selection.cross_val_score(model, X2 , Y, cv=outer_cv, scoring='balanced_accuracy', error_score=\"raise\")\n",
    "    results.append(nested_cv_results2)\n",
    "    names.append(name)\n",
    "    print(name, 'Nested CV results for all scores:', '\\n', nested_cv_results, '\\n')\n",
    "    print(name, 'Accuracy Nested CV Average', np.mean(nested_cv_results['test_accuracy']))\n",
    "    print(name, 'Balanced Accuracy Nested CV Average', np.mean(nested_cv_results['test_balanced_accuracy'] ))\n",
    "    print(name, 'F1 Nested CV Average', np.mean(nested_cv_results['test_f1_weighted'] ))\n",
    "    print(name, 'Precision Nested CV Average', np.mean(nested_cv_results['test_precision_weighted'] ))\n",
    "    print(name, 'Recall Nested CV Average', np.mean(nested_cv_results['test_recall_weighted'] ))\n",
    "    model.fit(X_train, Y_train)\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print('Non-nested CV Results:')\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(name, 'Train accuracy:', accuracy_score(Y_train, y_pred_train), 'Test accuracy:', accuracy_score(Y_test, y_pred))\n",
    "    print(name, 'Train balanced accuracy:', balanced_accuracy_score(Y_train, y_pred_train), 'Test balanced accuracy:', balanced_accuracy_score(Y_test, y_pred))\n",
    "    print(name, 'Train F1', f1_score(Y_train, y_pred_train, average='weighted'), 'Test F1:', f1_score(Y_test, y_pred, average='weighted'))\n",
    "    print(name, 'Train recall:', recall_score(Y_train, y_pred_train, average='weighted'),'Test recall:', recall_score(Y_test, y_pred,average='weighted'))\n",
    "    print(name, 'Train precision:', precision_score(Y_train, y_pred_train,average='weighted'), 'Test precision:', precision_score(Y_test, y_pred,average='weighted'))\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "print('All balanced accuracy results:', results) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model benchmarking - BorutaShap feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boruta_sel = pd.read_csv(\"2021-11-19_selected_features_training_data.csv\", header=0)\n",
    "X_boruta_sel.columns = [\n",
    "    regex.sub(\"_\", col) if any(x in str(col) for x in set((\"[\", \"]\", \"<\"))) else col\n",
    "    for col in X_boruta_sel.columns.values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, the shape of X: (243, 8)\n",
      "Before OverSampling, the shape of y: (243,) \n",
      "\n",
      "After OverSampling, the shape of X: (447, 8)\n",
      "After OverSampling, the shape of y: (447,) \n",
      "\n",
      "After OverSampling, counts of label '1': 149\n",
      "After OverSampling, counts of label '2': 149\n",
      "After OverSampling, counts of label '3': 149\n"
     ]
    }
   ],
   "source": [
    "print('Before OverSampling, the shape of X: {}'.format(X_boruta_sel.shape))\n",
    "print('Before OverSampling, the shape of y: {} \\n'.format(Y2.shape))\n",
    "\n",
    "sm = SMOTE(random_state=seed)\n",
    "X_boruta_sel, Y2 = sm.fit_resample(X_boruta_sel, Y2)\n",
    "\n",
    "print('After OverSampling, the shape of X: {}'.format(X_boruta_sel.shape))\n",
    "print('After OverSampling, the shape of y: {} \\n'.format(Y2.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(Y2==1)))\n",
    "print(\"After OverSampling, counts of label '2': {}\".format(sum(Y2==2)))\n",
    "print(\"After OverSampling, counts of label '3': {}\".format(sum(Y2==3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_boruta, X_test_boruta, Y_train_boruta, Y_test_boruta = train_test_split(X_boruta_sel, Y2, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Nested CV results for all scores: \n",
      " {'fit_time': array([71.16217709, 61.01804209, 58.0935061 , 56.19244814, 56.32305813]), 'score_time': array([0.00542712, 0.0054822 , 0.00525498, 0.00480199, 0.00499487]), 'test_accuracy': array([0.81111111, 0.76666667, 0.83146067, 0.88764045, 0.87640449]), 'test_balanced_accuracy': array([0.80479735, 0.79233512, 0.83176471, 0.88839286, 0.86911232]), 'test_f1_weighted': array([0.80632035, 0.75945479, 0.83234129, 0.88681636, 0.8771488 ]), 'test_precision_weighted': array([0.81329778, 0.76972222, 0.83577124, 0.8863504 , 0.88083033]), 'test_recall_weighted': array([0.81111111, 0.76666667, 0.83146067, 0.88764045, 0.87640449])} \n",
      "\n",
      "XGB Accuracy Nested CV Average 0.8346566791510612\n",
      "XGB Balanced Accuracy Nested CV Average 0.8372804701829535\n",
      "XGB F1 Nested CV Average 0.8324163155814748\n",
      "XGB Precision Nested CV Average 0.8371943936813204\n",
      "XGB Recall Nested CV Average 0.8346566791510612\n",
      "Best Parameters: \n",
      "OrderedDict([('learning_rate', 0.328070202737032), ('max_depth', 4), ('n_estimators', 50), ('reg_alpha', 1), ('reg_lambda', 1)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "XGB Train accuracy: 1.0 Test accuracy: 0.8666666666666667\n",
      "XGB Train balanced accuracy: 1.0 Test balanced accuracy: 0.8647642679900743\n",
      "XGB Train F1 1.0 Test F1: 0.8638188608776843\n",
      "XGB Train recall: 1.0 Test recall: 0.8666666666666667\n",
      "XGB Train precision: 1.0 Test precision: 0.8703068783068784\n",
      "\n",
      "\n",
      "RF Nested CV results for all scores: \n",
      " {'fit_time': array([67.09625602, 77.389081  , 65.492558  , 72.11250401, 62.83909202]), 'score_time': array([0.00781012, 0.00743103, 0.00626493, 0.00787997, 0.00729179]), 'test_accuracy': array([0.81111111, 0.78888889, 0.79775281, 0.87640449, 0.88764045]), 'test_balanced_accuracy': array([0.80479735, 0.81134878, 0.80941176, 0.87946429, 0.8754529 ]), 'test_f1_weighted': array([0.80685739, 0.78707647, 0.79497846, 0.87539771, 0.88764045]), 'test_precision_weighted': array([0.81090038, 0.78709891, 0.81805357, 0.87662405, 0.88764045]), 'test_recall_weighted': array([0.81111111, 0.78888889, 0.79775281, 0.87640449, 0.88764045])} \n",
      "\n",
      "RF Accuracy Nested CV Average 0.8323595505617977\n",
      "RF Balanced Accuracy Nested CV Average 0.8360950168184719\n",
      "RF F1 Nested CV Average 0.8303900978345456\n",
      "RF Precision Nested CV Average 0.8360634718651333\n",
      "RF Recall Nested CV Average 0.8323595505617977\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'entropy'), ('max_depth', 4), ('max_features', 'auto'), ('n_estimators', 43)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "RF Train accuracy: 0.9439775910364145 Test accuracy: 0.8444444444444444\n",
      "RF Train balanced accuracy: 0.9446511414266685 Test balanced accuracy: 0.8349875930521091\n",
      "RF Train F1 0.9439775910364145 Test F1: 0.8433433923279776\n",
      "RF Train recall: 0.9439775910364145 Test recall: 0.8444444444444444\n",
      "RF Train precision: 0.9439775910364145 Test precision: 0.8425490196078431\n",
      "\n",
      "\n",
      "GB Nested CV results for all scores: \n",
      " {'fit_time': array([94.342242  , 95.58127618, 87.07381296, 99.93185997, 81.88932991]), 'score_time': array([0.00372696, 0.00500894, 0.00493288, 0.00397301, 0.00418806]), 'test_accuracy': array([0.87777778, 0.81111111, 0.84269663, 0.87640449, 0.86516854]), 'test_balanced_accuracy': array([0.87758478, 0.83125371, 0.85215686, 0.8764881 , 0.85523231]), 'test_f1_weighted': array([0.87725047, 0.80948472, 0.84305825, 0.87536972, 0.86691276]), 'test_precision_weighted': array([0.89250842, 0.80976148, 0.86228753, 0.87536471, 0.86964842]), 'test_recall_weighted': array([0.87777778, 0.81111111, 0.84269663, 0.87640449, 0.86516854])} \n",
      "\n",
      "GB Accuracy Nested CV Average 0.8546317103620474\n",
      "GB Balanced Accuracy Nested CV Average 0.8585431525431731\n",
      "GB F1 Nested CV Average 0.8544151827326182\n",
      "GB Precision Nested CV Average 0.8619141108646364\n",
      "GB Recall Nested CV Average 0.8546317103620474\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'friedman_mse'), ('learning_rate', 0.2805312174298497), ('max_depth', 3), ('max_features', 'log2'), ('n_estimators', 50)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "GB Train accuracy: 1.0 Test accuracy: 0.8777777777777778\n",
      "GB Train balanced accuracy: 1.0 Test balanced accuracy: 0.8775847808105873\n",
      "GB Train F1 1.0 Test F1: 0.8772504708097928\n",
      "GB Train recall: 1.0 Test recall: 0.8777777777777778\n",
      "GB Train precision: 1.0 Test precision: 0.8925084175084176\n",
      "\n",
      "\n",
      "DT Nested CV results for all scores: \n",
      " {'fit_time': array([46.10029387, 48.82761288, 54.09260917, 51.58186412, 61.28165317]), 'score_time': array([0.00356293, 0.00383115, 0.00420499, 0.00371194, 0.00384688]), 'test_accuracy': array([0.78888889, 0.73333333, 0.75280899, 0.86516854, 0.76404494]), 'test_balanced_accuracy': array([0.7880793 , 0.76143791, 0.74196078, 0.86607143, 0.77432332]), 'test_f1_weighted': array([0.78310654, 0.73131826, 0.74890191, 0.86516854, 0.76286367]), 'test_precision_weighted': array([0.80960317, 0.73007898, 0.74687249, 0.86516854, 0.83494712]), 'test_recall_weighted': array([0.78888889, 0.73333333, 0.75280899, 0.86516854, 0.76404494])} \n",
      "\n",
      "DT Accuracy Nested CV Average 0.7808489388264669\n",
      "DT Balanced Accuracy Nested CV Average 0.7863745483746515\n",
      "DT F1 Nested CV Average 0.7782717846881919\n",
      "DT Precision Nested CV Average 0.7973340618614428\n",
      "DT Recall Nested CV Average 0.7808489388264669\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'entropy'), ('max_depth', 3), ('max_features', 'log2')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "DT Train accuracy: 0.7983193277310925 Test accuracy: 0.7888888888888889\n",
      "DT Train balanced accuracy: 0.7984161942729888 Test balanced accuracy: 0.7880793042083365\n",
      "DT Train F1 0.7946204764820809 Test F1: 0.7831065395192686\n",
      "DT Train recall: 0.7983193277310925 Test recall: 0.7888888888888889\n",
      "DT Train precision: 0.814956393154274 Test precision: 0.8096031746031744\n",
      "\n",
      "\n",
      "ExtraTrees Nested CV results for all scores: \n",
      " {'fit_time': array([71.21580482, 60.35731697, 66.93418002, 61.00220394, 67.88109112]), 'score_time': array([0.00549817, 0.00607991, 0.00656509, 0.00646806, 0.00593996]), 'test_accuracy': array([0.75555556, 0.67777778, 0.70786517, 0.75280899, 0.79775281]), 'test_balanced_accuracy': array([0.75080833, 0.71182412, 0.71738562, 0.75826149, 0.78804348]), 'test_f1_weighted': array([0.76081593, 0.6667988 , 0.71014648, 0.75131086, 0.79335117]), 'test_precision_weighted': array([0.77092201, 0.66794974, 0.7241301 , 0.7538122 , 0.80414832]), 'test_recall_weighted': array([0.75555556, 0.67777778, 0.70786517, 0.75280899, 0.79775281])} \n",
      "\n",
      "ExtraTrees Accuracy Nested CV Average 0.7383520599250936\n",
      "ExtraTrees Balanced Accuracy Nested CV Average 0.7452646096942196\n",
      "ExtraTrees F1 Nested CV Average 0.7364846466511542\n",
      "ExtraTrees Precision Nested CV Average 0.7441924747588986\n",
      "ExtraTrees Recall Nested CV Average 0.7383520599250936\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'gini'), ('max_depth', 4), ('max_features', 'log2'), ('n_estimators', 24)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "ExtraTrees Train accuracy: 0.7450980392156863 Test accuracy: 0.7555555555555555\n",
      "ExtraTrees Train balanced accuracy: 0.7444797650781885 Test balanced accuracy: 0.7508083314534928\n",
      "ExtraTrees Train F1 0.7494536415190003 Test F1: 0.7591633597883599\n",
      "ExtraTrees Train recall: 0.7450980392156863 Test recall: 0.7555555555555555\n",
      "ExtraTrees Train precision: 0.7669556935359618 Test precision: 0.7658682486713632\n",
      "\n",
      "\n",
      "All balanced accuracy results: [array([0.78163772, 0.74272133, 0.74156863, 0.80059524, 0.81748188]), array([0.8502895 , 0.80873957, 0.81568627, 0.86309524, 0.83727621]), array([0.76261373, 0.81313131, 0.80104575, 0.79613095, 0.75274403]), array([0.80479735, 0.80213904, 0.85490196, 0.8764881 , 0.84481564]), array([0.80479735, 0.81224005, 0.82196078, 0.85714286, 0.86911232]), array([0.79197684, 0.83125371, 0.81921569, 0.87946429, 0.82110507]), array([0.86476427, 0.84135472, 0.85215686, 0.90029762, 0.86972506]), array([0.7880793 , 0.76143791, 0.74196078, 0.86607143, 0.77432332]), array([0.74342682, 0.71182412, 0.76183007, 0.74825534, 0.76313406])]\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    nested_cv_results = model_selection.cross_validate(model, X_boruta_sel , Y2, cv=outer_cv, scoring=scoring, error_score=\"raise\")\n",
    "    nested_cv_results2 = model_selection.cross_val_score(model, X_boruta_sel , Y2, cv=outer_cv, scoring='balanced_accuracy', error_score=\"raise\")\n",
    "    results.append(nested_cv_results2)\n",
    "    names.append(name)\n",
    "    print(name, 'Nested CV results for all scores:', '\\n', nested_cv_results, '\\n')\n",
    "    print(name, 'Accuracy Nested CV Average', np.mean(nested_cv_results['test_accuracy']))\n",
    "    print(name, 'Balanced Accuracy Nested CV Average', np.mean(nested_cv_results['test_balanced_accuracy'] ))\n",
    "    print(name, 'F1 Nested CV Average', np.mean(nested_cv_results['test_f1_weighted'] ))\n",
    "    print(name, 'Precision Nested CV Average', np.mean(nested_cv_results['test_precision_weighted'] ))\n",
    "    print(name, 'Recall Nested CV Average', np.mean(nested_cv_results['test_recall_weighted'] ))\n",
    "    model.fit(X_train_boruta, Y_train_boruta)\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print('Non-nested CV Results:')\n",
    "    y_pred_train = model.predict(X_train_boruta)\n",
    "    y_pred = model.predict(X_test_boruta)\n",
    "    print(name, 'Train accuracy:', accuracy_score(Y_train_boruta, y_pred_train), 'Test accuracy:', accuracy_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train balanced accuracy:', balanced_accuracy_score(Y_train, y_pred_train), 'Test balanced accuracy:', balanced_accuracy_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train F1', f1_score(Y_train_boruta, y_pred_train, average='weighted'), 'Test F1:', f1_score(Y_test_boruta, y_pred, average='weighted'))\n",
    "    print(name, 'Train recall:', recall_score(Y_train_boruta, y_pred_train, average='weighted'),'Test recall:', recall_score(Y_test_boruta, y_pred,average='weighted'))\n",
    "    print(name, 'Train precision:', precision_score(Y_train_boruta, y_pred_train,average='weighted'), 'Test precision:', precision_score(Y_test_boruta, y_pred,average='weighted'))\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "print('All balanced accuracy results:', results)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_boruta_sel = MinMaxScaler().fit_transform(X_boruta_sel)\n",
    "X_train_boruta, X_test_boruta, Y_train_boruta, Y_test_boruta = train_test_split(X2_boruta_sel, Y2, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Nested CV results for all scores: \n",
      " {'fit_time': array([46.83808827, 47.92462993, 48.16604519, 52.48140407, 44.60405922]), 'score_time': array([0.00366807, 0.00394177, 0.00403595, 0.00392318, 0.00411892]), 'test_accuracy': array([0.8       , 0.68888889, 0.76404494, 0.73033708, 0.85393258]), 'test_balanced_accuracy': array([0.78577337, 0.7228164 , 0.78      , 0.74297003, 0.83258738]), 'test_f1_weighted': array([0.7960436 , 0.67814754, 0.75381585, 0.71048137, 0.85078389]), 'test_precision_weighted': array([0.79424991, 0.68585637, 0.78423075, 0.74502717, 0.8501133 ]), 'test_recall_weighted': array([0.8       , 0.68888889, 0.76404494, 0.73033708, 0.85393258])} \n",
      "\n",
      "KNN Accuracy Nested CV Average 0.7674406991260925\n",
      "KNN Balanced Accuracy Nested CV Average 0.7728294362650873\n",
      "KNN F1 Nested CV Average 0.7578544496047168\n",
      "KNN Precision Nested CV Average 0.7718955011836707\n",
      "KNN Recall Nested CV Average 0.7674406991260925\n",
      "Best Parameters: \n",
      "OrderedDict([('metric', 'manhattan'), ('n_neighbors', 7), ('weights', 'distance')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "KNN Train accuracy: 1.0 Test accuracy: 0.8\n",
      "KNN Train balanced accuracy: 1.0 Test balanced accuracy: 0.7857733664185277\n",
      "KNN Train F1 1.0 Test F1: 0.7960436026262357\n",
      "KNN Train recall: 1.0 Test recall: 0.8\n",
      "KNN Train precision: 1.0 Test precision: 0.7942499137336093\n",
      "\n",
      "\n",
      "SVC Nested CV results for all scores: \n",
      " {'fit_time': array([49.47072792, 44.19580007, 47.82993507, 47.2114861 , 47.84331107]), 'score_time': array([0.00412393, 0.00529218, 0.00394106, 0.00523806, 0.00458288]), 'test_accuracy': array([0.81111111, 0.73333333, 0.84269663, 0.79775281, 0.86516854]), 'test_balanced_accuracy': array([0.8006617 , 0.76232917, 0.84732026, 0.80141626, 0.85238171]), 'test_f1_weighted': array([0.80898259, 0.7262037 , 0.84277466, 0.79624815, 0.8653543 ]), 'test_precision_weighted': array([0.8089418 , 0.73169231, 0.84760429, 0.79559602, 0.86584951]), 'test_recall_weighted': array([0.81111111, 0.73333333, 0.84269663, 0.79775281, 0.86516854])} \n",
      "\n",
      "SVC Accuracy Nested CV Average 0.8100124843945068\n",
      "SVC Balanced Accuracy Nested CV Average 0.8128218218263843\n",
      "SVC F1 Nested CV Average 0.8079126804123516\n",
      "SVC Precision Nested CV Average 0.8099367845780865\n",
      "SVC Recall Nested CV Average 0.8100124843945068\n",
      "Best Parameters: \n",
      "OrderedDict([('C', 681.3426161935705), ('gamma', 'scale'), ('kernel', 'rbf')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "SVC Train accuracy: 0.9803921568627451 Test accuracy: 0.8111111111111111\n",
      "SVC Train balanced accuracy: 0.9808001469845208 Test balanced accuracy: 0.8006617038875103\n",
      "SVC Train F1 0.9803477482639696 Test F1: 0.808982591011034\n",
      "SVC Train recall: 0.9803921568627451 Test recall: 0.8111111111111111\n",
      "SVC Train precision: 0.9804627834039598 Test precision: 0.808941798941799\n",
      "\n",
      "\n",
      "LR Nested CV results for all scores: \n",
      " {'fit_time': array([51.01245618, 47.78402925, 52.34014106, 50.25826001, 46.96593404]), 'score_time': array([0.00269794, 0.00306368, 0.00289583, 0.00280786, 0.00283289]), 'test_accuracy': array([0.66666667, 0.61111111, 0.65168539, 0.59550562, 0.62921348]), 'test_balanced_accuracy': array([0.66195453, 0.63543362, 0.66666667, 0.60555213, 0.63445759]), 'test_f1_weighted': array([0.67687682, 0.59310027, 0.65238764, 0.59011881, 0.6457307 ]), 'test_precision_weighted': array([0.69986485, 0.60391986, 0.67193686, 0.59949779, 0.70663186]), 'test_recall_weighted': array([0.66666667, 0.61111111, 0.65168539, 0.59550562, 0.62921348])} \n",
      "\n",
      "LR Accuracy Nested CV Average 0.63083645443196\n",
      "LR Balanced Accuracy Nested CV Average 0.6408129083414069\n",
      "LR F1 Nested CV Average 0.6316428477846674\n",
      "LR Precision Nested CV Average 0.6563702456988623\n",
      "LR Recall Nested CV Average 0.63083645443196\n",
      "Best Parameters: \n",
      "OrderedDict([('C', 5.0), ('max_iter', 500), ('penalty', 'l2')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "LR Train accuracy: 0.6694677871148459 Test accuracy: 0.6666666666666666\n",
      "LR Train balanced accuracy: 0.6712916106367377 Test balanced accuracy: 0.659886708273805\n",
      "LR Train F1 0.6724017077376077 Test F1: 0.6761132373488852\n",
      "LR Train recall: 0.6694677871148459 Test recall: 0.6666666666666666\n",
      "LR Train precision: 0.6777326469987408 Test precision: 0.6934368313678658\n",
      "\n",
      "\n",
      "All balanced accuracy results: [array([0.78163772, 0.74272133, 0.74156863, 0.80059524, 0.81748188]), array([0.8502895 , 0.80873957, 0.81568627, 0.86309524, 0.83727621]), array([0.76261373, 0.81313131, 0.80104575, 0.79613095, 0.75274403]), array([0.80479735, 0.80213904, 0.85490196, 0.8764881 , 0.84481564]), array([0.80479735, 0.81224005, 0.82196078, 0.85714286, 0.86911232]), array([0.79197684, 0.83125371, 0.81921569, 0.87946429, 0.82110507]), array([0.86476427, 0.84135472, 0.85215686, 0.90029762, 0.86972506]), array([0.7880793 , 0.76143791, 0.74196078, 0.86607143, 0.77432332]), array([0.74342682, 0.71182412, 0.76183007, 0.74825534, 0.76313406]), array([0.78577337, 0.7228164 , 0.78      , 0.74297003, 0.83258738]), array([0.8006617 , 0.76232917, 0.83751634, 0.83117816, 0.82339621]), array([0.66195453, 0.63543362, 0.66666667, 0.60555213, 0.63445759])]\n"
     ]
    }
   ],
   "source": [
    "for name, model in othermodels:\n",
    "    nested_cv_results = model_selection.cross_validate(model, X2_boruta_sel , Y2, cv=outer_cv, scoring=scoring, error_score=\"raise\")\n",
    "    nested_cv_results2 = model_selection.cross_val_score(model, X2_boruta_sel , Y2, cv=outer_cv, scoring='balanced_accuracy', error_score=\"raise\")\n",
    "    results.append(nested_cv_results2)\n",
    "    names.append(name)\n",
    "    print(name, 'Nested CV results for all scores:', '\\n', nested_cv_results, '\\n')\n",
    "    print(name, 'Accuracy Nested CV Average', np.mean(nested_cv_results['test_accuracy']))\n",
    "    print(name, 'Balanced Accuracy Nested CV Average', np.mean(nested_cv_results['test_balanced_accuracy'] ))\n",
    "    print(name, 'F1 Nested CV Average', np.mean(nested_cv_results['test_f1_weighted'] ))\n",
    "    print(name, 'Precision Nested CV Average', np.mean(nested_cv_results['test_precision_weighted'] ))\n",
    "    print(name, 'Recall Nested CV Average', np.mean(nested_cv_results['test_recall_weighted'] ))\n",
    "    model.fit(X_train_boruta, Y_train_boruta)\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print('Non-nested CV Results:')\n",
    "    y_pred_train = model.predict(X_train_boruta)\n",
    "    y_pred = model.predict(X_test_boruta)\n",
    "    print(name, 'Train accuracy:', accuracy_score(Y_train_boruta, y_pred_train), 'Test accuracy:', accuracy_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train balanced accuracy:', balanced_accuracy_score(Y_train, y_pred_train), 'Test balanced accuracy:', balanced_accuracy_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train F1', f1_score(Y_train_boruta, y_pred_train, average='weighted'), 'Test F1:', f1_score(Y_test_boruta, y_pred, average='weighted'))\n",
    "    print(name, 'Train recall:', recall_score(Y_train_boruta, y_pred_train, average='weighted'),'Test recall:', recall_score(Y_test_boruta, y_pred,average='weighted'))\n",
    "    print(name, 'Train precision:', precision_score(Y_train_boruta, y_pred_train,average='weighted'), 'Test precision:', precision_score(Y_test_boruta, y_pred,average='weighted'))\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "print('All balanced accuracy results:', results)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier(random_state=seed, num_class=3, objective='multi:softmax', eval_metric='mlogloss', learning_rate=0.328070202737032,\n",
    "                           max_depth=4, n_estimators=50, reg_alpha=1, reg_lambda=1) \n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=seed, criterion='friedman_mse', learning_rate=0.2805312174298497, max_depth=3, max_features='log2',\n",
    "                               n_estimators=50)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=seed, criterion='entropy', max_depth=4, max_features='auto', n_estimators=43)\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=seed, criterion='entropy', max_depth=3, max_features='log2')\n",
    "\n",
    "extra = ExtraTreesClassifier(random_state=seed, criterion='gini', max_depth=4, max_features='log2', n_estimators=24)\n",
    "\n",
    "knn = KNeighborsClassifier(metric='manhattan', n_neighbors=7, weights='distance')\n",
    "\n",
    "svm = SVC(C=681.3426161935705, gamma='scale', kernel='rbf')\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear', multi_class='auto', random_state=seed, C=5.0, max_iter=500, penalty='l2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.88      0.71      0.79        31\n",
      "    probable       0.77      0.88      0.82        26\n",
      "least likely       0.94      1.00      0.97        33\n",
      "\n",
      "    accuracy                           0.87        90\n",
      "   macro avg       0.86      0.86      0.86        90\n",
      "weighted avg       0.87      0.87      0.86        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['most likely', 'probable', 'least likely']\n",
    "xgb.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(xgb.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.92      0.71      0.80        31\n",
      "    probable       0.73      0.92      0.81        26\n",
      "least likely       1.00      1.00      1.00        33\n",
      "\n",
      "    accuracy                           0.88        90\n",
      "   macro avg       0.88      0.88      0.87        90\n",
      "weighted avg       0.89      0.88      0.88        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(gb.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.80      0.77      0.79        31\n",
      "    probable       0.73      0.73      0.73        26\n",
      "least likely       0.97      1.00      0.99        33\n",
      "\n",
      "    accuracy                           0.84        90\n",
      "   macro avg       0.83      0.83      0.83        90\n",
      "weighted avg       0.84      0.84      0.84        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(rf.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.85      0.55      0.67        31\n",
      "    probable       0.63      0.85      0.72        26\n",
      "least likely       0.91      0.97      0.94        33\n",
      "\n",
      "    accuracy                           0.79        90\n",
      "   macro avg       0.80      0.79      0.78        90\n",
      "weighted avg       0.81      0.79      0.78        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(dt.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.79      0.74      0.77        31\n",
      "    probable       0.60      0.69      0.64        26\n",
      "least likely       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.76        90\n",
      "   macro avg       0.75      0.75      0.75        90\n",
      "weighted avg       0.77      0.76      0.76        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extra.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(extra.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.80      0.77      0.79        31\n",
      "    probable       0.84      0.62      0.71        26\n",
      "least likely       0.80      1.00      0.89        33\n",
      "\n",
      "    accuracy                           0.81        90\n",
      "   macro avg       0.82      0.80      0.80        90\n",
      "weighted avg       0.81      0.81      0.80        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(knn.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.80      0.77      0.79        31\n",
      "    probable       0.70      0.62      0.65        26\n",
      "least likely       0.89      1.00      0.94        33\n",
      "\n",
      "    accuracy                           0.81        90\n",
      "   macro avg       0.80      0.80      0.79        90\n",
      "weighted avg       0.80      0.81      0.81        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(svm.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.74      0.65      0.69        31\n",
      "    probable       0.47      0.62      0.53        26\n",
      "least likely       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.68        90\n",
      "   macro avg       0.69      0.67      0.68        90\n",
      "weighted avg       0.71      0.68      0.69        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(lr.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
