{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Machine Learning for Prioritizing Blood Pressure Genes__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import sort\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import statsmodels.api as sm\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "import statsmodels.stats.api as sms\n",
    "import xgboost\n",
    "from sklearn import datasets, metrics, model_selection, preprocessing\n",
    "from sklearn.ensemble import (\n",
    "    BaggingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    KFold,\n",
    "    RandomizedSearchCV,\n",
    "    RepeatedKFold,\n",
    "    cross_val_predict,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    learning_curve,\n",
    "    train_test_split,\n",
    "    validation_curve,\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.plots import plot_convergence\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.mpl.rcParams[\"figure.figsize\"] = (15.0, 9.0)\n",
    "\n",
    "import warnings\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "from warnings import filterwarnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"2021-11-19_training_cleaned.csv\", header=0, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BPlabel_encoded'] = data['BPlabel'].map( {'most likely':1,'probable':2, 'least likely':3})\n",
    "classes_weights_all = class_weight.compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=data[\"BPlabel_encoded\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(243, 103)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data[\"BPlabel_encoded\"] \n",
    "data = data.drop([\"BPlabel\"],1)\n",
    "data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"2021-11-19_imputed_training_data.csv\", header=0)\n",
    "X.columns = [\n",
    "    regex.sub(\"_\", col) if any(x in str(col) for x in set((\"[\", \"]\", \"<\"))) else col\n",
    "    for col in X.columns.values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_weights_train = class_weight.compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=Y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models:\n",
    "- Parameter tuning with Bayesian optimization over hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier(random_state=seed, num_class=3, objective='multi:softmax', eval_metric='mlogloss') \n",
    "xgb_params = {\n",
    "    'max_depth':  (1, 4), #Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit.\n",
    "    'learning_rate': (0.01, 0.5, 'log-uniform'),  #Step size shrinkage used in update to prevents overfitting. After each boosting step, we can directly get the weights of new features\n",
    "    'n_estimators':  (10, 50), #Number of gradient boosted trees. Equivalent to number of boosting rounds.\n",
    "    'reg_alpha':  (1, 10, 'log-uniform'), #L1 regularization term on weights. Increasing this value will make model more conservative.\n",
    "    'reg_lambda':  (1, 10, 'log-uniform')} #L2 regularization term on weights. Increasing this value will make model more conservative.\n",
    "\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=seed)\n",
    "gb_params = {\n",
    "    'learning_rate': (0.01, 0.5),\n",
    "    'max_depth': (1, 4),\n",
    "    \"max_features\":[\"log2\",\"sqrt\", \"auto\"],\n",
    "    \"criterion\": [\"friedman_mse\", \"mse\", \"mae\"],\n",
    "    'n_estimators': (10, 50)\n",
    "    }\n",
    "\n",
    "rf = RandomForestClassifier(random_state=seed)\n",
    "rf_params={'n_estimators': (10, 50), \n",
    "             'max_features': ['auto', 'sqrt', 'log2'],\n",
    "             'max_depth' : (1, 4),\n",
    "             'criterion' :[\"gini\", \"entropy\"]} \n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=seed)\n",
    "dt_params= {\"criterion\": [\"gini\", \"entropy\"],\n",
    "            'max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'max_depth' : (1, 4)}\n",
    "\n",
    "extra = ExtraTreesClassifier(random_state=seed)\n",
    "extra_params ={'n_estimators': (10, 50), \n",
    "             'max_features': ['auto', 'sqrt', 'log2'],\n",
    "             'max_depth' : (1, 4),\n",
    "             'criterion' :[\"gini\", \"entropy\"]}\n",
    "\n",
    "\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append(('XGB', BayesSearchCV(xgb, xgb_params, cv=inner_cv, iid=False, n_jobs=1))) \n",
    "models.append(('RF', BayesSearchCV(rf, rf_params, cv=inner_cv,iid=False, n_jobs=1)))\n",
    "models.append(('GB', BayesSearchCV(gb, gb_params, cv=inner_cv,iid=False, n_jobs=1)))\n",
    "models.append(('DT', BayesSearchCV(dt, dt_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "models.append(('ExtraTrees', BayesSearchCV(extra, extra_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "#models.append(('KNN', BayesSearchCV(knn, knn_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "#models.append(('SVC', BayesSearchCV(svc, svc_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "\n",
    "results = []\n",
    "results1 = []\n",
    "results2 = []\n",
    "results3 = []\n",
    "names = []\n",
    "names2 =[]\n",
    "scoring = ['accuracy', 'balanced_accuracy', 'f1_weighted', \n",
    "          'precision_weighted','recall_weighted'] #https://scikit-learn.org/stable/modules/model_evaluation.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Benchmarking - all features:\n",
    "### Tree-based models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Nested CV results for all scores: \n",
      " {'fit_time': array([68.36431885, 70.71956396, 70.11045504, 73.22160363, 70.91914225]), 'score_time': array([0.00626302, 0.00587416, 0.00563717, 0.00658727, 0.00670791]), 'test_accuracy': array([0.69387755, 0.73469388, 0.83673469, 0.72916667, 0.70833333]), 'test_balanced_accuracy': array([0.65      , 0.68013468, 0.72979798, 0.69347319, 0.62356902]), 'test_f1_weighted': array([0.63798701, 0.71292142, 0.81418853, 0.723557  , 0.67040073]), 'test_precision_weighted': array([0.61451247, 0.70828331, 0.80915609, 0.7232599 , 0.67830882]), 'test_recall_weighted': array([0.69387755, 0.73469388, 0.83673469, 0.72916667, 0.70833333])} \n",
      "\n",
      "XGB Accuracy Nested CV Average 0.7405612244897959\n",
      "XGB Balanced Accuracy Nested CV Average 0.6753949753949754\n",
      "XGB F1 Nested CV Average 0.7118109377196912\n",
      "XGB Precision Nested CV Average 0.7067041202418629\n",
      "XGB Recall Nested CV Average 0.7405612244897959\n",
      "Best Parameters: \n",
      "OrderedDict([('learning_rate', 0.01), ('max_depth', 3), ('n_estimators', 50), ('reg_alpha', 3), ('reg_lambda', 1)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "XGB Train accuracy: 0.8711340206185567 Test accuracy: 0.6938775510204082\n",
      "XGB Train balanced accuracy: 0.7920706744236156 Test balanced accuracy: 0.65\n",
      "XGB Train F1 0.8493559203545618 Test F1: 0.632674888137073\n",
      "XGB Train recall: 0.8711340206185567 Test recall: 0.6938775510204082\n",
      "XGB Train precision: 0.8913110874777783 Test precision: 0.6238095238095238\n",
      "\n",
      "\n",
      "RF Nested CV results for all scores: \n",
      " {'fit_time': array([64.03864908, 57.77561307, 63.7626009 , 66.43826008, 63.12994885]), 'score_time': array([0.00919414, 0.00558019, 0.00835896, 0.00835872, 0.00667095]), 'test_accuracy': array([0.73469388, 0.79591837, 0.79591837, 0.72916667, 0.625     ]), 'test_balanced_accuracy': array([0.61904762, 0.61904762, 0.58333333, 0.60606061, 0.45432099]), 'test_f1_weighted': array([0.63508312, 0.71672313, 0.72479669, 0.63958333, 0.52896825]), 'test_precision_weighted': array([0.57000475, 0.65970574, 0.68011391, 0.59027778, 0.50678295]), 'test_recall_weighted': array([0.73469388, 0.79591837, 0.79591837, 0.72916667, 0.625     ])} \n",
      "\n",
      "RF Accuracy Nested CV Average 0.736139455782313\n",
      "RF Balanced Accuracy Nested CV Average 0.5763620330286997\n",
      "RF F1 Nested CV Average 0.6490309031765596\n",
      "RF Precision Nested CV Average 0.6013770236776882\n",
      "RF Recall Nested CV Average 0.736139455782313\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'entropy'), ('max_depth', 4), ('max_features', 'auto'), ('n_estimators', 50)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "RF Train accuracy: 0.8556701030927835 Test accuracy: 0.7346938775510204\n",
      "RF Train balanced accuracy: 0.7578347578347578 Test balanced accuracy: 0.6190476190476191\n",
      "RF Train F1 0.8351685763833476 Test F1: 0.6350831164921185\n",
      "RF Train recall: 0.8556701030927835 Test recall: 0.7346938775510204\n",
      "RF Train precision: 0.8831615120274913 Test precision: 0.5700047460844804\n",
      "\n",
      "\n",
      "GB Nested CV results for all scores: \n",
      " {'fit_time': array([146.93501115, 104.57793808, 136.63899684, 126.88158107,\n",
      "       105.18512583]), 'score_time': array([0.00625587, 0.00363922, 0.00425601, 0.00477004, 0.00379109]), 'test_accuracy': array([0.73469388, 0.83673469, 0.79591837, 0.79166667, 0.6875    ]), 'test_balanced_accuracy': array([0.70555556, 0.75757576, 0.70959596, 0.73193473, 0.58720539]), 'test_f1_weighted': array([0.70811851, 0.81460716, 0.78434231, 0.77437297, 0.65912698]), 'test_precision_weighted': array([0.69814354, 0.82701324, 0.77570457, 0.78819444, 0.703125  ]), 'test_recall_weighted': array([0.73469388, 0.83673469, 0.79591837, 0.79166667, 0.6875    ])} \n",
      "\n",
      "GB Accuracy Nested CV Average 0.7693027210884353\n",
      "GB Balanced Accuracy Nested CV Average 0.6983734783734784\n",
      "GB F1 Nested CV Average 0.7481135864329577\n",
      "GB Precision Nested CV Average 0.7584361585689616\n",
      "GB Recall Nested CV Average 0.7693027210884353\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'friedman_mse'), ('learning_rate', 0.5), ('max_depth', 4), ('max_features', 'sqrt'), ('n_estimators', 44)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "GB Train accuracy: 1.0 Test accuracy: 0.6530612244897959\n",
      "GB Train balanced accuracy: 1.0 Test balanced accuracy: 0.6277777777777778\n",
      "GB Train F1 1.0 Test F1: 0.620755184664959\n",
      "GB Train recall: 1.0 Test recall: 0.6530612244897959\n",
      "GB Train precision: 1.0 Test precision: 0.5976676384839651\n",
      "\n",
      "\n",
      "DT Nested CV results for all scores: \n",
      " {'fit_time': array([52.98843479, 46.17097592, 49.65538478, 47.08702207, 53.68135881]), 'score_time': array([0.00500607, 0.00405812, 0.00449324, 0.00528193, 0.00437999]), 'test_accuracy': array([0.71428571, 0.69387755, 0.75510204, 0.70833333, 0.58333333]), 'test_balanced_accuracy': array([0.57142857, 0.63299663, 0.5       , 0.61072261, 0.40561167]), 'test_f1_weighted': array([0.6154624 , 0.65856806, 0.67870225, 0.63456284, 0.50826106]), 'test_precision_weighted': array([0.56029685, 0.65956383, 0.65714286, 0.5797619 , 0.53916836]), 'test_recall_weighted': array([0.71428571, 0.69387755, 0.75510204, 0.70833333, 0.58333333])} \n",
      "\n",
      "DT Accuracy Nested CV Average 0.6909863945578232\n",
      "DT Balanced Accuracy Nested CV Average 0.5441518974852307\n",
      "DT F1 Nested CV Average 0.6191113231236126\n",
      "DT Precision Nested CV Average 0.5991867587759421\n",
      "DT Recall Nested CV Average 0.6909863945578232\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'gini'), ('max_depth', 2), ('max_features', 'log2')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "DT Train accuracy: 0.7010309278350515 Test accuracy: 0.7142857142857143\n",
      "DT Train balanced accuracy: 0.49074074074074076 Test balanced accuracy: 0.5714285714285715\n",
      "DT Train F1 0.612251402345742 Test F1: 0.6154624011766869\n",
      "DT Train recall: 0.7010309278350515 Test recall: 0.7142857142857143\n",
      "DT Train precision: 0.5979672665851243 Test precision: 0.5602968460111317\n",
      "\n",
      "\n",
      "ExtraTrees Nested CV results for all scores: \n",
      " {'fit_time': array([65.37239003, 64.97728777, 63.42480516, 54.00462198, 59.43648386]), 'score_time': array([0.00908494, 0.00873303, 0.00705481, 0.00810003, 0.0082953 ]), 'test_accuracy': array([0.71428571, 0.75510204, 0.75510204, 0.6875    , 0.58333333]), 'test_balanced_accuracy': array([0.57142857, 0.52380952, 0.5       , 0.54545455, 0.38765432]), 'test_f1_weighted': array([0.6154624 , 0.67375482, 0.67870225, 0.59863875, 0.47035256]), 'test_precision_weighted': array([0.56029685, 0.63673469, 0.65714286, 0.5726626 , 0.46388889]), 'test_recall_weighted': array([0.71428571, 0.75510204, 0.75510204, 0.6875    , 0.58333333])} \n",
      "\n",
      "ExtraTrees Accuracy Nested CV Average 0.6990646258503401\n",
      "ExtraTrees Balanced Accuracy Nested CV Average 0.505669392336059\n",
      "ExtraTrees F1 Nested CV Average 0.6073821565426043\n",
      "ExtraTrees Precision Nested CV Average 0.578145177509289\n",
      "ExtraTrees Recall Nested CV Average 0.6990646258503401\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'entropy'), ('max_depth', 4), ('max_features', 'sqrt'), ('n_estimators', 13)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "ExtraTrees Train accuracy: 0.7680412371134021 Test accuracy: 0.7142857142857143\n",
      "ExtraTrees Train balanced accuracy: 0.603988603988604 Test balanced accuracy: 0.5714285714285715\n",
      "ExtraTrees Train F1 0.7304659359645648 Test F1: 0.6154624011766869\n",
      "ExtraTrees Train recall: 0.7680412371134021 Test recall: 0.7142857142857143\n",
      "ExtraTrees Train precision: 0.8316884586371637 Test precision: 0.5602968460111317\n",
      "\n",
      "\n",
      "All balanced accuracy results: [array([0.64444444, 0.65319865, 0.78156566, 0.76223776, 0.62356902]), array([0.63888889, 0.67003367, 0.77146465, 0.73659674, 0.62356902]), array([0.61904762, 0.61904762, 0.58333333, 0.63636364, 0.52098765]), array([0.66111111, 0.72053872, 0.77146465, 0.71445221, 0.54826038]), array([0.57142857, 0.63299663, 0.5       , 0.61072261, 0.40561167]), array([0.57142857, 0.52380952, 0.5       , 0.56293706, 0.38765432])]\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    nested_cv_results = model_selection.cross_validate(model, X , Y, cv=outer_cv, scoring=scoring, error_score=\"raise\")\n",
    "    nested_cv_results2 = model_selection.cross_val_score(model, X , Y, cv=outer_cv, scoring='balanced_accuracy', error_score=\"raise\")\n",
    "    results.append(nested_cv_results2)\n",
    "    names.append(name)\n",
    "    print(name, 'Nested CV results for all scores:', '\\n', nested_cv_results, '\\n')\n",
    "    print(name, 'Accuracy Nested CV Average', np.mean(nested_cv_results['test_accuracy']))\n",
    "    print(name, 'Balanced Accuracy Nested CV Average', np.mean(nested_cv_results['test_balanced_accuracy'] ))\n",
    "    print(name, 'F1 Nested CV Average', np.mean(nested_cv_results['test_f1_weighted'] ))\n",
    "    print(name, 'Precision Nested CV Average', np.mean(nested_cv_results['test_precision_weighted'] ))\n",
    "    print(name, 'Recall Nested CV Average', np.mean(nested_cv_results['test_recall_weighted'] ))\n",
    "    model.fit(X_train, Y_train, sample_weight)\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print('Non-nested CV Results:')\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(name, 'Train accuracy:', accuracy_score(Y_train, y_pred_train), 'Test accuracy:', accuracy_score(Y_test, y_pred))\n",
    "    print(name, 'Train balanced accuracy:', balanced_accuracy_score(Y_train, y_pred_train), 'Test balanced accuracy:', balanced_accuracy_score(Y_test, y_pred))\n",
    "    print(name, 'Train F1', f1_score(Y_train, y_pred_train, average='weighted'), 'Test F1:', f1_score(Y_test, y_pred, average='weighted'))\n",
    "    print(name, 'Train recall:', recall_score(Y_train, y_pred_train, average='weighted'),'Test recall:', recall_score(Y_test, y_pred,average='weighted'))\n",
    "    print(name, 'Train precision:', precision_score(Y_train, y_pred_train,average='weighted'), 'Test precision:', precision_score(Y_test, y_pred,average='weighted'))\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "print('All balanced accuracy results:', results)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: \n",
      "OrderedDict([('learning_rate', 0.14296452942858345), ('max_depth', 4), ('n_estimators', 49), ('reg_alpha', 1), ('reg_lambda', 9)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "XGB Train accuracy: 0.9948453608247423 Test accuracy: 0.6326530612244898\n",
      "XGB Train balanced accuracy: 0.9971988795518207 Test balanced accuracy: 0.6666666666666666\n",
      "XGB Train F1 0.9948697918063256 Test F1: 0.6229400030688967\n",
      "XGB Train recall: 0.9948453608247423 Test recall: 0.6326530612244898\n",
      "XGB Train precision: 0.9949846753970466 Test precision: 0.6392813535670678\n",
      "\n",
      "\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'entropy'), ('max_depth', 4), ('max_features', 'sqrt'), ('n_estimators', 50)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "RF Train accuracy: 0.9742268041237113 Test accuracy: 0.7551020408163265\n",
      "RF Train balanced accuracy: 0.9687567334626158 Test balanced accuracy: 0.6833333333333332\n",
      "RF Train F1 0.9741133645287551 Test F1: 0.6829593949380994\n",
      "RF Train recall: 0.9742268041237113 Test recall: 0.7551020408163265\n",
      "RF Train precision: 0.974084373304395 Test precision: 0.7027080062794349\n",
      "\n",
      "\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'mae'), ('learning_rate', 0.3460975179987179), ('max_depth', 4), ('max_features', 'sqrt'), ('n_estimators', 50)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "GB Train accuracy: 1.0 Test accuracy: 0.673469387755102\n",
      "GB Train balanced accuracy: 1.0 Test balanced accuracy: 0.6555555555555556\n",
      "GB Train F1 1.0 Test F1: 0.6440744718940209\n",
      "GB Train recall: 1.0 Test recall: 0.673469387755102\n",
      "GB Train precision: 1.0 Test precision: 0.6271437146287087\n",
      "\n",
      "\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'entropy'), ('max_depth', 3), ('max_features', 'log2')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "DT Train accuracy: 0.5979381443298969 Test accuracy: 0.5510204081632653\n",
      "DT Train balanced accuracy: 0.631407263760205 Test balanced accuracy: 0.565873015873016\n",
      "DT Train F1 0.5999656357388315 Test F1: 0.5723158828748891\n",
      "DT Train recall: 0.5979381443298969 Test recall: 0.5510204081632653\n",
      "DT Train precision: 0.664831553361654 Test precision: 0.6423104956268222\n",
      "\n",
      "\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'gini'), ('max_depth', 4), ('max_features', 'auto'), ('n_estimators', 50)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "ExtraTrees Train accuracy: 0.845360824742268 Test accuracy: 0.6938775510204082\n",
      "ExtraTrees Train balanced accuracy: 0.8355718355718356 Test balanced accuracy: 0.6634920634920635\n",
      "ExtraTrees Train F1 0.8469891783664194 Test F1: 0.6854988329642708\n",
      "ExtraTrees Train recall: 0.845360824742268 Test recall: 0.6938775510204082\n",
      "ExtraTrees Train precision: 0.8540667789650237 Test precision: 0.6795918367346938\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    model.fit(X_train, Y_train, sample_weight=classes_weights_train)\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print('Non-nested CV Results:')\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(name, 'Train accuracy:', accuracy_score(Y_train, y_pred_train), 'Test accuracy:', accuracy_score(Y_test, y_pred))\n",
    "    print(name, 'Train balanced accuracy:', balanced_accuracy_score(Y_train, y_pred_train), 'Test balanced accuracy:', balanced_accuracy_score(Y_test, y_pred))\n",
    "    print(name, 'Train F1', f1_score(Y_train, y_pred_train, average='weighted'), 'Test F1:', f1_score(Y_test, y_pred, average='weighted'))\n",
    "    print(name, 'Train recall:', recall_score(Y_train, y_pred_train, average='weighted'),'Test recall:', recall_score(Y_test, y_pred,average='weighted'))\n",
    "    print(name, 'Train precision:', precision_score(Y_train, y_pred_train,average='weighted'), 'Test precision:', precision_score(Y_test, y_pred,average='weighted'))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others models:\n",
    "- all other models require feature scaling before running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_params = {\n",
    "    'n_neighbors':[7,9,11,13,15,17],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['euclidean','manhattan', 'minkowski']}\n",
    "\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', solver='liblinear',multi_class='auto',random_state=seed)\n",
    "lr_params= {\n",
    "    'penalty':['l1', 'l2'], \n",
    "    'C': [0.5, 1, 5, 10], \n",
    "    'max_iter':[500, 1000, 2500]}\n",
    "\n",
    "svc = SVC()\n",
    "svc_params = {\n",
    "    'kernel': ['rbf'],\n",
    "   'C': (1e0, 1e3),\n",
    "   'gamma': ['scale', 'auto']}\n",
    "\n",
    "othermodels = []\n",
    "\n",
    "othermodels.append(('KNN', BayesSearchCV(knn, knn_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "othermodels.append(('SVC', BayesSearchCV(svc, svc_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "othermodels.append(('LR', BayesSearchCV(lr, lr_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "\n",
    "results = []\n",
    "results1 = []\n",
    "results2 = []\n",
    "results3 = []\n",
    "names = []\n",
    "names2 =[]\n",
    "scoring = ['accuracy', 'balanced_accuracy', 'f1_weighted', \n",
    "          'precision_weighted','recall_weighted'] #https://scikit-learn.org/stable/modules/model_evaluation.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = MinMaxScaler().fit_transform(X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X2, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_weights_train = class_weight.compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=Y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Nested CV results for all scores: \n",
      " {'fit_time': array([45.75626874, 51.53988719, 52.73966575, 47.63927698, 53.21452904]), 'score_time': array([0.00563407, 0.00351691, 0.00375724, 0.00381708, 0.00376678]), 'test_accuracy': array([0.6122449 , 0.71428571, 0.85714286, 0.66666667, 0.58333333]), 'test_balanced_accuracy': array([0.51587302, 0.59499759, 0.73989899, 0.55011655, 0.40864198]), 'test_f1_weighted': array([0.54093279, 0.69764521, 0.82877411, 0.57936508, 0.48511905]), 'test_precision_weighted': array([0.48510756, 0.68992462, 0.83642826, 0.51801802, 0.45203488]), 'test_recall_weighted': array([0.6122449 , 0.71428571, 0.85714286, 0.66666667, 0.58333333])} \n",
      "\n",
      "KNN Accuracy Nested CV Average 0.686734693877551\n",
      "KNN Balanced Accuracy Nested CV Average 0.5619056252389586\n",
      "KNN F1 Nested CV Average 0.6263672473974655\n",
      "KNN Precision Nested CV Average 0.5963026683541635\n",
      "KNN Recall Nested CV Average 0.686734693877551\n",
      "Best Parameters: \n",
      "OrderedDict([('metric', 'manhattan'), ('n_neighbors', 17), ('weights', 'distance')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "KNN Train accuracy: 1.0 Test accuracy: 0.5510204081632653\n",
      "KNN Train balanced accuracy: 1.0 Test balanced accuracy: 0.48253968253968255\n",
      "KNN Train F1 1.0 Test F1: 0.48585343228200367\n",
      "KNN Train recall: 1.0 Test recall: 0.5510204081632653\n",
      "KNN Train precision: 1.0 Test precision: 0.44377751100440177\n",
      "\n",
      "\n",
      "SVC Nested CV results for all scores: \n",
      " {'fit_time': array([46.91346192, 42.9466958 , 45.09099197, 45.32414198, 50.89256501]), 'score_time': array([0.00427294, 0.00430894, 0.00413418, 0.00410604, 0.00438499]), 'test_accuracy': array([0.71428571, 0.75510204, 0.67346939, 0.72916667, 0.58333333]), 'test_balanced_accuracy': array([0.57142857, 0.52380952, 0.49116162, 0.64102564, 0.40864198]), 'test_f1_weighted': array([0.6154624 , 0.67375482, 0.6549817 , 0.70514946, 0.48511905]), 'test_precision_weighted': array([0.56029685, 0.63673469, 0.65406373, 0.73809524, 0.45203488]), 'test_recall_weighted': array([0.71428571, 0.75510204, 0.67346939, 0.72916667, 0.58333333])} \n",
      "\n",
      "SVC Accuracy Nested CV Average 0.6910714285714286\n",
      "SVC Balanced Accuracy Nested CV Average 0.5272134655467989\n",
      "SVC F1 Nested CV Average 0.6268934850510699\n",
      "SVC Precision Nested CV Average 0.6082450784920622\n",
      "SVC Recall Nested CV Average 0.6910714285714286\n",
      "Best Parameters: \n",
      "OrderedDict([('C', 1.0), ('gamma', 'scale'), ('kernel', 'rbf')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "SVC Train accuracy: 0.7164948453608248 Test accuracy: 0.7142857142857143\n",
      "SVC Train balanced accuracy: 0.5249766573295985 Test balanced accuracy: 0.5714285714285715\n",
      "SVC Train F1 0.6308065494238934 Test F1: 0.6154624011766869\n",
      "SVC Train recall: 0.7164948453608248 Test recall: 0.7142857142857143\n",
      "SVC Train precision: 0.5881443298969072 Test precision: 0.5602968460111317\n",
      "\n",
      "\n",
      "LR Nested CV results for all scores: \n",
      " {'fit_time': array([42.97020793, 45.60365677, 43.19109488, 45.25640583, 46.51931   ]), 'score_time': array([0.00287008, 0.00268817, 0.00281715, 0.00285125, 0.00259185]), 'test_accuracy': array([0.67346939, 0.75510204, 0.75510204, 0.72916667, 0.66666667]), 'test_balanced_accuracy': array([0.58253968, 0.67965368, 0.53156566, 0.64102564, 0.51795735]), 'test_f1_weighted': array([0.63883735, 0.74594838, 0.7078179 , 0.70514946, 0.59854984]), 'test_precision_weighted': array([0.62585034, 0.73994169, 0.72536443, 0.73809524, 0.75948509]), 'test_recall_weighted': array([0.67346939, 0.75510204, 0.75510204, 0.72916667, 0.66666667])} \n",
      "\n",
      "LR Accuracy Nested CV Average 0.7159013605442176\n",
      "LR Balanced Accuracy Nested CV Average 0.5905484022150689\n",
      "LR F1 Nested CV Average 0.6792605859605025\n",
      "LR Precision Nested CV Average 0.7177473591062442\n",
      "LR Recall Nested CV Average 0.7159013605442176\n",
      "Best Parameters: \n",
      "OrderedDict([('C', 0.5), ('max_iter', 1000), ('penalty', 'l1')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "LR Train accuracy: 0.711340206185567 Test accuracy: 0.6938775510204082\n",
      "LR Train balanced accuracy: 0.5336673130790778 Test balanced accuracy: 0.5238095238095238\n",
      "LR Train F1 0.645947014237096 Test F1: 0.5936920222634509\n",
      "LR Train recall: 0.711340206185567 Test recall: 0.6938775510204082\n",
      "LR Train precision: 0.6799471347838532 Test precision: 0.5510204081632653\n",
      "\n",
      "\n",
      "All balanced accuracy results: [array([0.51587302, 0.59499759, 0.73989899, 0.55011655, 0.40864198]), array([0.57142857, 0.58152958, 0.50126263, 0.64102564, 0.44197531]), array([0.58253968, 0.67965368, 0.53156566, 0.64102564, 0.51795735])]\n"
     ]
    }
   ],
   "source": [
    "for name, model in othermodels:\n",
    "    nested_cv_results = model_selection.cross_validate(model, X2 , Y, cv=outer_cv, scoring=scoring, error_score=\"raise\")\n",
    "    nested_cv_results2 = model_selection.cross_val_score(model, X2 , Y, cv=outer_cv, scoring='balanced_accuracy', error_score=\"raise\")\n",
    "    results.append(nested_cv_results2)\n",
    "    names.append(name)\n",
    "    print(name, 'Nested CV results for all scores:', '\\n', nested_cv_results, '\\n')\n",
    "    print(name, 'Accuracy Nested CV Average', np.mean(nested_cv_results['test_accuracy']))\n",
    "    print(name, 'Balanced Accuracy Nested CV Average', np.mean(nested_cv_results['test_balanced_accuracy'] ))\n",
    "    print(name, 'F1 Nested CV Average', np.mean(nested_cv_results['test_f1_weighted'] ))\n",
    "    print(name, 'Precision Nested CV Average', np.mean(nested_cv_results['test_precision_weighted'] ))\n",
    "    print(name, 'Recall Nested CV Average', np.mean(nested_cv_results['test_recall_weighted'] ))\n",
    "    model.fit(X_train, Y_train)\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print('Non-nested CV Results:')\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(name, 'Train accuracy:', accuracy_score(Y_train, y_pred_train), 'Test accuracy:', accuracy_score(Y_test, y_pred))\n",
    "    print(name, 'Train balanced accuracy:', balanced_accuracy_score(Y_train, y_pred_train), 'Test balanced accuracy:', balanced_accuracy_score(Y_test, y_pred))\n",
    "    print(name, 'Train F1', f1_score(Y_train, y_pred_train, average='weighted'), 'Test F1:', f1_score(Y_test, y_pred, average='weighted'))\n",
    "    print(name, 'Train recall:', recall_score(Y_train, y_pred_train, average='weighted'),'Test recall:', recall_score(Y_test, y_pred,average='weighted'))\n",
    "    print(name, 'Train precision:', precision_score(Y_train, y_pred_train,average='weighted'), 'Test precision:', precision_score(Y_test, y_pred,average='weighted'))\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "print('All balanced accuracy results:', results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'sample_weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hq/kzr0rkh51pqbrlqch03_gq2r0000gp/T/ipykernel_6107/4059729773.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mothermodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses_weights_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best Parameters: \\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Non-nested CV Results:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_pred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BP_revisit/lib/python3.8/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_kwargs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;31m# BaseSearchCV never ranked train scores,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BP_revisit/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BP_revisit/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BP_revisit/lib/python3.8/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    510\u001b[0m                 \u001b[0mn_points_adjusted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                 optim_result = self._step(\n\u001b[0m\u001b[1;32m    513\u001b[0m                     \u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_points_adjusted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BP_revisit/lib/python3.8/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, search_space, optimizer, evaluate_candidates, n_points)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpoint_asdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0mall_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0;31m# Feed the point and objective value back into optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;31m# Optimizer minimizes objective, hence provide negative score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BP_revisit/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BP_revisit/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BP_revisit/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BP_revisit/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BP_revisit/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BP_revisit/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BP_revisit/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BP_revisit/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BP_revisit/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/BP_revisit/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'sample_weight'"
     ]
    }
   ],
   "source": [
    "for name, model in othermodels:\n",
    "    model.fit(X_train, Y_train, sample_weight=classes_weights_train)\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print('Non-nested CV Results:')\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(name, 'Train accuracy:', accuracy_score(Y_train, y_pred_train), 'Test accuracy:', accuracy_score(Y_test, y_pred))\n",
    "    print(name, 'Train balanced accuracy:', balanced_accuracy_score(Y_train, y_pred_train), 'Test balanced accuracy:', balanced_accuracy_score(Y_test, y_pred))\n",
    "    print(name, 'Train F1', f1_score(Y_train, y_pred_train, average='weighted'), 'Test F1:', f1_score(Y_test, y_pred, average='weighted'))\n",
    "    print(name, 'Train recall:', recall_score(Y_train, y_pred_train, average='weighted'),'Test recall:', recall_score(Y_test, y_pred,average='weighted'))\n",
    "    print(name, 'Train precision:', precision_score(Y_train, y_pred_train,average='weighted'), 'Test precision:', precision_score(Y_test, y_pred,average='weighted'))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model benchmarking - BorutaShap feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boruta_sel = pd.read_csv(\"2021-11-19_selected_features_training_data.csv\", header=0)\n",
    "X_boruta_sel.columns = [\n",
    "    regex.sub(\"_\", col) if any(x in str(col) for x in set((\"[\", \"]\", \"<\"))) else col\n",
    "    for col in X_boruta_sel.columns.values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_boruta, X_test_boruta, Y_train_boruta, Y_test_boruta = train_test_split(X_boruta_sel, Y, test_size=0.2, random_state=0)\n",
    "classes_weights_train = class_weight.compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=Y_train_boruta\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Nested CV results for all scores: \n",
      " {'fit_time': array([53.2495141 , 57.86611295, 55.35747099, 54.30866885, 52.22345304]), 'score_time': array([0.00477004, 0.00446701, 0.00481415, 0.00500607, 0.00476193]), 'test_accuracy': array([0.65306122, 0.7755102 , 0.85714286, 0.79166667, 0.77083333]), 'test_balanced_accuracy': array([0.64444444, 0.7003367 , 0.77146465, 0.76689977, 0.66363636]), 'test_f1_weighted': array([0.62934888, 0.74400617, 0.83932493, 0.78510802, 0.70287056]), 'test_precision_weighted': array([0.61294063, 0.81709957, 0.87380952, 0.78207672, 0.83717105]), 'test_recall_weighted': array([0.65306122, 0.7755102 , 0.85714286, 0.79166667, 0.77083333])} \n",
      "\n",
      "XGB Accuracy Nested CV Average 0.7696428571428571\n",
      "XGB Balanced Accuracy Nested CV Average 0.7093563843563844\n",
      "XGB F1 Nested CV Average 0.7401317115108192\n",
      "XGB Precision Nested CV Average 0.7846194987830326\n",
      "XGB Recall Nested CV Average 0.7696428571428571\n",
      "Best Parameters: \n",
      "OrderedDict([('learning_rate', 0.4885189317071115), ('max_depth', 3), ('n_estimators', 49), ('reg_alpha', 7), ('reg_lambda', 3)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "XGB Train accuracy: 0.845360824742268 Test accuracy: 0.7551020408163265\n",
      "XGB Train balanced accuracy: 0.7601151571739807 Test balanced accuracy: 0.7000000000000001\n",
      "XGB Train F1 0.8203702246355901 Test F1: 0.7020332013402376\n",
      "XGB Train recall: 0.845360824742268 Test recall: 0.7551020408163265\n",
      "XGB Train precision: 0.8522240645951985 Test precision: 0.7376968805540235\n",
      "\n",
      "\n",
      "RF Nested CV results for all scores: \n",
      " {'fit_time': array([59.39402795, 57.57645011, 57.18202806, 56.67901587, 53.86179614]), 'score_time': array([0.00681901, 0.00570488, 0.00532889, 0.00428104, 0.00662088]), 'test_accuracy': array([0.71428571, 0.7755102 , 0.87755102, 0.79166667, 0.70833333]), 'test_balanced_accuracy': array([0.66111111, 0.7003367 , 0.78156566, 0.73193473, 0.58462402]), 'test_f1_weighted': array([0.65218087, 0.75191617, 0.85845871, 0.77437297, 0.65000686]), 'test_precision_weighted': array([0.64164876, 0.74098639, 0.89085003, 0.78819444, 0.69791667]), 'test_recall_weighted': array([0.71428571, 0.7755102 , 0.87755102, 0.79166667, 0.70833333])} \n",
      "\n",
      "RF Accuracy Nested CV Average 0.773469387755102\n",
      "RF Balanced Accuracy Nested CV Average 0.6919144435811102\n",
      "RF F1 Nested CV Average 0.7373871148338715\n",
      "RF Precision Nested CV Average 0.7519192608290352\n",
      "RF Recall Nested CV Average 0.773469387755102\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'entropy'), ('max_depth', 3), ('max_features', 'auto'), ('n_estimators', 27)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "RF Train accuracy: 0.8298969072164949 Test accuracy: 0.7142857142857143\n",
      "RF Train balanced accuracy: 0.7222701046230459 Test balanced accuracy: 0.5880952380952381\n",
      "RF Train F1 0.7912647434447638 Test F1: 0.6450192520902496\n",
      "RF Train recall: 0.8298969072164949 Test recall: 0.7142857142857143\n",
      "RF Train precision: 0.8638389788905253 Test precision: 0.6745478679276589\n",
      "\n",
      "\n",
      "GB Nested CV results for all scores: \n",
      " {'fit_time': array([69.3413949 , 73.33913922, 69.9638772 , 72.42089891, 66.90699291]), 'score_time': array([0.00323415, 0.003371  , 0.00354314, 0.00316501, 0.00332212]), 'test_accuracy': array([0.63265306, 0.73469388, 0.87755102, 0.75      , 0.72916667]), 'test_balanced_accuracy': array([0.63333333, 0.64261664, 0.78156566, 0.70629371, 0.61795735]), 'test_f1_weighted': array([0.61447694, 0.71024162, 0.85845871, 0.73115079, 0.6704416 ]), 'test_precision_weighted': array([0.60034014, 0.71088435, 0.89085003, 0.72460317, 0.70778509]), 'test_recall_weighted': array([0.63265306, 0.73469388, 0.87755102, 0.75      , 0.72916667])} \n",
      "\n",
      "GB Accuracy Nested CV Average 0.7448129251700679\n",
      "GB Balanced Accuracy Nested CV Average 0.6763533380200046\n",
      "GB F1 Nested CV Average 0.7169539323668309\n",
      "GB Precision Nested CV Average 0.7268925571651136\n",
      "GB Recall Nested CV Average 0.7448129251700679\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'mae'), ('learning_rate', 0.260757764244599), ('max_depth', 2), ('max_features', 'sqrt'), ('n_estimators', 21)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "GB Train accuracy: 0.8711340206185567 Test accuracy: 0.7142857142857143\n",
      "GB Train balanced accuracy: 0.8028501999090234 Test balanced accuracy: 0.6944444444444445\n",
      "GB Train F1 0.8564513866523109 Test F1: 0.688244846810905\n",
      "GB Train recall: 0.8711340206185567 Test recall: 0.7142857142857143\n",
      "GB Train precision: 0.8816000411461499 Test precision: 0.6798892717260064\n",
      "\n",
      "\n",
      "DT Nested CV results for all scores: \n",
      " {'fit_time': array([52.245363  , 38.59248996, 39.14485097, 48.68163991, 43.89276409]), 'score_time': array([0.002985  , 0.00328016, 0.00362206, 0.00335503, 0.00356984]), 'test_accuracy': array([0.67346939, 0.6122449 , 0.69387755, 0.64583333, 0.625     ]), 'test_balanced_accuracy': array([0.67222222, 0.72727273, 0.43813131, 0.64219114, 0.59517396]), 'test_f1_weighted': array([0.65102041, 0.63883969, 0.61762727, 0.65902778, 0.59140339]), 'test_precision_weighted': array([0.66875981, 0.74992711, 0.57244898, 0.67934524, 0.63849976]), 'test_recall_weighted': array([0.67346939, 0.6122449 , 0.69387755, 0.64583333, 0.625     ])} \n",
      "\n",
      "DT Accuracy Nested CV Average 0.6500850340136054\n",
      "DT Balanced Accuracy Nested CV Average 0.6149982733316066\n",
      "DT F1 Nested CV Average 0.63158370634521\n",
      "DT Precision Nested CV Average 0.6617961807086103\n",
      "DT Recall Nested CV Average 0.6500850340136054\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'entropy'), ('max_depth', 4), ('max_features', 'log2')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "DT Train accuracy: 0.8144329896907216 Test accuracy: 0.6938775510204082\n",
      "DT Train balanced accuracy: 0.6945402092460915 Test balanced accuracy: 0.6103174603174604\n",
      "DT Train F1 0.7989574232628576 Test F1: 0.6715589613693083\n",
      "DT Train recall: 0.8144329896907216 Test recall: 0.6938775510204082\n",
      "DT Train precision: 0.8417798866662114 Test precision: 0.6780395555905759\n",
      "\n",
      "\n",
      "ExtraTrees Nested CV results for all scores: \n",
      " {'fit_time': array([61.33552909, 51.88913202, 65.54567766, 52.30644608, 45.06111097]), 'score_time': array([0.00408983, 0.00622296, 0.00649333, 0.00431776, 0.00431108]), 'test_accuracy': array([0.73469388, 0.73469388, 0.79591837, 0.75      , 0.66666667]), 'test_balanced_accuracy': array([0.63571429, 0.60509861, 0.58333333, 0.65384615, 0.5       ]), 'test_f1_weighted': array([0.66472303, 0.71252634, 0.75900465, 0.72147708, 0.57281746]), 'test_precision_weighted': array([0.68877551, 0.70648049, 0.84337921, 0.77719907, 0.56153101]), 'test_recall_weighted': array([0.73469388, 0.73469388, 0.79591837, 0.75      , 0.66666667])} \n",
      "\n",
      "ExtraTrees Accuracy Nested CV Average 0.7363945578231292\n",
      "ExtraTrees Balanced Accuracy Nested CV Average 0.5955984755984756\n",
      "ExtraTrees F1 Nested CV Average 0.6861097124167091\n",
      "ExtraTrees Precision Nested CV Average 0.7154730582223369\n",
      "ExtraTrees Recall Nested CV Average 0.7363945578231292\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'gini'), ('max_depth', 3), ('max_features', 'log2'), ('n_estimators', 29)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "ExtraTrees Train accuracy: 0.7783505154639175 Test accuracy: 0.7346938775510204\n",
      "ExtraTrees Train balanced accuracy: 0.6303897627427039 Test balanced accuracy: 0.6357142857142857\n",
      "ExtraTrees Train F1 0.7369502681292901 Test F1: 0.6647230320699709\n",
      "ExtraTrees Train recall: 0.7783505154639175 Test recall: 0.7346938775510204\n",
      "ExtraTrees Train precision: 0.8318447660586836 Test precision: 0.6887755102040817\n",
      "\n",
      "\n",
      "All balanced accuracy results: [array([0.65555556, 0.7003367 , 0.79166667, 0.74125874, 0.66363636]), array([0.66111111, 0.72053872, 0.78156566, 0.7016317 , 0.58462402]), array([0.60555556, 0.64309764, 0.79166667, 0.66317016, 0.65129068]), array([0.67222222, 0.72727273, 0.43813131, 0.64219114, 0.59517396]), array([0.60793651, 0.60509861, 0.58333333, 0.64102564, 0.53333333])]\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    nested_cv_results = model_selection.cross_validate(model, X_boruta_sel , Y, cv=outer_cv, scoring=scoring, error_score=\"raise\")\n",
    "    nested_cv_results2 = model_selection.cross_val_score(model, X_boruta_sel , Y, cv=outer_cv, scoring='balanced_accuracy', error_score=\"raise\")\n",
    "    results.append(nested_cv_results2)\n",
    "    names.append(name)\n",
    "    print(name, 'Nested CV results for all scores:', '\\n', nested_cv_results, '\\n')\n",
    "    print(name, 'Accuracy Nested CV Average', np.mean(nested_cv_results['test_accuracy']))\n",
    "    print(name, 'Balanced Accuracy Nested CV Average', np.mean(nested_cv_results['test_balanced_accuracy'] ))\n",
    "    print(name, 'F1 Nested CV Average', np.mean(nested_cv_results['test_f1_weighted'] ))\n",
    "    print(name, 'Precision Nested CV Average', np.mean(nested_cv_results['test_precision_weighted'] ))\n",
    "    print(name, 'Recall Nested CV Average', np.mean(nested_cv_results['test_recall_weighted'] ))\n",
    "    model.fit(X_train_boruta, Y_train_boruta)\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print('Non-nested CV Results:')\n",
    "    y_pred_train = model.predict(X_train_boruta)\n",
    "    y_pred = model.predict(X_test_boruta)\n",
    "    print(name, 'Train accuracy:', accuracy_score(Y_train_boruta, y_pred_train), 'Test accuracy:', accuracy_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train balanced accuracy:', balanced_accuracy_score(Y_train, y_pred_train), 'Test balanced accuracy:', balanced_accuracy_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train F1', f1_score(Y_train_boruta, y_pred_train, average='weighted'), 'Test F1:', f1_score(Y_test_boruta, y_pred, average='weighted'))\n",
    "    print(name, 'Train recall:', recall_score(Y_train_boruta, y_pred_train, average='weighted'),'Test recall:', recall_score(Y_test_boruta, y_pred,average='weighted'))\n",
    "    print(name, 'Train precision:', precision_score(Y_train_boruta, y_pred_train,average='weighted'), 'Test precision:', precision_score(Y_test_boruta, y_pred,average='weighted'))\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "print('All balanced accuracy results:', results)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: \n",
      "OrderedDict([('learning_rate', 0.3142036021192166), ('max_depth', 3), ('n_estimators', 50), ('reg_alpha', 1), ('reg_lambda', 1)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "XGB Train accuracy: 0.9742268041237113 Test accuracy: 0.6122448979591837\n",
      "XGB Train balanced accuracy: 0.9859943977591037 Test balanced accuracy: 0.6222222222222222\n",
      "XGB Train F1 0.9743759511026445 Test F1: 0.5980983302411873\n",
      "XGB Train recall: 0.9742268041237113 Test recall: 0.6122448979591837\n",
      "XGB Train precision: 0.9758739632586622 Test precision: 0.5886621315192743\n",
      "\n",
      "\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'entropy'), ('max_depth', 4), ('max_features', 'log2'), ('n_estimators', 20)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "RF Train accuracy: 0.9175257731958762 Test accuracy: 0.6122448979591837\n",
      "RF Train balanced accuracy: 0.8977231918408389 Test balanced accuracy: 0.6555555555555556\n",
      "RF Train F1 0.9153398200961462 Test F1: 0.6168498168498169\n",
      "RF Train recall: 0.9175257731958762 Test recall: 0.6122448979591837\n",
      "RF Train precision: 0.9159958437250233 Test precision: 0.6258098477486232\n",
      "\n",
      "\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'friedman_mse'), ('learning_rate', 0.4677799591898774), ('max_depth', 3), ('max_features', 'sqrt'), ('n_estimators', 35)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "GB Train accuracy: 1.0 Test accuracy: 0.673469387755102\n",
      "GB Train balanced accuracy: 1.0 Test balanced accuracy: 0.6722222222222222\n",
      "GB Train F1 1.0 Test F1: 0.6638937099766593\n",
      "GB Train recall: 1.0 Test recall: 0.673469387755102\n",
      "GB Train precision: 1.0 Test precision: 0.6563775510204082\n",
      "\n",
      "\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'gini'), ('max_depth', 3), ('max_features', 'log2')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "DT Train accuracy: 0.8298969072164949 Test accuracy: 0.5714285714285714\n",
      "DT Train balanced accuracy: 0.8321542292130527 Test balanced accuracy: 0.6166666666666667\n",
      "DT Train F1 0.8338993329290479 Test F1: 0.5751009194886747\n",
      "DT Train recall: 0.8298969072164949 Test recall: 0.5714285714285714\n",
      "DT Train precision: 0.8406123935454953 Test precision: 0.5874510976551793\n",
      "\n",
      "\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'entropy'), ('max_depth', 4), ('max_features', 'log2'), ('n_estimators', 15)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "ExtraTrees Train accuracy: 0.7835051546391752 Test accuracy: 0.6122448979591837\n",
      "ExtraTrees Train balanced accuracy: 0.7918911154205271 Test balanced accuracy: 0.6190476190476191\n",
      "ExtraTrees Train F1 0.7880667822278989 Test F1: 0.6121185316231755\n",
      "ExtraTrees Train recall: 0.7835051546391752 Test recall: 0.6122448979591837\n",
      "ExtraTrees Train precision: 0.8003037808244022 Test precision: 0.6208616780045351\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    model.fit(X_train_boruta, Y_train_boruta,  sample_weight=classes_weights_train)\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print('Non-nested CV Results:')\n",
    "    y_pred_train = model.predict(X_train_boruta)\n",
    "    y_pred = model.predict(X_test_boruta)\n",
    "    print(name, 'Train accuracy:', accuracy_score(Y_train_boruta, y_pred_train), 'Test accuracy:', accuracy_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train balanced accuracy:', balanced_accuracy_score(Y_train, y_pred_train), 'Test balanced accuracy:', balanced_accuracy_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train F1', f1_score(Y_train_boruta, y_pred_train, average='weighted'), 'Test F1:', f1_score(Y_test_boruta, y_pred, average='weighted'))\n",
    "    print(name, 'Train recall:', recall_score(Y_train_boruta, y_pred_train, average='weighted'),'Test recall:', recall_score(Y_test_boruta, y_pred,average='weighted'))\n",
    "    print(name, 'Train precision:', precision_score(Y_train_boruta, y_pred_train,average='weighted'), 'Test precision:', precision_score(Y_test_boruta, y_pred,average='weighted'))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_boruta_sel = MinMaxScaler().fit_transform(X_boruta_sel)\n",
    "X_train_boruta, X_test_boruta, Y_train_boruta, Y_test_boruta = train_test_split(X2_boruta_sel, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_weights_train = class_weight.compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=Y_train_boruta\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Nested CV results for all scores: \n",
      " {'fit_time': array([42.36386037, 45.76399589, 44.42084885, 48.70277309, 45.12233591]), 'score_time': array([0.00371099, 0.00355411, 0.00468826, 0.00357103, 0.00330877]), 'test_accuracy': array([0.69387755, 0.69387755, 0.75510204, 0.85416667, 0.72916667]), 'test_balanced_accuracy': array([0.61349206, 0.64935065, 0.59469697, 0.78787879, 0.61795735]), 'test_f1_weighted': array([0.63324703, 0.69356358, 0.73704867, 0.82879002, 0.66363304]), 'test_precision_weighted': array([0.62364405, 0.69451531, 0.7466248 , 0.88510101, 0.79922027]), 'test_recall_weighted': array([0.69387755, 0.69387755, 0.75510204, 0.85416667, 0.72916667])} \n",
      "\n",
      "KNN Accuracy Nested CV Average 0.7452380952380951\n",
      "KNN Balanced Accuracy Nested CV Average 0.652675164341831\n",
      "KNN F1 Nested CV Average 0.7112564669642738\n",
      "KNN Precision Nested CV Average 0.7498210890222168\n",
      "KNN Recall Nested CV Average 0.7452380952380951\n",
      "Best Parameters: \n",
      "OrderedDict([('metric', 'manhattan'), ('n_neighbors', 15), ('weights', 'distance')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "KNN Train accuracy: 1.0 Test accuracy: 0.6938775510204082\n",
      "KNN Train balanced accuracy: 1.0 Test balanced accuracy: 0.6134920634920635\n",
      "KNN Train F1 1.0 Test F1: 0.6332470301553457\n",
      "KNN Train recall: 1.0 Test recall: 0.6938775510204082\n",
      "KNN Train precision: 1.0 Test precision: 0.6236440522154808\n",
      "\n",
      "\n",
      "SVC Nested CV results for all scores: \n",
      " {'fit_time': array([44.56299496, 46.03860402, 44.73095202, 45.06452417, 43.01065302]), 'score_time': array([0.00306416, 0.0031209 , 0.00335598, 0.00331593, 0.00367904]), 'test_accuracy': array([0.67346939, 0.75510204, 0.75510204, 0.79166667, 0.6875    ]), 'test_balanced_accuracy': array([0.61904762, 0.61519962, 0.59469697, 0.73193473, 0.56621773]), 'test_f1_weighted': array([0.63988095, 0.72762951, 0.73704867, 0.77437297, 0.65922437]), 'test_precision_weighted': array([0.62705082, 0.72893773, 0.7466248 , 0.78819444, 0.70298423]), 'test_recall_weighted': array([0.67346939, 0.75510204, 0.75510204, 0.79166667, 0.6875    ])} \n",
      "\n",
      "SVC Accuracy Nested CV Average 0.7325680272108843\n",
      "SVC Balanced Accuracy Nested CV Average 0.625419333752667\n",
      "SVC F1 Nested CV Average 0.7076312931505494\n",
      "SVC Precision Nested CV Average 0.7187584063424399\n",
      "SVC Recall Nested CV Average 0.7325680272108843\n",
      "Best Parameters: \n",
      "OrderedDict([('C', 95.4041342841097), ('gamma', 'auto'), ('kernel', 'rbf')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "SVC Train accuracy: 0.8041237113402062 Test accuracy: 0.6938775510204082\n",
      "SVC Train balanced accuracy: 0.6961083578730637 Test balanced accuracy: 0.6301587301587301\n",
      "SVC Train F1 0.7885931389975115 Test F1: 0.654561824729892\n",
      "SVC Train recall: 0.8041237113402062 Test recall: 0.6938775510204082\n",
      "SVC Train precision: 0.8212541663436942 Test precision: 0.6480077745383868\n",
      "\n",
      "\n",
      "LR Nested CV results for all scores: \n",
      " {'fit_time': array([44.96482086, 44.39719796, 42.5439918 , 47.06843495, 44.82579207]), 'score_time': array([0.00293088, 0.0027101 , 0.00269294, 0.00283408, 0.00262189]), 'test_accuracy': array([0.69387755, 0.69387755, 0.73469388, 0.75      , 0.625     ]), 'test_balanced_accuracy': array([0.57698413, 0.55796056, 0.52146465, 0.68881119, 0.532211  ]), 'test_f1_weighted': array([0.62711793, 0.6673163 , 0.68631033, 0.73769955, 0.58875399]), 'test_precision_weighted': array([0.65129513, 0.65202291, 0.76919339, 0.74944196, 0.69637446]), 'test_recall_weighted': array([0.69387755, 0.69387755, 0.73469388, 0.75      , 0.625     ])} \n",
      "\n",
      "LR Accuracy Nested CV Average 0.6994897959183674\n",
      "LR Balanced Accuracy Nested CV Average 0.5754863038196372\n",
      "LR F1 Nested CV Average 0.6614396204409032\n",
      "LR Precision Nested CV Average 0.703665572533893\n",
      "LR Recall Nested CV Average 0.6994897959183674\n",
      "Best Parameters: \n",
      "OrderedDict([('C', 1.0), ('max_iter', 1000), ('penalty', 'l2')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "LR Train accuracy: 0.7474226804123711 Test accuracy: 0.6938775510204082\n",
      "LR Train balanced accuracy: 0.5956331250448897 Test balanced accuracy: 0.576984126984127\n",
      "LR Train F1 0.6994991901803543 Test F1: 0.6271179279165083\n",
      "LR Train recall: 0.7474226804123711 Test recall: 0.6938775510204082\n",
      "LR Train precision: 0.7781434094256259 Test precision: 0.6512951334379906\n",
      "\n",
      "\n",
      "All balanced accuracy results: [array([0.51587302, 0.59499759, 0.73989899, 0.55011655, 0.40864198]), array([0.57142857, 0.58152958, 0.50126263, 0.64102564, 0.44197531]), array([0.58253968, 0.67965368, 0.53156566, 0.64102564, 0.51795735]), array([0.66666667, 0.7003367 , 0.75      , 0.76689977, 0.66363636]), array([0.67777778, 0.7003367 , 0.78156566, 0.73193473, 0.58462402]), array([0.61349206, 0.64935065, 0.59469697, 0.80536131, 0.61795735]), array([0.61904762, 0.65223665, 0.59469697, 0.73193473, 0.56621773]), array([0.57698413, 0.55796056, 0.52146465, 0.68881119, 0.532211  ])]\n"
     ]
    }
   ],
   "source": [
    "for name, model in othermodels:\n",
    "    nested_cv_results = model_selection.cross_validate(model, X2_boruta_sel , Y, cv=outer_cv, scoring=scoring, error_score=\"raise\")\n",
    "    nested_cv_results2 = model_selection.cross_val_score(model, X2_boruta_sel , Y, cv=outer_cv, scoring='balanced_accuracy', error_score=\"raise\")\n",
    "    results.append(nested_cv_results2)\n",
    "    names.append(name)\n",
    "    print(name, 'Nested CV results for all scores:', '\\n', nested_cv_results, '\\n')\n",
    "    print(name, 'Accuracy Nested CV Average', np.mean(nested_cv_results['test_accuracy']))\n",
    "    print(name, 'Balanced Accuracy Nested CV Average', np.mean(nested_cv_results['test_balanced_accuracy'] ))\n",
    "    print(name, 'F1 Nested CV Average', np.mean(nested_cv_results['test_f1_weighted'] ))\n",
    "    print(name, 'Precision Nested CV Average', np.mean(nested_cv_results['test_precision_weighted'] ))\n",
    "    print(name, 'Recall Nested CV Average', np.mean(nested_cv_results['test_recall_weighted'] ))\n",
    "    model.fit(X_train_boruta, Y_train_boruta)\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print('Non-nested CV Results:')\n",
    "    y_pred_train = model.predict(X_train_boruta)\n",
    "    y_pred = model.predict(X_test_boruta)\n",
    "    print(name, 'Train accuracy:', accuracy_score(Y_train_boruta, y_pred_train), 'Test accuracy:', accuracy_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train balanced accuracy:', balanced_accuracy_score(Y_train, y_pred_train), 'Test balanced accuracy:', balanced_accuracy_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train F1', f1_score(Y_train_boruta, y_pred_train, average='weighted'), 'Test F1:', f1_score(Y_test_boruta, y_pred, average='weighted'))\n",
    "    print(name, 'Train recall:', recall_score(Y_train_boruta, y_pred_train, average='weighted'),'Test recall:', recall_score(Y_test_boruta, y_pred,average='weighted'))\n",
    "    print(name, 'Train precision:', precision_score(Y_train_boruta, y_pred_train,average='weighted'), 'Test precision:', precision_score(Y_test_boruta, y_pred,average='weighted'))\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "print('All balanced accuracy results:', results)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in othermodels:\n",
    "    model.fit(X_train_boruta, Y_train_boruta, sample_weight=classes_weights_train)\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print('Non-nested CV Results:')\n",
    "    y_pred_train = model.predict(X_train_boruta)\n",
    "    y_pred = model.predict(X_test_boruta)\n",
    "    print(name, 'Train accuracy:', accuracy_score(Y_train_boruta, y_pred_train), 'Test accuracy:', accuracy_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train balanced accuracy:', balanced_accuracy_score(Y_train, y_pred_train), 'Test balanced accuracy:', balanced_accuracy_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train F1', f1_score(Y_train_boruta, y_pred_train, average='weighted'), 'Test F1:', f1_score(Y_test_boruta, y_pred, average='weighted'))\n",
    "    print(name, 'Train recall:', recall_score(Y_train_boruta, y_pred_train, average='weighted'),'Test recall:', recall_score(Y_test_boruta, y_pred,average='weighted'))\n",
    "    print(name, 'Train precision:', precision_score(Y_train_boruta, y_pred_train,average='weighted'), 'Test precision:', precision_score(Y_test_boruta, y_pred,average='weighted'))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier(random_state=seed, num_class=3, objective='multi:softmax', eval_metric='mlogloss', learning_rate=0.4885189317071115,\n",
    "                           max_depth=3, n_estimators=49, reg_alpha=7, reg_lambda=3) \n",
    "\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=seed, criterion='mae', learning_rate=0.260757764244599, max_depth=2, max_features='sqrt',\n",
    "                               n_estimators=21)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=seed, criterion='entropy', max_depth=4, max_features='auto', n_estimators=27)\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=seed, criterion='entropy', max_depth=4, max_features='log2')\n",
    "\n",
    "\n",
    "extra = ExtraTreesClassifier(random_state=seed, criterion='gini', max_depth=3, max_features='log2', n_estimators=29)\n",
    "\n",
    "knn = KNeighborsClassifier(metric='manhattan', n_neighbors=15, weights='distance')\n",
    "\n",
    "svm = SVC(C=95.4041342841097, gamma='auto', kernel='rbf')\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear',multi_class='auto',random_state=seed, C=1, max_iter=1000, penalty='l2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.67      0.17      0.27        12\n",
      "    probable       0.76      0.93      0.84        30\n",
      "least likely       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.76        49\n",
      "   macro avg       0.73      0.70      0.66        49\n",
      "weighted avg       0.74      0.76      0.70        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['most likely', 'probable', 'least likely']\n",
    "xgb.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(xgb.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.43      0.25      0.32        12\n",
      "    probable       0.76      0.83      0.79        30\n",
      "least likely       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.71        49\n",
      "   macro avg       0.65      0.69      0.66        49\n",
      "weighted avg       0.68      0.71      0.69        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(gb.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.17      0.08      0.11        12\n",
      "    probable       0.65      0.80      0.72        30\n",
      "least likely       0.83      0.71      0.77         7\n",
      "\n",
      "    accuracy                           0.61        49\n",
      "   macro avg       0.55      0.53      0.53        49\n",
      "weighted avg       0.56      0.61      0.58        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(rf.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.43      0.25      0.32        12\n",
      "    probable       0.70      0.87      0.78        30\n",
      "least likely       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.69        49\n",
      "   macro avg       0.71      0.61      0.64        49\n",
      "weighted avg       0.68      0.69      0.67        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(dt.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.50      0.08      0.14        12\n",
      "    probable       0.72      0.97      0.83        30\n",
      "least likely       0.86      0.86      0.86         7\n",
      "\n",
      "    accuracy                           0.73        49\n",
      "   macro avg       0.69      0.64      0.61        49\n",
      "weighted avg       0.69      0.73      0.66        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extra.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(extra.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.67      0.17      0.27        12\n",
      "    probable       0.74      0.87      0.80        30\n",
      "least likely       0.45      0.71      0.56         7\n",
      "\n",
      "    accuracy                           0.67        49\n",
      "   macro avg       0.62      0.58      0.54        49\n",
      "weighted avg       0.68      0.67      0.63        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(knn.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.14      0.08      0.11        12\n",
      "    probable       0.65      0.80      0.72        30\n",
      "least likely       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.61        49\n",
      "   macro avg       0.60      0.53      0.55        49\n",
      "weighted avg       0.57      0.61      0.58        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(svm.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.33      0.17      0.22        12\n",
      "    probable       0.72      0.87      0.79        30\n",
      "least likely       0.57      0.57      0.57         7\n",
      "\n",
      "    accuracy                           0.65        49\n",
      "   macro avg       0.54      0.53      0.53        49\n",
      "weighted avg       0.61      0.65      0.62        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(lr.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
