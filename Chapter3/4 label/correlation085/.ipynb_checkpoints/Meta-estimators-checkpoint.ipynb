{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eaa5868-b315-42af-98bf-0df9aaecfc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import sort\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import statsmodels.api as sm\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "import statsmodels.stats.api as sms\n",
    "import xgboost\n",
    "from BorutaShap import BorutaShap\n",
    "from sklearn import datasets, metrics, model_selection, preprocessing\n",
    "from sklearn.ensemble import (\n",
    "    BaggingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "import lightgbm\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import ElasticNet, Lasso, LinearRegression\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    KFold,\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold,\n",
    "    RepeatedKFold,\n",
    "    cross_val_predict,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    learning_curve,\n",
    "    train_test_split,\n",
    "    validation_curve,\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.mpl.rcParams[\"figure.figsize\"] = (15.0, 9.0)\n",
    "\n",
    "import warnings\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca37a895-7fd1-4e48-86bb-23a209af0cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"training_cleaned.csv\", header=0, sep=\",\")\n",
    "\n",
    "data[\"BPlabel_encoded\"] = data[\"BPlabel\"].map(\n",
    "    {\"most likely\": 1, \"probable\": 2, \"possible\": 3, 'least likely':4}\n",
    ")\n",
    "Y = data[\"BPlabel_encoded\"]\n",
    "data = data.drop([\"BPlabel\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eae62e6-142a-428e-b1c5-f223cd068fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"selected_features_training_data.csv\", header=0)\n",
    "X.columns = [\n",
    "    regex.sub(\"_\", col) if any(x in str(col) for x in set((\"[\", \"]\", \"<\"))) else col\n",
    "    for col in X.columns.values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c69a8ec-05ac-4ac7-a60c-0ebaa0c4188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8e791c0-e854-477d-9e9c-edff7bce7c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb =  xgboost.XGBClassifier(learning_rate=0.15120340125789705, n_estimators=50, max_depth=4, random_state=0, reg_alpha=3, reg_lambda=10,\n",
    "                            eval_metric='mlogloss')\n",
    "\n",
    "lgbm =  LGBMClassifier(learning_rate=0.2, max_depth=1, n_estimators=50, random_state=0,\n",
    "               reg_alpha=1, reg_lambda=1)\n",
    "\n",
    "cb = CatBoostClassifier(depth=4, iterations=50, learning_rate=0.1964188294579477, random_seed=seed, verbose=False)\n",
    "\n",
    "gb = GradientBoostingClassifier(learning_rate=0.19101624063861414, max_depth=1,\n",
    "                           max_features='auto', n_estimators=47,\n",
    "                           random_state=0)\n",
    "                       \n",
    "rf = RandomForestClassifier(criterion='entropy', max_depth=4, max_features='log2',\n",
    "                       n_estimators=24, random_state=0)\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=3, max_features='sqrt', random_state=0)\n",
    "\n",
    "et = ExtraTreesClassifier(criterion='entropy', max_depth=4, max_features='log2',\n",
    "                     n_estimators=10, random_state=0)\n",
    "\n",
    "knn = KNeighborsClassifier(metric='manhattan', n_neighbors=7)\n",
    "\n",
    "svc = SVC(C=999.9984985741586)\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, penalty='l1', random_state=0,\n",
    "                   solver='liblinear')\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "scoring = ['accuracy', 'balanced_accuracy', 'f1_weighted', \n",
    "          'precision_weighted','recall_weighted']\n",
    "\n",
    "inner_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True,  random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c6b1142-fa41-46ef-a672-2a145f61d4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking CV results for all scores: {'fit_time': array([1.77260208, 1.66073322, 1.75240588, 1.72378087, 1.73308182]), 'score_time': array([0.02458811, 0.02298594, 0.02501702, 0.02559614, 0.02425313]), 'test_accuracy': array([0.53947368, 0.55263158, 0.56      , 0.52      , 0.50666667]), 'test_balanced_accuracy': array([0.48174391, 0.46934985, 0.49176364, 0.44656863, 0.49607843]), 'test_f1_weighted': array([0.51086651, 0.52821096, 0.54187141, 0.49101215, 0.48976589]), 'test_precision_weighted': array([0.51907895, 0.5421123 , 0.56617544, 0.46571429, 0.48450956]), 'test_recall_weighted': array([0.53947368, 0.55263158, 0.56      , 0.52      , 0.50666667])}\n",
      "Accuracy CV Average 0.5394736842105263\n",
      "Balanced Accuracy CV Average 0.4817439096850862\n",
      "F1 CV Average 0.5108665092217725\n",
      "Precision CV Average 0.5190789473684211\n",
      "Recall CV Average 0.5394736842105263\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "    (\"XGBR\", xgb),\n",
    "    (\"GBR\", gb),\n",
    "    (\"RFR\", rf),\n",
    "    (\"LGBM\", lgbm),\n",
    "    (\"CB\", cb),\n",
    "    (\"ET\", et),\n",
    "    (\"DT\", dt),\n",
    "    (\"KNN\", knn),\n",
    "    (\"SVM\", svc),\n",
    "    (\"LR\", lr),\n",
    "\n",
    "]\n",
    "\n",
    "stacker = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator= xgboost.XGBClassifier(learning_rate=0.15120340125789705, n_estimators=50, max_depth=4, random_state=0, reg_alpha=3, reg_lambda=10,\n",
    "                            eval_metric='mlogloss')\n",
    ")\n",
    "cv_results = model_selection.cross_validate(\n",
    "        stacker, X, Y, cv=outer_cv, scoring=scoring\n",
    ")\n",
    "print(\"Stacking CV results for all scores:\", cv_results)\n",
    "print('Accuracy CV Average', np.median(cv_results['test_accuracy']))\n",
    "print('Balanced Accuracy CV Average', np.median(cv_results['test_balanced_accuracy'] ))\n",
    "print('F1 CV Average', np.median(cv_results['test_f1_weighted'] ))\n",
    "print('Precision CV Average', np.median(cv_results['test_precision_weighted'] ))\n",
    "print('Recall CV Average', np.median(cv_results['test_recall_weighted'] ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbb5ab3e-d099-4ee3-a9bb-38ca590b36f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier CV results for all scores: \n",
      " {'fit_time': array([4.05002213, 2.54948711, 2.65910196, 2.61676216, 2.64616489]), 'score_time': array([0.17299795, 0.16878319, 0.17158389, 0.172261  , 0.16837621]), 'test_accuracy': array([0.59210526, 0.52631579, 0.65333333, 0.42666667, 0.6       ]), 'test_balanced_accuracy': array([0.53894831, 0.42874097, 0.5951612 , 0.38022876, 0.53137255]), 'test_f1_weighted': array([0.53232678, 0.46869468, 0.62400825, 0.41022916, 0.54285917]), 'test_precision_weighted': array([0.53474861, 0.47841345, 0.66181762, 0.43244444, 0.59276596]), 'test_recall_weighted': array([0.59210526, 0.52631579, 0.65333333, 0.42666667, 0.6       ])} \n",
      "\n",
      "Bagging Accuracy CV Average 0.5921052631578947\n",
      "Bagging Balanced Accuracy CV Average 0.5313725490196078\n",
      "Bagging F1 CV Average 0.5323267755910267\n",
      "Bagging Precision CV Average 0.5347486093281986\n",
      "Bagging Recall CV Average 0.5921052631578947\n"
     ]
    }
   ],
   "source": [
    "bagging_xgbr = BaggingClassifier(base_estimator=xgb, n_estimators=10, oob_score=True, random_state=seed, n_jobs=-1)\n",
    "\n",
    "cv_results = model_selection.cross_validate(bagging_xgbr, X , Y, cv=outer_cv, scoring=scoring)\n",
    "print('Bagging Classifier CV results for all scores:', '\\n', cv_results, '\\n')\n",
    "print('Bagging Accuracy CV Average', np.median(cv_results['test_accuracy']))\n",
    "print('Bagging Balanced Accuracy CV Average', np.median(cv_results['test_balanced_accuracy'] ))\n",
    "print('Bagging F1 CV Average', np.median(cv_results['test_f1_weighted'] ))\n",
    "print('Bagging Precision CV Average', np.median(cv_results['test_precision_weighted'] ))\n",
    "print('Bagging Recall CV Average', np.median(cv_results['test_recall_weighted'] ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "340c998e-0135-4bbd-b33c-e084e96f3d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting CV results for all scores {'fit_time': array([0.3238709 , 0.48452425, 0.32647204, 0.29443717, 0.34964395]), 'score_time': array([0.02710986, 0.02485299, 0.02542996, 0.02642775, 0.02511096]), 'test_accuracy': array([0.57894737, 0.57894737, 0.64      , 0.53333333, 0.56      ]), 'test_balanced_accuracy': array([0.49627154, 0.46689886, 0.5476967 , 0.43970588, 0.48333333]), 'test_f1_weighted': array([0.49852902, 0.51189228, 0.58457811, 0.4681994 , 0.48605051]), 'test_precision_weighted': array([0.68098339, 0.53398693, 0.62879433, 0.48366667, 0.43817345]), 'test_recall_weighted': array([0.57894737, 0.57894737, 0.64      , 0.53333333, 0.56      ])}\n",
      "Accuracy CV Average 0.5789473684210527\n",
      "Balanced Accuracy CV Average 0.4833333333333334\n",
      "F1 CV Average 0.4985290179195997\n",
      "Precision CV Average 0.5339869281045753\n",
      "Recall CV Average 0.5789473684210527\n"
     ]
    }
   ],
   "source": [
    "model1 = xgb.fit(X_train, Y_train)\n",
    "model2 = gb.fit(X_train, Y_train)\n",
    "model3 = lgbm.fit(X_train, Y_train)\n",
    "model4 = cb.fit(X_train, Y_train)\n",
    "model5 = rf.fit(X_train, Y_train)\n",
    "model6 = et.fit(X_train, Y_train)\n",
    "model7 = dt.fit(X_train, Y_train)\n",
    "model8 = knn.fit(X_train, Y_train)\n",
    "model9 = svc.fit(X_train, Y_train)\n",
    "model10 = lr.fit(X_train, Y_train)\n",
    "\n",
    "vote = VotingClassifier([(\"xgbr\", model1), (\"gbr\", model2), (\"lgbm\", model3),\n",
    "                      (\"rf\", model5), (\"et\", model6),\n",
    "                       (\"dt\", model7), (\"knn\", model8), (\"svm\", model9),\n",
    "                       (\"lr\", model10)])\n",
    "\n",
    "cv_results = model_selection.cross_validate(\n",
    "        vote, X, Y, cv=outer_cv, scoring=scoring\n",
    ")\n",
    "print(\"Voting CV results for all scores\", cv_results)\n",
    "\n",
    "print('Accuracy CV Average', np.median(cv_results['test_accuracy']))\n",
    "print('Balanced Accuracy CV Average', np.median(cv_results['test_balanced_accuracy'] ))\n",
    "print('F1 CV Average', np.median(cv_results['test_f1_weighted'] ))\n",
    "print('Precision CV Average', np.median(cv_results['test_precision_weighted'] ))\n",
    "print('Recall CV Average', np.median(cv_results['test_recall_weighted'] ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b51f151-14ee-4f74-852c-69daf033d549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.33      0.10      0.15        10\n",
      "    probable       0.46      0.70      0.56        27\n",
      "    possible       0.25      0.12      0.17        16\n",
      "least likely       0.83      0.87      0.85        23\n",
      "\n",
      "    accuracy                           0.55        76\n",
      "   macro avg       0.47      0.45      0.43        76\n",
      "weighted avg       0.51      0.55      0.51        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['most likely', 'probable', 'possible','least likely']\n",
    "stacker.fit(X_train, Y_train)\n",
    "predictions = list(stacker.predict(X_test))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "623f89c5-2a87-49d6-a140-4b032cb3f08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.17      0.10      0.12        10\n",
      "    probable       0.47      0.81      0.59        27\n",
      "    possible       0.50      0.06      0.11        16\n",
      "least likely       0.81      0.74      0.77        23\n",
      "\n",
      "    accuracy                           0.54        76\n",
      "   macro avg       0.49      0.43      0.40        76\n",
      "weighted avg       0.54      0.54      0.48        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vote.fit(X_train, Y_train)\n",
    "predictions = list(vote.predict(X_test))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652c7636-e378-4abd-b084-bd39123d50e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_xgbr.fit(X_train, Y_train)\n",
    "predictions = list(bagging_xgbr.predict(X_test))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde857dc-d111-4ab3-81dc-3f9e66cf45d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
