{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb24d86f-592d-4c57-ba36-b71d868bb17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import sort\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.cluster import hierarchy\n",
    "import scipy.cluster\n",
    "from numpy import absolute, mean, sort, std\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import re\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "\n",
    "from sklearn import datasets, metrics, preprocessing, model_selection\n",
    "import sklearn.neighbors._base\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold,StratifiedKFold,RepeatedKFold, cross_val_score, cross_validate, cross_val_predict, GridSearchCV, RandomizedSearchCV, validation_curve, learning_curve\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, mean_absolute_error, max_error\n",
    "\n",
    "import skopt\n",
    "from skopt import BayesSearchCV \n",
    "\n",
    "from missingpy import MissForest\n",
    "\n",
    "import shap\n",
    "from BorutaShap import BorutaShap\n",
    "\n",
    "import xgboost\n",
    "import lightgbm\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier, StackingClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "\n",
    "seed = 0\n",
    "\n",
    "data = pd.read_csv(\"training_cleaned.csv\", header=0, sep=\",\")\n",
    "\n",
    "data[\"BPlabel_encoded\"] = data[\"BPlabel\"].map(\n",
    "    {\"most likely\": 1, \"probable\": 2, \"possible\":3,\"least likely\": 4}\n",
    ")\n",
    "Y = data[\"BPlabel_encoded\"]\n",
    "data = data.drop([\"BPlabel\"], 1)\n",
    "\n",
    "\n",
    "xgbr = xgboost.XGBClassifier(random_state=seed, objective='reg:squarederror', verbosity = 0, eval_metric='mlogloss') \n",
    "xgbr_params = {\n",
    "    'max_depth':  (1, 4), \n",
    "    'learning_rate': (0.01, 0.2, 'log-uniform'),  \n",
    "    'n_estimators':  (10, 50), \n",
    "    'reg_alpha':  (1, 10, 'log-uniform'), \n",
    "    'reg_lambda':  (1, 10, 'log-uniform')} \n",
    "\n",
    "lgbm = LGBMClassifier(random_state=seed)\n",
    "lgbm_params = {\n",
    "    \"max_depth\": (1, 4),\n",
    "    \"learning_rate\": (0.01, 0.2, \"log-uniform\"),\n",
    "    \"n_estimators\": (10, 50),\n",
    "    \"reg_alpha\": (1, 10, \"log-uniform\"),\n",
    "    \"reg_lambda\": (1, 10, \"log-uniform\"),\n",
    "}\n",
    "\n",
    "catboost = CatBoostClassifier(random_seed=seed, verbose=False)\n",
    "cat_params = {\n",
    "     \"iterations\": (10, 50),\n",
    "     'learning_rate': (0.01, 0.2, 'log-uniform'), \n",
    "     'depth':  (1, 4), \n",
    "}\n",
    "\n",
    "\n",
    "gbr = GradientBoostingClassifier(random_state=seed)\n",
    "gbr_params = {\n",
    "    'learning_rate': (0.01, 0.2),\n",
    "    'max_depth': (1, 4),\n",
    "    \"max_features\":[\"log2\",\"sqrt\", \"auto\"],\n",
    "    \"criterion\": [\"friedman_mse\", \"mse\"],\n",
    "    'n_estimators': (10, 50)\n",
    "    }\n",
    "\n",
    "rfr = RandomForestClassifier(random_state=seed)\n",
    "rfr_params={'n_estimators': (10, 50), \n",
    "             'max_features': ['sqrt', 'log2'],\n",
    "             'max_depth' : (1, 4),\n",
    "             'criterion' :['gini', 'entropy']} \n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=seed)\n",
    "dt_params= {\"criterion\": ['gini', 'entropy'],\n",
    "            'max_features': ['sqrt', 'log2'],\n",
    "            'max_depth' : (1, 4)}\n",
    "\n",
    "extra = ExtraTreesClassifier(random_state=seed)\n",
    "extra_params ={'n_estimators': (10, 50), \n",
    "             'max_features': ['sqrt', 'log2'],\n",
    "             'max_depth' : (1, 4),\n",
    "             'criterion' :['gini', 'entropy']}\n",
    "\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn_params = {\n",
    "    'n_neighbors':[7,9,11,13,15,17],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['euclidean','manhattan', 'minkowski']}\n",
    "\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', solver='liblinear',multi_class='auto',random_state=seed)\n",
    "lr_params= {\n",
    "    'penalty':['l1', 'l2'], \n",
    "    'C': [0.5, 1, 5, 10], \n",
    "    'max_iter':[500, 1000, 2500]}\n",
    "\n",
    "svc = SVC()\n",
    "svc_params = {\n",
    "    'kernel': ['rbf'],\n",
    "   'C': (1e0, 1e3),\n",
    "   'gamma': ['scale', 'auto']}\n",
    "\n",
    "inner_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "medians =[]\n",
    "models_list_balancedac = []\n",
    "scoring = ['accuracy', 'balanced_accuracy', 'f1_weighted', \n",
    "          'precision_weighted','recall_weighted']\n",
    "\n",
    "\n",
    "\n",
    "X = pd.read_csv(\"selected_features_training_data.csv\", header=0)\n",
    "\n",
    "X.columns = [\n",
    "    regex.sub(\"_\", col) if any(x in str(col) for x in set((\"[\", \"]\", \"<\"))) else col\n",
    "    for col in X.columns.values\n",
    "]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=0\n",
    ")\n",
    "\n",
    "df3 = pd.DataFrame(data= X, columns= X.columns)\n",
    "df3.columns = [\n",
    "    regex.sub(\"_\", col) if any(x in str(col) for x in set((\"[\", \"]\", \"<\"))) else col\n",
    "    for col in  X.columns.values\n",
    "]\n",
    "X_importance = X_test\n",
    "\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append(('XGBR', BayesSearchCV(xgbr, xgbr_params, cv=inner_cv,iid=False,n_jobs=1, random_state=seed))) \n",
    "models.append((\"LGBM\", BayesSearchCV(lgbm, lgbm_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n",
    "models.append((\"CB\", BayesSearchCV(catboost, cat_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n",
    "models.append(('GBR', BayesSearchCV(gbr, gbr_params, cv=inner_cv,iid=False, n_jobs=1, random_state=seed)))\n",
    "models.append(('RFR', BayesSearchCV(rfr, rfr_params, cv=inner_cv,iid=False, n_jobs=1, random_state=seed)))\n",
    "models.append(('DT', BayesSearchCV(dt, dt_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n",
    "models.append(('ExtraTrees', BayesSearchCV(extra, extra_params, cv=inner_cv, iid=False, n_jobs=1, random_state=seed)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd9b3357-21a3-4fdf-878b-fdc4cdca54dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBR Nested CV results for all scores: \n",
      " {'fit_time': array([250.45499706, 216.87853527, 202.06913996, 238.65334702,\n",
      "       251.4058938 , 219.38489294, 259.57282495, 274.15962505,\n",
      "       270.63423085, 246.43836784]), 'score_time': array([0.00625896, 0.00676608, 0.006814  , 0.00602484, 0.00634122,\n",
      "       0.00619698, 0.00629401, 0.00607109, 0.00648594, 0.00597525]), 'test_accuracy': array([0.65789474, 0.63157895, 0.57894737, 0.55263158, 0.71052632,\n",
      "       0.63157895, 0.47368421, 0.51351351, 0.62162162, 0.54054054]), 'test_balanced_accuracy': array([0.62777778, 0.6       , 0.48888889, 0.45      , 0.65      ,\n",
      "       0.56736111, 0.41458333, 0.40267857, 0.55347222, 0.52222222]), 'test_f1_weighted': array([0.64205786, 0.5936494 , 0.52869306, 0.48987854, 0.68280675,\n",
      "       0.60134628, 0.44278967, 0.47205577, 0.58139698, 0.49841017]), 'test_precision_weighted': array([0.67759543, 0.615311  , 0.55723684, 0.46710526, 0.70728406,\n",
      "       0.59896617, 0.44402919, 0.49081081, 0.61577162, 0.46616541]), 'test_recall_weighted': array([0.65789474, 0.63157895, 0.57894737, 0.55263158, 0.71052632,\n",
      "       0.63157895, 0.47368421, 0.51351351, 0.62162162, 0.54054054])} \n",
      "\n",
      "XGBR Accuracy Nested CV Average 0.6002844950213371\n",
      "XGBR Balanced Accuracy Nested CV Average 0.5378472222222221\n",
      "XGBR F1 Nested CV Average 0.5550450187834088\n",
      "XGBR Precision Nested CV Average 0.5781015037593985\n",
      "XGBR Recall Nested CV Average 0.6002844950213371\n",
      "\n",
      "\n",
      "Best Parameters: \n",
      "OrderedDict([('learning_rate', 0.15120340125789705), ('max_depth', 3), ('n_estimators', 50), ('reg_alpha', 3), ('reg_lambda', 10)])\n",
      "\n",
      "Best Estimator: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
      "              gamma=0, gpu_id=-1, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.15120340125789705,\n",
      "              max_delta_step=0, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=50, n_jobs=16,\n",
      "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
      "              reg_alpha=3, reg_lambda=10, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=0)\n",
      "\n",
      "\n",
      "LGBM Nested CV results for all scores: \n",
      " {'fit_time': array([224.51259494, 231.35774708, 226.60177112, 212.42392516,\n",
      "       218.50570989, 239.37172484, 221.95151305, 235.3598249 ,\n",
      "       285.38638377, 251.98752713]), 'score_time': array([0.00617814, 0.0061698 , 0.00608397, 0.00620198, 0.00625706,\n",
      "       0.00602913, 0.00652599, 0.00640512, 0.00731421, 0.00645423]), 'test_accuracy': array([0.57894737, 0.55263158, 0.60526316, 0.55263158, 0.60526316,\n",
      "       0.60526316, 0.5       , 0.56756757, 0.59459459, 0.59459459]), 'test_balanced_accuracy': array([0.52222222, 0.45      , 0.50555556, 0.45      , 0.51666667,\n",
      "       0.55069444, 0.4125    , 0.45892857, 0.51111111, 0.55555556]), 'test_f1_weighted': array([0.53644653, 0.46223848, 0.54731917, 0.48987854, 0.50733083,\n",
      "       0.57941646, 0.46561993, 0.52699804, 0.52672221, 0.55106776]), 'test_precision_weighted': array([0.55593437, 0.49977314, 0.59057018, 0.46710526, 0.46483254,\n",
      "       0.58016917, 0.43851855, 0.52330591, 0.525     , 0.52702703]), 'test_recall_weighted': array([0.57894737, 0.55263158, 0.60526316, 0.55263158, 0.60526316,\n",
      "       0.60526316, 0.5       , 0.56756757, 0.59459459, 0.59459459])} \n",
      "\n",
      "LGBM Accuracy Nested CV Average 0.5867709815078237\n",
      "LGBM Balanced Accuracy Nested CV Average 0.5083333333333333\n",
      "LGBM F1 Nested CV Average 0.5268601257221457\n",
      "LGBM Precision Nested CV Average 0.5241529573051312\n",
      "LGBM Recall Nested CV Average 0.5867709815078237\n",
      "\n",
      "\n",
      "Best Parameters: \n",
      "OrderedDict([('learning_rate', 0.2), ('max_depth', 1), ('n_estimators', 50), ('reg_alpha', 1), ('reg_lambda', 1)])\n",
      "\n",
      "Best Estimator: LGBMClassifier(learning_rate=0.2, max_depth=1, n_estimators=50, random_state=0,\n",
      "               reg_alpha=1, reg_lambda=1)\n",
      "\n",
      "\n",
      "CB Nested CV results for all scores: \n",
      " {'fit_time': array([77.38341308, 75.77907777, 77.75895977, 82.72059536, 73.5239768 ,\n",
      "       75.04024792, 75.24480295, 74.67772007, 69.86409497, 84.87528896]), 'score_time': array([0.00584006, 0.00561309, 0.00555801, 0.00601172, 0.00552607,\n",
      "       0.00614095, 0.00554323, 0.00557208, 0.00698185, 0.00609207]), 'test_accuracy': array([0.52631579, 0.57894737, 0.52631579, 0.47368421, 0.71052632,\n",
      "       0.60526316, 0.44736842, 0.59459459, 0.54054054, 0.54054054]), 'test_balanced_accuracy': array([0.45555556, 0.51111111, 0.41111111, 0.38888889, 0.65      ,\n",
      "       0.48611111, 0.38958333, 0.47678571, 0.44444444, 0.45555556]), 'test_f1_weighted': array([0.43837464, 0.50971942, 0.43453145, 0.38820736, 0.68180358,\n",
      "       0.50929798, 0.43233083, 0.54516055, 0.45681772, 0.46308677]), 'test_precision_weighted': array([0.40032565, 0.51315789, 0.38157895, 0.32951945, 0.70614035,\n",
      "       0.56930581, 0.44298246, 0.56      , 0.42097532, 0.41583876]), 'test_recall_weighted': array([0.52631579, 0.57894737, 0.52631579, 0.47368421, 0.71052632,\n",
      "       0.60526316, 0.44736842, 0.59459459, 0.54054054, 0.54054054])} \n",
      "\n",
      "CB Accuracy Nested CV Average 0.5405405405405406\n",
      "CB Balanced Accuracy Nested CV Average 0.45555555555555555\n",
      "CB F1 Nested CV Average 0.4599522454785613\n",
      "CB Precision Nested CV Average 0.4319788896447936\n",
      "CB Recall Nested CV Average 0.5405405405405406\n",
      "\n",
      "\n",
      "Best Parameters: \n",
      "OrderedDict([('depth', 4), ('iterations', 50), ('learning_rate', 0.1964188294579477)])\n",
      "\n",
      "Best Estimator: <catboost.core.CatBoostClassifier object at 0x7fbe0cd7c850>\n",
      "\n",
      "\n",
      "GBR Nested CV results for all scores: \n",
      " {'fit_time': array([150.40721107, 148.95721102, 145.28677607, 151.13391685,\n",
      "       133.21414971, 148.6793263 , 148.18973684, 171.79738331,\n",
      "       154.42850399, 154.0446732 ]), 'score_time': array([0.00636888, 0.00735402, 0.00639606, 0.00666404, 0.00635719,\n",
      "       0.00549483, 0.00716186, 0.00701475, 0.00537992, 0.00578666]), 'test_accuracy': array([0.60526316, 0.55263158, 0.57894737, 0.55263158, 0.65789474,\n",
      "       0.60526316, 0.36842105, 0.59459459, 0.56756757, 0.64864865]), 'test_balanced_accuracy': array([0.52777778, 0.47222222, 0.47777778, 0.46111111, 0.59444444,\n",
      "       0.55069444, 0.30625   , 0.46339286, 0.46111111, 0.55555556]), 'test_f1_weighted': array([0.53478783, 0.47441046, 0.49579832, 0.48067284, 0.60330111,\n",
      "       0.57941646, 0.36876505, 0.52343075, 0.48779042, 0.57336461]), 'test_precision_weighted': array([0.6819102 , 0.49131449, 0.47770468, 0.44360902, 0.63062201,\n",
      "       0.58016917, 0.37830871, 0.56056056, 0.51621622, 0.55162855]), 'test_recall_weighted': array([0.60526316, 0.55263158, 0.57894737, 0.55263158, 0.65789474,\n",
      "       0.60526316, 0.36842105, 0.59459459, 0.56756757, 0.64864865])} \n",
      "\n",
      "GBR Accuracy Nested CV Average 0.5867709815078237\n",
      "GBR Balanced Accuracy Nested CV Average 0.475\n",
      "GBR F1 Nested CV Average 0.5096145335743615\n",
      "GBR Precision Nested CV Average 0.5339223839223839\n",
      "GBR Recall Nested CV Average 0.5867709815078237\n",
      "\n",
      "\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'friedman_mse'), ('learning_rate', 0.19101624063861414), ('max_depth', 1), ('max_features', 'auto'), ('n_estimators', 47)])\n",
      "\n",
      "Best Estimator: GradientBoostingClassifier(learning_rate=0.19101624063861414, max_depth=1,\n",
      "                           max_features='auto', n_estimators=47,\n",
      "                           random_state=0)\n",
      "\n",
      "\n",
      "RFR Nested CV results for all scores: \n",
      " {'fit_time': array([107.88616323, 109.9429822 , 106.496907  ,  99.35746408,\n",
      "        96.89489102, 101.18175507,  99.08006287,  98.55623698,\n",
      "       106.23841619, 101.96804595]), 'score_time': array([0.01225996, 0.01409101, 0.00932217, 0.00890279, 0.01203895,\n",
      "       0.01066494, 0.01009297, 0.0092411 , 0.00713301, 0.00761294]), 'test_accuracy': array([0.52631579, 0.52631579, 0.60526316, 0.47368421, 0.68421053,\n",
      "       0.63157895, 0.47368421, 0.59459459, 0.51351351, 0.62162162]), 'test_balanced_accuracy': array([0.46666667, 0.4       , 0.49444444, 0.38888889, 0.6       ,\n",
      "       0.51736111, 0.36666667, 0.49553571, 0.43888889, 0.53888889]), 'test_f1_weighted': array([0.43452381, 0.4127967 , 0.51430389, 0.38562007, 0.58839654,\n",
      "       0.56234064, 0.39381671, 0.55494175, 0.46258451, 0.55694981]), 'test_precision_weighted': array([0.39586466, 0.36184211, 0.55028195, 0.32517483, 0.57246964,\n",
      "       0.78712406, 0.33991228, 0.62756757, 0.44643735, 0.56216216]), 'test_recall_weighted': array([0.52631579, 0.52631579, 0.60526316, 0.47368421, 0.68421053,\n",
      "       0.63157895, 0.47368421, 0.59459459, 0.51351351, 0.62162162])} \n",
      "\n",
      "RFR Accuracy Nested CV Average 0.5604551920341394\n",
      "RFR Balanced Accuracy Nested CV Average 0.48055555555555557\n",
      "RFR F1 Nested CV Average 0.48844419825879004\n",
      "RFR Precision Nested CV Average 0.4983596506622822\n",
      "RFR Recall Nested CV Average 0.5604551920341394\n",
      "\n",
      "\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'entropy'), ('max_depth', 4), ('max_features', 'log2'), ('n_estimators', 24)])\n",
      "\n",
      "Best Estimator: RandomForestClassifier(criterion='entropy', max_depth=4, max_features='log2',\n",
      "                       n_estimators=24, random_state=0)\n",
      "\n",
      "\n",
      "DT Nested CV results for all scores: \n",
      " {'fit_time': array([66.06863594, 62.80467582, 67.09777188, 64.72369504, 61.4919641 ,\n",
      "       59.33201885, 66.25358391, 60.54034185, 65.84222698, 62.51217794]), 'score_time': array([0.00619316, 0.00561309, 0.00634503, 0.006109  , 0.00701404,\n",
      "       0.00600505, 0.00597906, 0.00567889, 0.00588894, 0.00735807]), 'test_accuracy': array([0.44736842, 0.47368421, 0.5       , 0.44736842, 0.57894737,\n",
      "       0.57894737, 0.47368421, 0.54054054, 0.45945946, 0.51351351]), 'test_balanced_accuracy': array([0.36111111, 0.34444444, 0.39444444, 0.36111111, 0.5       ,\n",
      "       0.46180556, 0.37916667, 0.40714286, 0.36111111, 0.40555556]), 'test_f1_weighted': array([0.371266  , 0.37751196, 0.41854637, 0.36032389, 0.55454743,\n",
      "       0.51294904, 0.45028056, 0.43899714, 0.40445709, 0.43352664]), 'test_precision_weighted': array([0.31758373, 0.34845735, 0.43947368, 0.30263158, 0.61052632,\n",
      "       0.76315789, 0.44761905, 0.40610438, 0.36332046, 0.38040541]), 'test_recall_weighted': array([0.44736842, 0.47368421, 0.5       , 0.44736842, 0.57894737,\n",
      "       0.57894737, 0.47368421, 0.54054054, 0.45945946, 0.51351351])} \n",
      "\n",
      "DT Accuracy Nested CV Average 0.48684210526315785\n",
      "DT Balanced Accuracy Nested CV Average 0.3868055555555555\n",
      "DT F1 Nested CV Average 0.42603650498387347\n",
      "DT Precision Nested CV Average 0.39325489282385834\n",
      "DT Recall Nested CV Average 0.48684210526315785\n",
      "\n",
      "\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'gini'), ('max_depth', 3), ('max_features', 'sqrt')])\n",
      "\n",
      "Best Estimator: DecisionTreeClassifier(max_depth=3, max_features='sqrt', random_state=0)\n",
      "\n",
      "\n",
      "ExtraTrees Nested CV results for all scores: \n",
      " {'fit_time': array([ 92.50245404, 105.23125291, 114.17857409,  83.38551116,\n",
      "        85.76805878,  89.96657896,  88.48614597,  97.70218801,\n",
      "        94.57993078,  96.98061013]), 'score_time': array([0.00756097, 0.00793195, 0.00747085, 0.00709677, 0.00730801,\n",
      "       0.00732684, 0.00750899, 0.00551391, 0.00763321, 0.005229  ]), 'test_accuracy': array([0.47368421, 0.57894737, 0.55263158, 0.5       , 0.57894737,\n",
      "       0.55263158, 0.5       , 0.56756757, 0.51351351, 0.48648649]), 'test_balanced_accuracy': array([0.43333333, 0.48888889, 0.41666667, 0.39444444, 0.48888889,\n",
      "       0.45555556, 0.375     , 0.45714286, 0.40555556, 0.4       ]), 'test_f1_weighted': array([0.40888405, 0.48088972, 0.43034056, 0.42611191, 0.48120301,\n",
      "       0.48803828, 0.39852958, 0.48948949, 0.43265955, 0.41891892]), 'test_precision_weighted': array([0.37776506, 0.49473684, 0.375     , 0.38942308, 0.4375    ,\n",
      "       0.54582577, 0.33569501, 0.5472973 , 0.41478979, 0.38558559]), 'test_recall_weighted': array([0.47368421, 0.57894737, 0.55263158, 0.5       , 0.57894737,\n",
      "       0.55263158, 0.5       , 0.56756757, 0.51351351, 0.48648649])} \n",
      "\n",
      "ExtraTrees Accuracy Nested CV Average 0.533072546230441\n",
      "ExtraTrees Balanced Accuracy Nested CV Average 0.425\n",
      "ExtraTrees F1 Nested CV Average 0.4315000537910755\n",
      "ExtraTrees Precision Nested CV Average 0.40210643335643337\n",
      "ExtraTrees Recall Nested CV Average 0.533072546230441\n",
      "\n",
      "\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'entropy'), ('max_depth', 4), ('max_features', 'log2'), ('n_estimators', 10)])\n",
      "\n",
      "Best Estimator: ExtraTreesClassifier(criterion='entropy', max_depth=4, max_features='log2',\n",
      "                     n_estimators=10, random_state=0)\n",
      "\n",
      "\n",
      "All results: [array([0.62777778, 0.6       , 0.48888889, 0.45      , 0.65      ,\n",
      "       0.56736111, 0.41458333, 0.40267857, 0.55347222, 0.52222222]), array([0.52222222, 0.45      , 0.50555556, 0.45      , 0.51666667,\n",
      "       0.55069444, 0.4125    , 0.45892857, 0.51111111, 0.55555556]), array([0.45555556, 0.51111111, 0.41111111, 0.38888889, 0.65      ,\n",
      "       0.48611111, 0.38958333, 0.47678571, 0.44444444, 0.45555556]), array([0.52777778, 0.47222222, 0.47777778, 0.46111111, 0.59444444,\n",
      "       0.55069444, 0.30625   , 0.46339286, 0.46111111, 0.55555556]), array([0.46666667, 0.4       , 0.49444444, 0.38888889, 0.6       ,\n",
      "       0.51736111, 0.36666667, 0.49553571, 0.43888889, 0.53888889]), array([0.36111111, 0.34444444, 0.39444444, 0.36111111, 0.5       ,\n",
      "       0.46180556, 0.37916667, 0.40714286, 0.36111111, 0.40555556]), array([0.43333333, 0.48888889, 0.41666667, 0.39444444, 0.48888889,\n",
      "       0.45555556, 0.375     , 0.45714286, 0.40555556, 0.4       ])]\n",
      "Best model by median balanced accuracy: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
      "              gamma=0, gpu_id=-1, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.15120340125789705,\n",
      "              max_delta_step=0, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=50, n_jobs=16,\n",
      "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
      "              reg_alpha=3, reg_lambda=10, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=0)\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    nested_cv_results = model_selection.cross_validate(model, X , Y, cv=outer_cv, scoring=scoring, error_score=\"raise\")\n",
    "    nested_cv_results2 = model_selection.cross_val_score(model, X , Y, cv=outer_cv, scoring='balanced_accuracy', error_score=\"raise\")\n",
    "    results.append(nested_cv_results2)\n",
    "    names.append(name)\n",
    "    print(name, 'Nested CV results for all scores:', '\\n', nested_cv_results, '\\n')\n",
    "    print(name, 'Accuracy Nested CV Average', np.median(nested_cv_results['test_accuracy']))\n",
    "    print(name, 'Balanced Accuracy Nested CV Average', np.median(nested_cv_results['test_balanced_accuracy'] ))\n",
    "    print(name, 'F1 Nested CV Average', np.median(nested_cv_results['test_f1_weighted'] ))\n",
    "    print(name, 'Precision Nested CV Average', np.median(nested_cv_results['test_precision_weighted'] ))\n",
    "    print(name, 'Recall Nested CV Average', np.median(nested_cv_results['test_recall_weighted'] ))\n",
    "    model.fit(X, Y)\n",
    "    print('\\n')\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print(\"Best Estimator:\", model.best_estimator_)\n",
    "    best_model = model.best_estimator_\n",
    "    print('\\n')\n",
    "    best_model.fit(X_train, Y_train)\n",
    "    y_pred_train = best_model.predict(X_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    best_model.fit(X, Y)\n",
    "    median_balancedac = np.median(nested_cv_results['test_balanced_accuracy'])\n",
    "    models_list_balancedac.append((best_model, median_balancedac))\n",
    "\n",
    "\n",
    "print('All results:', results)         \n",
    "\n",
    "best_model1, best_balancedac = sorted(models_list_balancedac, key = lambda x: x[1], reverse=True)[0]\n",
    "print('Best model by median balanced accuracy:',best_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4346c82-5d3f-4f3b-bfbf-ba76a6dfbdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Nested CV results for all scores: \n",
      " {'fit_time': array([59.88663888, 63.73879576, 68.38802409, 60.20594692, 63.12526417,\n",
      "       63.49519682, 70.21255207, 70.45793295, 63.79241109, 73.39909196]), 'score_time': array([0.00652909, 0.00654817, 0.00686884, 0.00753212, 0.00664306,\n",
      "       0.00684118, 0.00684905, 0.00632405, 0.00675488, 0.00529814]), 'test_accuracy': array([0.42105263, 0.57894737, 0.55263158, 0.44736842, 0.44736842,\n",
      "       0.63157895, 0.44736842, 0.51351351, 0.48648649, 0.51351351]), 'test_balanced_accuracy': array([0.4       , 0.53333333, 0.47222222, 0.37222222, 0.42777778,\n",
      "       0.59722222, 0.36458333, 0.45535714, 0.42152778, 0.48680556]), 'test_f1_weighted': array([0.36184211, 0.53292992, 0.49890266, 0.36687307, 0.41242236,\n",
      "       0.61904762, 0.38840156, 0.4887764 , 0.4499667 , 0.49115418]), 'test_precision_weighted': array([0.32631579, 0.54094751, 0.51076555, 0.3132964 , 0.40023135,\n",
      "       0.62030075, 0.3622291 , 0.55610996, 0.43243243, 0.47690418]), 'test_recall_weighted': array([0.42105263, 0.57894737, 0.55263158, 0.44736842, 0.44736842,\n",
      "       0.63157895, 0.44736842, 0.51351351, 0.48648649, 0.51351351])} \n",
      "\n",
      "KNN Accuracy Nested CV Average 0.5\n",
      "KNN Balanced Accuracy Nested CV Average 0.4415674603174603\n",
      "KNN F1 Nested CV Average 0.46937154931544833\n",
      "KNN Precision Nested CV Average 0.45466830466830466\n",
      "KNN Recall Nested CV Average 0.5\n",
      "\n",
      "\n",
      "Best Parameters: \n",
      "OrderedDict([('metric', 'manhattan'), ('n_neighbors', 7), ('weights', 'uniform')])\n",
      "\n",
      "Best Estimator: KNeighborsClassifier(metric='manhattan', n_neighbors=7)\n",
      "\n",
      "\n",
      "SVC Nested CV results for all scores: \n",
      " {'fit_time': array([62.47181177, 68.1805439 , 66.74134994, 65.76282692, 69.45663404,\n",
      "       64.72552514, 70.803864  , 71.02295518, 69.31913209, 61.38422608]), 'score_time': array([0.00631309, 0.00605106, 0.00434399, 0.00611997, 0.005867  ,\n",
      "       0.0042398 , 0.00648308, 0.00626469, 0.00569391, 0.00645876]), 'test_accuracy': array([0.5       , 0.55263158, 0.60526316, 0.36842105, 0.52631579,\n",
      "       0.68421053, 0.44736842, 0.62162162, 0.48648649, 0.59459459]), 'test_balanced_accuracy': array([0.46111111, 0.52777778, 0.50555556, 0.33333333, 0.46666667,\n",
      "       0.62986111, 0.4       , 0.53303571, 0.40347222, 0.55555556]), 'test_f1_weighted': array([0.45449945, 0.49572267, 0.55165913, 0.3183871 , 0.45887278,\n",
      "       0.67324193, 0.42985085, 0.61747041, 0.45272684, 0.55405405]), 'test_precision_weighted': array([0.44247638, 0.45071231, 0.61907895, 0.32072368, 0.41558349,\n",
      "       0.6875    , 0.4335971 , 0.63738739, 0.42987198, 0.52992278]), 'test_recall_weighted': array([0.5       , 0.55263158, 0.60526316, 0.36842105, 0.52631579,\n",
      "       0.68421053, 0.44736842, 0.62162162, 0.48648649, 0.59459459])} \n",
      "\n",
      "SVC Accuracy Nested CV Average 0.5394736842105263\n",
      "SVC Balanced Accuracy Nested CV Average 0.4861111111111111\n",
      "SVC F1 Nested CV Average 0.4772977246804035\n",
      "SVC Precision Nested CV Average 0.44659434517467755\n",
      "SVC Recall Nested CV Average 0.5394736842105263\n",
      "\n",
      "\n",
      "Best Parameters: \n",
      "OrderedDict([('C', 999.9984985741586), ('gamma', 'scale'), ('kernel', 'rbf')])\n",
      "\n",
      "Best Estimator: SVC(C=999.9984985741586)\n",
      "\n",
      "\n",
      "LR Nested CV results for all scores: \n",
      " {'fit_time': array([63.62674713, 66.00385118, 60.43375182, 68.29806805, 63.60478687,\n",
      "       62.74158788, 67.68110776, 63.74498892, 63.80158472, 65.75677705]), 'score_time': array([0.00473094, 0.00436878, 0.00418925, 0.00442004, 0.00459623,\n",
      "       0.0040729 , 0.00416589, 0.00542593, 0.0045042 , 0.0033021 ]), 'test_accuracy': array([0.42105263, 0.52631579, 0.55263158, 0.44736842, 0.47368421,\n",
      "       0.55263158, 0.47368421, 0.51351351, 0.40540541, 0.54054054]), 'test_balanced_accuracy': array([0.41111111, 0.47777778, 0.46111111, 0.37222222, 0.41111111,\n",
      "       0.43055556, 0.36666667, 0.42142857, 0.37222222, 0.43333333]), 'test_f1_weighted': array([0.39103391, 0.48909774, 0.46654135, 0.34894737, 0.3995958 ,\n",
      "       0.45629699, 0.37617729, 0.44124344, 0.35574918, 0.46257125]), 'test_precision_weighted': array([0.54448622, 0.68026316, 0.43032297, 0.28759398, 0.35117729,\n",
      "       0.52443609, 0.31197559, 0.42324324, 0.31709341, 0.43018018]), 'test_recall_weighted': array([0.42105263, 0.52631579, 0.55263158, 0.44736842, 0.47368421,\n",
      "       0.55263158, 0.47368421, 0.51351351, 0.40540541, 0.54054054])} \n",
      "\n",
      "LR Accuracy Nested CV Average 0.49359886201991465\n",
      "LR Balanced Accuracy Nested CV Average 0.41626984126984123\n",
      "LR F1 Nested CV Average 0.4204196222385077\n",
      "LR Precision Nested CV Average 0.42671171171171174\n",
      "LR Recall Nested CV Average 0.49359886201991465\n",
      "\n",
      "\n",
      "Best Parameters: \n",
      "OrderedDict([('C', 1.0), ('max_iter', 1000), ('penalty', 'l1')])\n",
      "\n",
      "Best Estimator: LogisticRegression(max_iter=1000, penalty='l1', random_state=0,\n",
      "                   solver='liblinear')\n",
      "\n",
      "\n",
      "All results: [array([0.4       , 0.53333333, 0.47222222, 0.37222222, 0.42777778,\n",
      "       0.59722222, 0.36458333, 0.45535714, 0.42152778, 0.48680556]), array([0.46111111, 0.5       , 0.50555556, 0.33333333, 0.46666667,\n",
      "       0.62986111, 0.3       , 0.53303571, 0.40347222, 0.51805556]), array([0.41111111, 0.47777778, 0.46111111, 0.37222222, 0.41111111,\n",
      "       0.43055556, 0.36666667, 0.42142857, 0.37222222, 0.43333333])]\n",
      "Best model by median balanced accuracy: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
      "              gamma=0, gpu_id=-1, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.15120340125789705,\n",
      "              max_delta_step=0, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=50, n_jobs=16,\n",
      "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
      "              reg_alpha=3, reg_lambda=10, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=0)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "othermodels = []\n",
    "\n",
    "othermodels.append(('KNN', BayesSearchCV(knn, knn_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "othermodels.append(('SVC', BayesSearchCV(svc, svc_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "othermodels.append(('LR', BayesSearchCV(lr, lr_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "\n",
    "X2 = MinMaxScaler().fit_transform(X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X2, Y, test_size=0.2, random_state=seed)\n",
    "\n",
    "df3 = pd.DataFrame(data= X2, columns= X.columns)\n",
    "df3.columns = [\n",
    "    regex.sub(\"_\", col) if any(x in str(col) for x in set((\"[\", \"]\", \"<\"))) else col\n",
    "    for col in  X.columns.values\n",
    "]\n",
    "X_importance = df3\n",
    "\n",
    "for name, model in othermodels:\n",
    "    nested_cv_results = model_selection.cross_validate(model, X2 , Y, cv=outer_cv, scoring=scoring, error_score=\"raise\")\n",
    "    nested_cv_results2 = model_selection.cross_val_score(model, X2 , Y, cv=outer_cv, scoring='balanced_accuracy', error_score=\"raise\")\n",
    "    results.append(nested_cv_results2)\n",
    "    names.append(name)\n",
    "    print(name, 'Nested CV results for all scores:', '\\n', nested_cv_results, '\\n')\n",
    "    print(name, 'Accuracy Nested CV Average', np.median(nested_cv_results['test_accuracy']))\n",
    "    print(name, 'Balanced Accuracy Nested CV Average', np.median(nested_cv_results['test_balanced_accuracy'] ))\n",
    "    print(name, 'F1 Nested CV Average', np.median(nested_cv_results['test_f1_weighted'] ))\n",
    "    print(name, 'Precision Nested CV Average', np.median(nested_cv_results['test_precision_weighted'] ))\n",
    "    print(name, 'Recall Nested CV Average', np.median(nested_cv_results['test_recall_weighted'] ))\n",
    "    model.fit(X2, Y)\n",
    "    print('\\n')\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print(\"Best Estimator:\", model.best_estimator_)\n",
    "    best_model = model.best_estimator_\n",
    "    print('\\n')\n",
    "    best_model.fit(X_train, Y_train)\n",
    "    y_pred_train = best_model.predict(X_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    best_model.fit(X2, Y)\n",
    "    median_balancedac = np.median(nested_cv_results['test_balanced_accuracy'])\n",
    "    models_list_balancedac.append((best_model, median_balancedac))\n",
    "\n",
    "\n",
    "print('All results:', results)   \n",
    "\n",
    "\n",
    "best_model1, best_balancedac = sorted(models_list_balancedac, key = lambda x: x[1], reverse=True)[0]\n",
    "print('Best model by median balanced accuracy:', best_model1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5e3c827-1eb2-412d-93f1-dfecfc929d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb =  xgboost.XGBClassifier(learning_rate=0.15120340125789705, n_estimators=50, max_depth=4, random_state=0, reg_alpha=3, reg_lambda=10)\n",
    "\n",
    "lgbm =  LGBMClassifier(learning_rate=0.2, max_depth=1, n_estimators=50, random_state=0,\n",
    "               reg_alpha=1, reg_lambda=1)\n",
    "\n",
    "cb = CatBoostClassifier(depth=4, iterations=50, learning_rate=0.1964188294579477, random_seed=seed, verbose=False)\n",
    "\n",
    "gb = GradientBoostingClassifier(learning_rate=0.19101624063861414, max_depth=1,\n",
    "                           max_features='auto', n_estimators=47,\n",
    "                           random_state=0)\n",
    "                       \n",
    "rf = RandomForestClassifier(criterion='entropy', max_depth=4, max_features='log2',\n",
    "                       n_estimators=24, random_state=0)\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=3, max_features='sqrt', random_state=0)\n",
    "\n",
    "et = ExtraTreesClassifier(criterion='entropy', max_depth=4, max_features='log2',\n",
    "                     n_estimators=10, random_state=0)\n",
    "\n",
    "knn = KNeighborsClassifier(metric='manhattan', n_neighbors=7)\n",
    "\n",
    "svc = SVC(C=999.9984985741586)\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, penalty='l1', random_state=0,\n",
    "                   solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b96defa-1c55-46fd-bc79-810f9de963f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:42] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.33      0.10      0.15        10\n",
      "    probable       0.55      0.81      0.66        27\n",
      "    possible       0.33      0.19      0.24        16\n",
      "least likely       0.88      0.91      0.89        23\n",
      "\n",
      "    accuracy                           0.62        76\n",
      "   macro avg       0.52      0.50      0.49        76\n",
      "weighted avg       0.57      0.62      0.57        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['most likely', 'probable', 'possible','least likely']\n",
    "xgb.fit(X_train, Y_train)\n",
    "predictions = list(xgb.predict(X_test))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9973cc4-5114-4f07-947d-2964f1587a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.17      0.10      0.12        10\n",
      "    probable       0.50      0.78      0.61        27\n",
      "    possible       0.50      0.19      0.27        16\n",
      "least likely       0.82      0.78      0.80        23\n",
      "\n",
      "    accuracy                           0.57        76\n",
      "   macro avg       0.50      0.46      0.45        76\n",
      "weighted avg       0.55      0.57      0.53        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm.fit(X_train, Y_train)\n",
    "predictions = list(lgbm.predict(X_test))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f53b7cbe-d685-4831-b1b6-a77668a2b6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.00      0.00      0.00        10\n",
      "    probable       0.50      0.70      0.58        27\n",
      "    possible       0.27      0.19      0.22        16\n",
      "least likely       0.79      0.83      0.81        23\n",
      "\n",
      "    accuracy                           0.54        76\n",
      "   macro avg       0.39      0.43      0.40        76\n",
      "weighted avg       0.47      0.54      0.50        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cb.fit(X_train, Y_train)\n",
    "predictions = list(cb.predict(X_test))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc220b5b-4e81-4761-a519-74acf94ab3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.17      0.10      0.12        10\n",
      "    probable       0.49      0.70      0.58        27\n",
      "    possible       0.33      0.12      0.18        16\n",
      "least likely       0.80      0.87      0.83        23\n",
      "\n",
      "    accuracy                           0.55        76\n",
      "   macro avg       0.45      0.45      0.43        76\n",
      "weighted avg       0.51      0.55      0.51        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb.fit(X_train, Y_train)\n",
    "predictions = list(gb.predict(X_test))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a01e88a-dd17-4e23-8790-8d95502948d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.00      0.00      0.00        10\n",
      "    probable       0.51      0.85      0.64        27\n",
      "    possible       0.33      0.06      0.11        16\n",
      "least likely       0.84      0.91      0.87        23\n",
      "\n",
      "    accuracy                           0.59        76\n",
      "   macro avg       0.42      0.46      0.40        76\n",
      "weighted avg       0.51      0.59      0.51        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train, Y_train)\n",
    "predictions = list(rf.predict(X_test))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97c3a084-0b3c-4415-ad33-9cd027e97636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.00      0.00      0.00        10\n",
      "    probable       0.44      0.89      0.59        27\n",
      "    possible       0.00      0.00      0.00        16\n",
      "least likely       0.73      0.70      0.71        23\n",
      "\n",
      "    accuracy                           0.53        76\n",
      "   macro avg       0.29      0.40      0.33        76\n",
      "weighted avg       0.38      0.53      0.43        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt.fit(X_train, Y_train)\n",
    "predictions = list(dt.predict(X_test))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2334675a-3ba1-4079-a255-1cf943d7d291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.25      0.10      0.14        10\n",
      "    probable       0.45      0.89      0.60        27\n",
      "    possible       0.00      0.00      0.00        16\n",
      "least likely       0.74      0.61      0.67        23\n",
      "\n",
      "    accuracy                           0.51        76\n",
      "   macro avg       0.36      0.40      0.35        76\n",
      "weighted avg       0.42      0.51      0.43        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "et.fit(X_train, Y_train)\n",
    "predictions = list(et.predict(X_test))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4e81dfd-c225-46eb-89e4-383ac71d32e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.00      0.00      0.00        10\n",
      "    probable       0.35      0.44      0.39        27\n",
      "    possible       0.14      0.06      0.09        16\n",
      "least likely       0.61      0.74      0.67        23\n",
      "\n",
      "    accuracy                           0.39        76\n",
      "   macro avg       0.28      0.31      0.29        76\n",
      "weighted avg       0.34      0.39      0.36        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X_train, Y_train)\n",
    "predictions = list(knn.predict(X_test))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63c511aa-8f36-471e-a71e-eb2d8a8945ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.21      0.30      0.25        10\n",
      "    probable       0.35      0.41      0.38        27\n",
      "    possible       0.23      0.19      0.21        16\n",
      "least likely       0.78      0.61      0.68        23\n",
      "\n",
      "    accuracy                           0.41        76\n",
      "   macro avg       0.39      0.38      0.38        76\n",
      "weighted avg       0.44      0.41      0.42        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc.fit(X_train, Y_train)\n",
    "predictions = list(svc.predict(X_test))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d67883c-a092-4289-8878-b54e2fee3a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.00      0.00      0.00        10\n",
      "    probable       0.45      0.70      0.55        27\n",
      "    possible       0.33      0.06      0.11        16\n",
      "least likely       0.52      0.61      0.56        23\n",
      "\n",
      "    accuracy                           0.45        76\n",
      "   macro avg       0.33      0.34      0.30        76\n",
      "weighted avg       0.39      0.45      0.39        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train, Y_train)\n",
    "predictions = list(lr.predict(X_test))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d850b3d5-1a6e-4302-b8ef-b7c7a2ebf0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
