{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Machine Learning for Prioritizing Blood Pressure Genes__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import sort\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import statsmodels.api as sm\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "import statsmodels.stats.api as sms\n",
    "import xgboost\n",
    "from sklearn import datasets, metrics, model_selection, preprocessing\n",
    "from sklearn.ensemble import (\n",
    "    BaggingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    KFold,\n",
    "    RandomizedSearchCV,\n",
    "    RepeatedKFold,\n",
    "    cross_val_predict,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    learning_curve,\n",
    "    train_test_split,\n",
    "    validation_curve,\n",
    ")\n",
    "\n",
    "\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, BorderlineSMOTE, SVMSMOTE, SMOTENC, RandomOverSampler\n",
    "from imblearn.base import BaseSampler\n",
    "from imblearn.datasets import make_imbalance\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.mpl.rcParams[\"figure.figsize\"] = (15.0, 9.0)\n",
    "\n",
    "import warnings\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "from warnings import filterwarnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"2021-11-19_training_cleaned.csv\", header=0, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327, 109)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['BPlabel_encoded'] = data['BPlabel'].map( {'most likely':1,'probable':2, 'possible':3, 'least likely':4})\n",
    "Y = data[\"BPlabel_encoded\"] \n",
    "Y2 = Y\n",
    "data = data.drop([\"BPlabel\"],1)\n",
    "data.shape  #Data has IPA and ensembl features without possible label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"2021-11-19_imputed_training_data.csv\", header=0)\n",
    "X.columns = [\n",
    "    regex.sub(\"_\", col) if any(x in str(col) for x in set((\"[\", \"]\", \"<\"))) else col\n",
    "    for col in X.columns.values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, the shape of X: (327, 107)\n",
      "Before OverSampling, the shape of y: (327,) \n",
      "\n",
      "After OverSampling, the shape of X: (596, 107)\n",
      "After OverSampling, the shape of y: (596,) \n",
      "\n",
      "After OverSampling, counts of label '1': 149\n",
      "After OverSampling, counts of label '2': 149\n",
      "After OverSampling, counts of label '3': 149\n",
      "After OverSampling, counts of label '4': 149\n"
     ]
    }
   ],
   "source": [
    "print('Before OverSampling, the shape of X: {}'.format(X.shape))\n",
    "print('Before OverSampling, the shape of y: {} \\n'.format(Y.shape))\n",
    "\n",
    "sm = SMOTE(random_state=seed)\n",
    "X, Y = sm.fit_resample(X, Y)\n",
    "\n",
    "print('After OverSampling, the shape of X: {}'.format(X.shape))\n",
    "print('After OverSampling, the shape of y: {} \\n'.format(Y.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(Y==1)))\n",
    "print(\"After OverSampling, counts of label '2': {}\".format(sum(Y==2)))\n",
    "print(\"After OverSampling, counts of label '3': {}\".format(sum(Y==3)))\n",
    "print(\"After OverSampling, counts of label '4': {}\".format(sum(Y==4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models:\n",
    "- Parameter tuning with Bayesian optimization over hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier(random_state=seed, num_class=3, objective='multi:softmax', eval_metric='mlogloss') \n",
    "xgb_params = {\n",
    "    'max_depth':  (1, 4), #Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit.\n",
    "    'learning_rate': (0.01, 0.5, 'log-uniform'),  #Step size shrinkage used in update to prevents overfitting. After each boosting step, we can directly get the weights of new features\n",
    "    'n_estimators':  (10, 50), #Number of gradient boosted trees. Equivalent to number of boosting rounds.\n",
    "    'reg_alpha':  (1, 10, 'log-uniform'), #L1 regularization term on weights. Increasing this value will make model more conservative.\n",
    "    'reg_lambda':  (1, 10, 'log-uniform')} #L2 regularization term on weights. Increasing this value will make model more conservative.\n",
    "\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=seed)\n",
    "gb_params = {\n",
    "    'learning_rate': (0.01, 0.5),\n",
    "    'max_depth': (1, 4),\n",
    "    \"max_features\":[\"log2\",\"sqrt\", \"auto\"],\n",
    "    \"criterion\": [\"friedman_mse\", \"mse\", \"mae\"],\n",
    "    'n_estimators': (10, 50)\n",
    "    }\n",
    "\n",
    "rf = RandomForestClassifier(random_state=seed)\n",
    "rf_params={'n_estimators': (10, 50), \n",
    "             'max_features': ['auto', 'sqrt', 'log2'],\n",
    "             'max_depth' : (1, 4),\n",
    "             'criterion' :[\"gini\", \"entropy\"]} \n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=seed)\n",
    "dt_params= {\"criterion\": [\"gini\", \"entropy\"],\n",
    "            'max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'max_depth' : (1, 4)}\n",
    "\n",
    "extra = ExtraTreesClassifier(random_state=seed)\n",
    "extra_params ={'n_estimators': (10, 50), \n",
    "             'max_features': ['auto', 'sqrt', 'log2'],\n",
    "             'max_depth' : (1, 4),\n",
    "             'criterion' :[\"gini\", \"entropy\"]}\n",
    "\n",
    "\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append(('XGB', BayesSearchCV(xgb, xgb_params, cv=inner_cv, iid=False, n_jobs=1))) \n",
    "models.append(('RF', BayesSearchCV(rf, rf_params, cv=inner_cv,iid=False, n_jobs=1)))\n",
    "models.append(('GB', BayesSearchCV(gb, gb_params, cv=inner_cv,iid=False, n_jobs=1)))\n",
    "models.append(('DT', BayesSearchCV(dt, dt_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "models.append(('ExtraTrees', BayesSearchCV(extra, extra_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "#models.append(('KNN', BayesSearchCV(knn, knn_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "#models.append(('SVC', BayesSearchCV(svc, svc_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "\n",
    "results = []\n",
    "results1 = []\n",
    "results2 = []\n",
    "results3 = []\n",
    "names = []\n",
    "names2 =[]\n",
    "scoring = ['accuracy', 'balanced_accuracy', 'f1_weighted', \n",
    "          'precision_weighted','recall_weighted'] #https://scikit-learn.org/stable/modules/model_evaluation.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Benchmarking - all features:\n",
    "### Tree-based models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Nested CV results for all scores: \n",
      " {'fit_time': array([75.04053569, 84.01658392, 76.79741311, 76.62657213, 81.51650786]), 'score_time': array([0.00570416, 0.00551081, 0.00544214, 0.0060091 , 0.00647497]), 'test_accuracy': array([0.75833333, 0.74789916, 0.80672269, 0.74789916, 0.76470588]), 'test_balanced_accuracy': array([0.76560407, 0.75836406, 0.79787212, 0.75348039, 0.76830357]), 'test_f1_weighted': array([0.75507565, 0.74100258, 0.79958552, 0.74210849, 0.76311296]), 'test_precision_weighted': array([0.75415675, 0.75212894, 0.79864559, 0.74619301, 0.76416492]), 'test_recall_weighted': array([0.75833333, 0.74789916, 0.80672269, 0.74789916, 0.76470588])} \n",
      "\n",
      "XGB Accuracy Nested CV Average 0.7651120448179272\n",
      "XGB Balanced Accuracy Nested CV Average 0.7687248415772084\n",
      "XGB F1 Nested CV Average 0.7601770408870026\n",
      "XGB Precision Nested CV Average 0.76305784270752\n",
      "XGB Recall Nested CV Average 0.7651120448179272\n",
      "Best Parameters: \n",
      "OrderedDict([('learning_rate', 0.22364286948058623), ('max_depth', 3), ('n_estimators', 50), ('reg_alpha', 1), ('reg_lambda', 1)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "XGB Train accuracy: 1.0 Test accuracy: 0.775\n",
      "XGB Train balanced accuracy: 1.0 Test balanced accuracy: 0.771556448666423\n",
      "XGB Train F1 1.0 Test F1: 0.7782934357121349\n",
      "XGB Train recall: 1.0 Test recall: 0.775\n",
      "XGB Train precision: 1.0 Test precision: 0.7838394062078272\n",
      "\n",
      "\n",
      "RF Nested CV results for all scores: \n",
      " {'fit_time': array([65.03126192, 69.56411505, 63.83958292, 66.20682001, 66.3347888 ]), 'score_time': array([0.00920725, 0.00906897, 0.00679183, 0.00687194, 0.00739622]), 'test_accuracy': array([0.60833333, 0.65546218, 0.68067227, 0.64705882, 0.68907563]), 'test_balanced_accuracy': array([0.6405584 , 0.6662212 , 0.67151226, 0.64796569, 0.6898476 ]), 'test_f1_weighted': array([0.59685728, 0.65218279, 0.6844468 , 0.64304579, 0.68771141]), 'test_precision_weighted': array([0.6600509 , 0.72041772, 0.69292717, 0.70899905, 0.69340044]), 'test_recall_weighted': array([0.60833333, 0.65546218, 0.68067227, 0.64705882, 0.68907563])} \n",
      "\n",
      "RF Accuracy Nested CV Average 0.6561204481792717\n",
      "RF Balanced Accuracy Nested CV Average 0.6632210288733077\n",
      "RF F1 Nested CV Average 0.6528488140608587\n",
      "RF Precision Nested CV Average 0.6951590540481046\n",
      "RF Recall Nested CV Average 0.6561204481792717\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'entropy'), ('max_depth', 4), ('max_features', 'log2'), ('n_estimators', 50)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "RF Train accuracy: 0.8298319327731093 Test accuracy: 0.6166666666666667\n",
      "RF Train balanced accuracy: 0.8271780298449463 Test balanced accuracy: 0.6317592254293021\n",
      "RF Train F1 0.831733033442606 Test F1: 0.6077970908259122\n",
      "RF Train recall: 0.8298319327731093 Test recall: 0.6166666666666667\n",
      "RF Train precision: 0.8493390523590763 Test precision: 0.647127570772707\n",
      "\n",
      "\n",
      "GB Nested CV results for all scores: \n",
      " {'fit_time': array([333.02097774, 363.39369702, 332.12732697, 282.26589322,\n",
      "       365.593256  ]), 'score_time': array([0.00437307, 0.00450897, 0.00382996, 0.00447178, 0.00654483]), 'test_accuracy': array([0.80833333, 0.76470588, 0.80672269, 0.81512605, 0.80672269]), 'test_balanced_accuracy': array([0.81291865, 0.78264977, 0.800344  , 0.82414216, 0.80684524]), 'test_f1_weighted': array([0.81323563, 0.75358217, 0.80688398, 0.81151038, 0.80290298]), 'test_precision_weighted': array([0.82270187, 0.7786391 , 0.80852968, 0.82328412, 0.8049896 ]), 'test_recall_weighted': array([0.80833333, 0.76470588, 0.80672269, 0.81512605, 0.80672269])} \n",
      "\n",
      "GB Accuracy Nested CV Average 0.8003221288515405\n",
      "GB Balanced Accuracy Nested CV Average 0.8053799627775643\n",
      "GB F1 Nested CV Average 0.7976230280138894\n",
      "GB Precision Nested CV Average 0.8076288741347751\n",
      "GB Recall Nested CV Average 0.8003221288515405\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'mse'), ('learning_rate', 0.28176104191963025), ('max_depth', 4), ('max_features', 'sqrt'), ('n_estimators', 37)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "GB Train accuracy: 1.0 Test accuracy: 0.8\n",
      "GB Train balanced accuracy: 1.0 Test balanced accuracy: 0.803799780781878\n",
      "GB Train F1 1.0 Test F1: 0.8040172109392356\n",
      "GB Train recall: 1.0 Test recall: 0.8\n",
      "GB Train precision: 1.0 Test precision: 0.8121557877606266\n",
      "\n",
      "\n",
      "DT Nested CV results for all scores: \n",
      " {'fit_time': array([40.80889797, 43.19693899, 46.24070907, 37.77022696, 41.87037516]), 'score_time': array([0.0042541 , 0.00398111, 0.00458813, 0.0038991 , 0.00391078]), 'test_accuracy': array([0.46666667, 0.51260504, 0.5210084 , 0.57142857, 0.50420168]), 'test_balanced_accuracy': array([0.50563269, 0.53672811, 0.50289287, 0.56688725, 0.51611248]), 'test_f1_weighted': array([0.35830092, 0.45973766, 0.47309855, 0.54820884, 0.44754346]), 'test_precision_weighted': array([0.47682692, 0.58674095, 0.51946611, 0.62569755, 0.42148109]), 'test_recall_weighted': array([0.46666667, 0.51260504, 0.5210084 , 0.57142857, 0.50420168])} \n",
      "\n",
      "DT Accuracy Nested CV Average 0.5151820728291316\n",
      "DT Balanced Accuracy Nested CV Average 0.5256506815264996\n",
      "DT F1 Nested CV Average 0.4573778861902607\n",
      "DT Precision Nested CV Average 0.5260425238244131\n",
      "DT Recall Nested CV Average 0.5151820728291316\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'gini'), ('max_depth', 4), ('max_features', 'log2')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "DT Train accuracy: 0.5546218487394958 Test accuracy: 0.4666666666666667\n",
      "DT Train balanced accuracy: 0.5449181084037976 Test balanced accuracy: 0.5163043478260869\n",
      "DT Train F1 0.47329714470933465 Test F1: 0.3840251572327044\n",
      "DT Train recall: 0.5546218487394958 Test recall: 0.4666666666666667\n",
      "DT Train precision: 0.4183540455567944 Test precision: 0.3340972222222222\n",
      "\n",
      "\n",
      "ExtraTrees Nested CV results for all scores: \n",
      " {'fit_time': array([52.525388  , 53.54199576, 52.4231739 , 49.75458097, 50.37523198]), 'score_time': array([0.00773096, 0.00701308, 0.00575519, 0.00688291, 0.00605583]), 'test_accuracy': array([0.575     , 0.62184874, 0.6302521 , 0.57983193, 0.59663866]), 'test_balanced_accuracy': array([0.61467848, 0.65048387, 0.62194362, 0.60607843, 0.59914819]), 'test_f1_weighted': array([0.55256877, 0.5869643 , 0.63596228, 0.54292287, 0.58415371]), 'test_precision_weighted': array([0.62387821, 0.73393812, 0.66405275, 0.66081973, 0.63605963]), 'test_recall_weighted': array([0.575     , 0.62184874, 0.6302521 , 0.57983193, 0.59663866])} \n",
      "\n",
      "ExtraTrees Accuracy Nested CV Average 0.6007142857142858\n",
      "ExtraTrees Balanced Accuracy Nested CV Average 0.6184665193343812\n",
      "ExtraTrees F1 Nested CV Average 0.5805143862376114\n",
      "ExtraTrees Precision Nested CV Average 0.6637496872433697\n",
      "ExtraTrees Recall Nested CV Average 0.6007142857142858\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'entropy'), ('max_depth', 4), ('max_features', 'auto'), ('n_estimators', 44)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "ExtraTrees Train accuracy: 0.8256302521008403 Test accuracy: 0.55\n",
      "ExtraTrees Train balanced accuracy: 0.8193079324163296 Test balanced accuracy: 0.5845512117890634\n",
      "ExtraTrees Train F1 0.8237305136271373 Test F1: 0.5312821464203696\n",
      "ExtraTrees Train recall: 0.8256302521008403 Test recall: 0.55\n",
      "ExtraTrees Train precision: 0.8532622160039611 Test precision: 0.5934867800612786\n",
      "\n",
      "\n",
      "All balanced accuracy results: [array([0.76700463, 0.77979263, 0.79787212, 0.76860294, 0.73497024]), array([0.64122823, 0.69336406, 0.67151226, 0.60896242, 0.6898476 ]), array([0.81291865, 0.80586406, 0.82326041, 0.79902778, 0.80677083]), array([0.50563269, 0.53672811, 0.50289287, 0.56688725, 0.51611248]), array([0.66477896, 0.65048387, 0.60581459, 0.60607843, 0.63014419])]\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    nested_cv_results = model_selection.cross_validate(model, X , Y, cv=outer_cv, scoring=scoring, error_score=\"raise\")\n",
    "    nested_cv_results2 = model_selection.cross_val_score(model, X , Y, cv=outer_cv, scoring='balanced_accuracy', error_score=\"raise\")\n",
    "    results.append(nested_cv_results2)\n",
    "    names.append(name)\n",
    "    print(name, 'Nested CV results for all scores:', '\\n', nested_cv_results, '\\n')\n",
    "    print(name, 'Accuracy Nested CV Average', np.mean(nested_cv_results['test_accuracy']))\n",
    "    print(name, 'Balanced Accuracy Nested CV Average', np.mean(nested_cv_results['test_balanced_accuracy'] ))\n",
    "    print(name, 'F1 Nested CV Average', np.mean(nested_cv_results['test_f1_weighted'] ))\n",
    "    print(name, 'Precision Nested CV Average', np.mean(nested_cv_results['test_precision_weighted'] ))\n",
    "    print(name, 'Recall Nested CV Average', np.mean(nested_cv_results['test_recall_weighted'] ))\n",
    "    model.fit(X_train, Y_train)\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print('Non-nested CV Results:')\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(name, 'Train accuracy:', accuracy_score(Y_train, y_pred_train), 'Test accuracy:', accuracy_score(Y_test, y_pred))\n",
    "    print(name, 'Train balanced accuracy:', balanced_accuracy_score(Y_train, y_pred_train), 'Test balanced accuracy:', balanced_accuracy_score(Y_test, y_pred))\n",
    "    print(name, 'Train F1', f1_score(Y_train, y_pred_train, average='weighted'), 'Test F1:', f1_score(Y_test, y_pred, average='weighted'))\n",
    "    print(name, 'Train recall:', recall_score(Y_train, y_pred_train, average='weighted'),'Test recall:', recall_score(Y_test, y_pred,average='weighted'))\n",
    "    print(name, 'Train precision:', precision_score(Y_train, y_pred_train,average='weighted'), 'Test precision:', precision_score(Y_test, y_pred,average='weighted'))\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "print('All balanced accuracy results:', results)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others models:\n",
    "- all other models require feature scaling before running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_params = {\n",
    "    'n_neighbors':[7,9,11,13,15,17],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['euclidean','manhattan', 'minkowski']}\n",
    "\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', solver='liblinear',multi_class='auto',random_state=seed)\n",
    "lr_params= {\n",
    "    'penalty':['l1', 'l2'], \n",
    "    'C': [0.5, 1, 5, 10], \n",
    "    'max_iter':[500, 1000, 2500]}\n",
    "\n",
    "svc = SVC()\n",
    "svc_params = {\n",
    "    'kernel': ['rbf'],\n",
    "   'C': (1e0, 1e3),\n",
    "   'gamma': ['scale', 'auto']}\n",
    "\n",
    "othermodels = []\n",
    "\n",
    "othermodels.append(('KNN', BayesSearchCV(knn, knn_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "othermodels.append(('SVC', BayesSearchCV(svc, svc_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "othermodels.append(('LR', BayesSearchCV(lr, lr_params, cv=inner_cv, iid=False, n_jobs=1)))\n",
    "\n",
    "results = []\n",
    "results1 = []\n",
    "results2 = []\n",
    "results3 = []\n",
    "names = []\n",
    "names2 =[]\n",
    "scoring = ['accuracy', 'balanced_accuracy', 'f1_weighted', \n",
    "          'precision_weighted','recall_weighted'] #https://scikit-learn.org/stable/modules/model_evaluation.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = MinMaxScaler().fit_transform(X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X2, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Nested CV results for all scores: \n",
      " {'fit_time': array([45.73063397, 45.01727414, 46.19174695, 47.83670712, 44.06176591]), 'score_time': array([0.00728798, 0.00749803, 0.00714302, 0.00731897, 0.00761104]), 'test_accuracy': array([0.80833333, 0.7394958 , 0.7394958 , 0.72268908, 0.71428571]), 'test_balanced_accuracy': array([0.79708623, 0.76857143, 0.72810324, 0.74244281, 0.71733631]), 'test_f1_weighted': array([0.80068617, 0.69678406, 0.72377004, 0.67413358, 0.68180516]), 'test_precision_weighted': array([0.80816983, 0.7585699 , 0.73178033, 0.76631749, 0.72905632]), 'test_recall_weighted': array([0.80833333, 0.7394958 , 0.7394958 , 0.72268908, 0.71428571])} \n",
      "\n",
      "KNN Accuracy Nested CV Average 0.7448599439775911\n",
      "KNN Balanced Accuracy Nested CV Average 0.7507080033266174\n",
      "KNN F1 Nested CV Average 0.7154358019534685\n",
      "KNN Precision Nested CV Average 0.7587787727645342\n",
      "KNN Recall Nested CV Average 0.7448599439775911\n",
      "Best Parameters: \n",
      "OrderedDict([('metric', 'manhattan'), ('n_neighbors', 7), ('weights', 'distance')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "KNN Train accuracy: 1.0 Test accuracy: 0.8083333333333333\n",
      "KNN Train balanced accuracy: 1.0 Test balanced accuracy: 0.7970862257946657\n",
      "KNN Train F1 1.0 Test F1: 0.8006861682918022\n",
      "KNN Train recall: 1.0 Test recall: 0.8083333333333333\n",
      "KNN Train precision: 1.0 Test precision: 0.8081698284823285\n",
      "\n",
      "\n",
      "SVC Nested CV results for all scores: \n",
      " {'fit_time': array([47.62093997, 46.48360705, 49.20190716, 49.12202668, 49.87303686]), 'score_time': array([0.0100522 , 0.01041412, 0.00957489, 0.00976515, 0.00974631]), 'test_accuracy': array([0.79166667, 0.77310924, 0.79831933, 0.79831933, 0.76470588]), 'test_balanced_accuracy': array([0.78134515, 0.7925    , 0.7856672 , 0.80249183, 0.76949405]), 'test_f1_weighted': array([0.78577393, 0.76110013, 0.78236222, 0.78962595, 0.75965754]), 'test_precision_weighted': array([0.78497475, 0.80023424, 0.7999314 , 0.80646896, 0.75980366]), 'test_recall_weighted': array([0.79166667, 0.77310924, 0.79831933, 0.79831933, 0.76470588])} \n",
      "\n",
      "SVC Accuracy Nested CV Average 0.7852240896358543\n",
      "SVC Balanced Accuracy Nested CV Average 0.7862996453359868\n",
      "SVC F1 Nested CV Average 0.775703952952848\n",
      "SVC Precision Nested CV Average 0.7902826019324967\n",
      "SVC Recall Nested CV Average 0.7852240896358543\n",
      "Best Parameters: \n",
      "OrderedDict([('C', 467.5934467565067), ('gamma', 'scale'), ('kernel', 'rbf')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "SVC Train accuracy: 0.9978991596638656 Test accuracy: 0.7666666666666667\n",
      "SVC Train balanced accuracy: 0.998015873015873 Test balanced accuracy: 0.7620874436731213\n",
      "SVC Train F1 0.9978995219964117 Test F1: 0.7633348409467813\n",
      "SVC Train recall: 0.9978991596638656 Test recall: 0.7666666666666667\n",
      "SVC Train precision: 0.9979172703564184 Test precision: 0.7619227994227994\n",
      "\n",
      "\n",
      "LR Nested CV results for all scores: \n",
      " {'fit_time': array([ 92.81453085, 104.05790591,  98.61050391, 106.25143886,\n",
      "       101.26667619]), 'score_time': array([0.00250316, 0.00233078, 0.00242186, 0.00247908, 0.00247788]), 'test_accuracy': array([0.63333333, 0.6302521 , 0.65546218, 0.68907563, 0.57142857]), 'test_balanced_accuracy': array([0.66439837, 0.64167051, 0.64079365, 0.69446895, 0.58148348]), 'test_f1_weighted': array([0.63199208, 0.62995221, 0.62751519, 0.68309006, 0.54505431]), 'test_precision_weighted': array([0.67030088, 0.6384412 , 0.61528095, 0.69043779, 0.53489253]), 'test_recall_weighted': array([0.63333333, 0.6302521 , 0.65546218, 0.68907563, 0.57142857])} \n",
      "\n",
      "LR Accuracy Nested CV Average 0.6359103641456582\n",
      "LR Balanced Accuracy Nested CV Average 0.6445629921374438\n",
      "LR F1 Nested CV Average 0.6235207701775671\n",
      "LR Precision Nested CV Average 0.6298706705664733\n",
      "LR Recall Nested CV Average 0.6359103641456582\n",
      "Best Parameters: \n",
      "OrderedDict([('C', 10.0), ('max_iter', 2500), ('penalty', 'l1')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "LR Train accuracy: 0.8046218487394958 Test accuracy: 0.6333333333333333\n",
      "LR Train balanced accuracy: 0.802798180383829 Test balanced accuracy: 0.6643983680428693\n",
      "LR Train F1 0.8024411784915988 Test F1: 0.631992081992082\n",
      "LR Train recall: 0.8046218487394958 Test recall: 0.6333333333333333\n",
      "LR Train precision: 0.8012477693527092 Test precision: 0.6703008789722786\n",
      "\n",
      "\n",
      "All balanced accuracy results: [array([0.79708623, 0.76857143, 0.72810324, 0.74244281, 0.71733631]), array([0.77399221, 0.7925    , 0.7856672 , 0.80249183, 0.76949405]), array([0.66439837, 0.64167051, 0.64079365, 0.69446895, 0.58148348])]\n"
     ]
    }
   ],
   "source": [
    "for name, model in othermodels:\n",
    "    nested_cv_results = model_selection.cross_validate(model, X2 , Y, cv=outer_cv, scoring=scoring, error_score=\"raise\")\n",
    "    nested_cv_results2 = model_selection.cross_val_score(model, X2 , Y, cv=outer_cv, scoring='balanced_accuracy', error_score=\"raise\")\n",
    "    results.append(nested_cv_results2)\n",
    "    names.append(name)\n",
    "    print(name, 'Nested CV results for all scores:', '\\n', nested_cv_results, '\\n')\n",
    "    print(name, 'Accuracy Nested CV Average', np.mean(nested_cv_results['test_accuracy']))\n",
    "    print(name, 'Balanced Accuracy Nested CV Average', np.mean(nested_cv_results['test_balanced_accuracy'] ))\n",
    "    print(name, 'F1 Nested CV Average', np.mean(nested_cv_results['test_f1_weighted'] ))\n",
    "    print(name, 'Precision Nested CV Average', np.mean(nested_cv_results['test_precision_weighted'] ))\n",
    "    print(name, 'Recall Nested CV Average', np.mean(nested_cv_results['test_recall_weighted'] ))\n",
    "    model.fit(X_train, Y_train)\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print('Non-nested CV Results:')\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(name, 'Train accuracy:', accuracy_score(Y_train, y_pred_train), 'Test accuracy:', accuracy_score(Y_test, y_pred))\n",
    "    print(name, 'Train balanced accuracy:', balanced_accuracy_score(Y_train, y_pred_train), 'Test balanced accuracy:', balanced_accuracy_score(Y_test, y_pred))\n",
    "    print(name, 'Train F1', f1_score(Y_train, y_pred_train, average='weighted'), 'Test F1:', f1_score(Y_test, y_pred, average='weighted'))\n",
    "    print(name, 'Train recall:', recall_score(Y_train, y_pred_train, average='weighted'),'Test recall:', recall_score(Y_test, y_pred,average='weighted'))\n",
    "    print(name, 'Train precision:', precision_score(Y_train, y_pred_train,average='weighted'), 'Test precision:', precision_score(Y_test, y_pred,average='weighted'))\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "print('All balanced accuracy results:', results) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model benchmarking - BorutaShap feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boruta_sel = pd.read_csv(\"2021-11-19_selected_features_training_data.csv\", header=0)\n",
    "X_boruta_sel.columns = [\n",
    "    regex.sub(\"_\", col) if any(x in str(col) for x in set((\"[\", \"]\", \"<\"))) else col\n",
    "    for col in X_boruta_sel.columns.values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, the shape of X: (327, 6)\n",
      "Before OverSampling, the shape of y: (327,) \n",
      "\n",
      "After OverSampling, the shape of X: (596, 6)\n",
      "After OverSampling, the shape of y: (596,) \n",
      "\n",
      "After OverSampling, counts of label '1': 149\n",
      "After OverSampling, counts of label '2': 149\n",
      "After OverSampling, counts of label '3': 149\n",
      "After OverSampling, counts of label '4': 149\n"
     ]
    }
   ],
   "source": [
    "print('Before OverSampling, the shape of X: {}'.format(X_boruta_sel.shape))\n",
    "print('Before OverSampling, the shape of y: {} \\n'.format(Y2.shape))\n",
    "\n",
    "sm = SMOTE(random_state=seed)\n",
    "X_boruta_sel, Y2 = sm.fit_resample(X_boruta_sel, Y2)\n",
    "\n",
    "print('After OverSampling, the shape of X: {}'.format(X_boruta_sel.shape))\n",
    "print('After OverSampling, the shape of y: {} \\n'.format(Y2.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(Y2==1)))\n",
    "print(\"After OverSampling, counts of label '2': {}\".format(sum(Y2==2)))\n",
    "print(\"After OverSampling, counts of label '3': {}\".format(sum(Y2==3)))\n",
    "print(\"After OverSampling, counts of label '4': {}\".format(sum(Y2==4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_boruta, X_test_boruta, Y_train_boruta, Y_test_boruta = train_test_split(X_boruta_sel, Y2, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Nested CV results for all scores: \n",
      " {'fit_time': array([54.93386698, 50.17822003, 53.28910208, 65.77923989, 52.71464276]), 'score_time': array([0.005162  , 0.00528002, 0.00525904, 0.00514293, 0.00522232]), 'test_accuracy': array([0.65      , 0.7394958 , 0.76470588, 0.70588235, 0.71428571]), 'test_balanced_accuracy': array([0.67418707, 0.74443548, 0.75660199, 0.69735294, 0.71863198]), 'test_f1_weighted': array([0.65265543, 0.73864912, 0.76338582, 0.70634345, 0.70808351]), 'test_precision_weighted': array([0.67290487, 0.7414081 , 0.7630932 , 0.7110463 , 0.71162077]), 'test_recall_weighted': array([0.65      , 0.7394958 , 0.76470588, 0.70588235, 0.71428571])} \n",
      "\n",
      "XGB Accuracy Nested CV Average 0.714873949579832\n",
      "XGB Balanced Accuracy Nested CV Average 0.7182418911154494\n",
      "XGB F1 Nested CV Average 0.7138234659837958\n",
      "XGB Precision Nested CV Average 0.7200146474711575\n",
      "XGB Recall Nested CV Average 0.714873949579832\n",
      "Best Parameters: \n",
      "OrderedDict([('learning_rate', 0.49999999999999994), ('max_depth', 3), ('n_estimators', 32), ('reg_alpha', 1), ('reg_lambda', 1)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "XGB Train accuracy: 0.9894957983193278 Test accuracy: 0.6583333333333333\n",
      "XGB Train balanced accuracy: 0.9891849357920061 Test balanced accuracy: 0.6815400073072708\n",
      "XGB Train F1 0.989504670231453 Test F1: 0.6572000478032322\n",
      "XGB Train recall: 0.9894957983193278 Test recall: 0.6583333333333333\n",
      "XGB Train precision: 0.9895669077500376 Test precision: 0.6805945663531872\n",
      "\n",
      "\n",
      "RF Nested CV results for all scores: \n",
      " {'fit_time': array([51.34791803, 50.68148398, 54.24853301, 54.98547888, 49.45121479]), 'score_time': array([0.00519609, 0.00612903, 0.00563192, 0.00482202, 0.0057261 ]), 'test_accuracy': array([0.56666667, 0.68067227, 0.64705882, 0.6302521 , 0.59663866]), 'test_balanced_accuracy': array([0.60202777, 0.6887212 , 0.63630854, 0.63201797, 0.60159329]), 'test_f1_weighted': array([0.56863746, 0.6792914 , 0.64557207, 0.61371802, 0.59027828]), 'test_precision_weighted': array([0.60304831, 0.69632084, 0.64469504, 0.66321913, 0.59839519]), 'test_recall_weighted': array([0.56666667, 0.68067227, 0.64705882, 0.6302521 , 0.59663866])} \n",
      "\n",
      "RF Accuracy Nested CV Average 0.6242577030812325\n",
      "RF Balanced Accuracy Nested CV Average 0.632133753531505\n",
      "RF F1 Nested CV Average 0.6194994464580372\n",
      "RF Precision Nested CV Average 0.6411357027819279\n",
      "RF Recall Nested CV Average 0.6242577030812325\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'gini'), ('max_depth', 4), ('max_features', 'auto'), ('n_estimators', 25)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "RF Train accuracy: 0.7899159663865546 Test accuracy: 0.5916666666666667\n",
      "RF Train balanced accuracy: 0.782571253922299 Test balanced accuracy: 0.6395536475459749\n",
      "RF Train F1 0.7891979244165229 Test F1: 0.5919930618659432\n",
      "RF Train recall: 0.7899159663865546 Test recall: 0.5916666666666667\n",
      "RF Train precision: 0.7931517012399366 Test precision: 0.636814030850072\n",
      "\n",
      "\n",
      "GB Nested CV results for all scores: \n",
      " {'fit_time': array([ 90.65686822,  93.33560014,  87.64271402, 106.03964114,\n",
      "        96.4801569 ]), 'score_time': array([0.00368285, 0.00386262, 0.00395298, 0.00378799, 0.00367785]), 'test_accuracy': array([0.64166667, 0.78151261, 0.72268908, 0.71428571, 0.71428571]), 'test_balanced_accuracy': array([0.67035075, 0.78300691, 0.71038809, 0.71388889, 0.71855757]), 'test_f1_weighted': array([0.64475262, 0.78099664, 0.71787318, 0.71693553, 0.71355025]), 'test_precision_weighted': array([0.6655885 , 0.78315196, 0.71504191, 0.73139398, 0.7153139 ]), 'test_recall_weighted': array([0.64166667, 0.78151261, 0.72268908, 0.71428571, 0.71428571])} \n",
      "\n",
      "GB Accuracy Nested CV Average 0.7148879551820728\n",
      "GB Balanced Accuracy Nested CV Average 0.7192384419490582\n",
      "GB F1 Nested CV Average 0.7148216418212077\n",
      "GB Precision Nested CV Average 0.7220980488871029\n",
      "GB Recall Nested CV Average 0.7148879551820728\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'friedman_mse'), ('learning_rate', 0.28483530005634594), ('max_depth', 4), ('max_features', 'sqrt'), ('n_estimators', 41)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "GB Train accuracy: 1.0 Test accuracy: 0.6333333333333333\n",
      "GB Train balanced accuracy: 1.0 Test balanced accuracy: 0.6643983680428693\n",
      "GB Train F1 1.0 Test F1: 0.6350500370644923\n",
      "GB Train recall: 1.0 Test recall: 0.6333333333333333\n",
      "GB Train precision: 1.0 Test precision: 0.6576318418171866\n",
      "\n",
      "\n",
      "DT Nested CV results for all scores: \n",
      " {'fit_time': array([37.85763502, 34.83280087, 37.17793608, 36.85472298, 35.98155904]), 'score_time': array([0.00366807, 0.00342512, 0.00351095, 0.00366902, 0.00352693]), 'test_accuracy': array([0.51666667, 0.52941176, 0.57983193, 0.52941176, 0.5210084 ]), 'test_balanced_accuracy': array([0.55784923, 0.54672811, 0.57529424, 0.54607026, 0.53434165]), 'test_f1_weighted': array([0.47588384, 0.4582556 , 0.54698911, 0.51889327, 0.48648504]), 'test_precision_weighted': array([0.53337452, 0.58097826, 0.56085937, 0.59307958, 0.5060226 ]), 'test_recall_weighted': array([0.51666667, 0.52941176, 0.57983193, 0.52941176, 0.5210084 ])} \n",
      "\n",
      "DT Accuracy Nested CV Average 0.535266106442577\n",
      "DT Balanced Accuracy Nested CV Average 0.5520566977888725\n",
      "DT F1 Nested CV Average 0.4973013713674369\n",
      "DT Precision Nested CV Average 0.5548628657019808\n",
      "DT Recall Nested CV Average 0.535266106442577\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'entropy'), ('max_depth', 4), ('max_features', 'sqrt')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "DT Train accuracy: 0.6260504201680672 Test accuracy: 0.5166666666666667\n",
      "DT Train balanced accuracy: 0.6166750615151926 Test balanced accuracy: 0.5578492266471806\n",
      "DT Train F1 0.610417244760084 Test F1: 0.4758838383838384\n",
      "DT Train recall: 0.6260504201680672 Test recall: 0.5166666666666667\n",
      "DT Train precision: 0.6511601856586492 Test precision: 0.5333745185778845\n",
      "\n",
      "\n",
      "ExtraTrees Nested CV results for all scores: \n",
      " {'fit_time': array([54.20904326, 55.14224577, 53.32301593, 49.26462698, 49.29499698]), 'score_time': array([0.00743198, 0.00723028, 0.00504303, 0.00670981, 0.00716019]), 'test_accuracy': array([0.50833333, 0.57983193, 0.57142857, 0.55462185, 0.61344538]), 'test_balanced_accuracy': array([0.58149129, 0.57759217, 0.56581322, 0.54867647, 0.62269345]), 'test_f1_weighted': array([0.47551663, 0.57219253, 0.55981454, 0.5454224 , 0.59112066]), 'test_precision_weighted': array([0.57967313, 0.5701729 , 0.55918856, 0.57534205, 0.60935726]), 'test_recall_weighted': array([0.50833333, 0.57983193, 0.57142857, 0.55462185, 0.61344538])} \n",
      "\n",
      "ExtraTrees Accuracy Nested CV Average 0.5655322128851541\n",
      "ExtraTrees Balanced Accuracy Nested CV Average 0.5792533209154813\n",
      "ExtraTrees F1 Nested CV Average 0.5488133522202867\n",
      "ExtraTrees Precision Nested CV Average 0.578746778526461\n",
      "ExtraTrees Recall Nested CV Average 0.5655322128851541\n",
      "Best Parameters: \n",
      "OrderedDict([('criterion', 'entropy'), ('max_depth', 4), ('max_features', 'sqrt'), ('n_estimators', 50)])\n",
      "\n",
      "Non-nested CV Results:\n",
      "ExtraTrees Train accuracy: 0.6911764705882353 Test accuracy: 0.5166666666666667\n",
      "ExtraTrees Train balanced accuracy: 0.6771991958480873 Test balanced accuracy: 0.5909602971623432\n",
      "ExtraTrees Train F1 0.6666758124905479 Test F1: 0.47818666201658533\n",
      "ExtraTrees Train recall: 0.6911764705882353 Test recall: 0.5166666666666667\n",
      "ExtraTrees Train precision: 0.7582937381144313 Test precision: 0.5604807692307693\n",
      "\n",
      "\n",
      "All balanced accuracy results: [array([0.79708623, 0.76857143, 0.72810324, 0.74244281, 0.71733631]), array([0.77399221, 0.7925    , 0.7856672 , 0.80249183, 0.76949405]), array([0.66439837, 0.64167051, 0.64079365, 0.69446895, 0.58148348]), array([0.67418707, 0.76050691, 0.7646665 , 0.69735294, 0.70189091]), array([0.60274327, 0.6887212 , 0.66200099, 0.63201797, 0.62770936]), array([0.68609183, 0.78300691, 0.73808347, 0.71164216, 0.71855757]), array([0.55784923, 0.54672811, 0.57529424, 0.54607026, 0.53434165]), array([0.58009073, 0.55616359, 0.59901402, 0.52132353, 0.62269345])]\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    nested_cv_results = model_selection.cross_validate(model, X_boruta_sel , Y2, cv=outer_cv, scoring=scoring, error_score=\"raise\")\n",
    "    nested_cv_results2 = model_selection.cross_val_score(model, X_boruta_sel , Y2, cv=outer_cv, scoring='balanced_accuracy', error_score=\"raise\")\n",
    "    results.append(nested_cv_results2)\n",
    "    names.append(name)\n",
    "    print(name, 'Nested CV results for all scores:', '\\n', nested_cv_results, '\\n')\n",
    "    print(name, 'Accuracy Nested CV Average', np.mean(nested_cv_results['test_accuracy']))\n",
    "    print(name, 'Balanced Accuracy Nested CV Average', np.mean(nested_cv_results['test_balanced_accuracy'] ))\n",
    "    print(name, 'F1 Nested CV Average', np.mean(nested_cv_results['test_f1_weighted'] ))\n",
    "    print(name, 'Precision Nested CV Average', np.mean(nested_cv_results['test_precision_weighted'] ))\n",
    "    print(name, 'Recall Nested CV Average', np.mean(nested_cv_results['test_recall_weighted'] ))\n",
    "    model.fit(X_train_boruta, Y_train_boruta)\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print('Non-nested CV Results:')\n",
    "    y_pred_train = model.predict(X_train_boruta)\n",
    "    y_pred = model.predict(X_test_boruta)\n",
    "    print(name, 'Train accuracy:', accuracy_score(Y_train_boruta, y_pred_train), 'Test accuracy:', accuracy_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train balanced accuracy:', balanced_accuracy_score(Y_train, y_pred_train), 'Test balanced accuracy:', balanced_accuracy_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train F1', f1_score(Y_train_boruta, y_pred_train, average='weighted'), 'Test F1:', f1_score(Y_test_boruta, y_pred, average='weighted'))\n",
    "    print(name, 'Train recall:', recall_score(Y_train_boruta, y_pred_train, average='weighted'),'Test recall:', recall_score(Y_test_boruta, y_pred,average='weighted'))\n",
    "    print(name, 'Train precision:', precision_score(Y_train_boruta, y_pred_train,average='weighted'), 'Test precision:', precision_score(Y_test_boruta, y_pred,average='weighted'))\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "print('All balanced accuracy results:', results)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_boruta_sel = MinMaxScaler().fit_transform(X_boruta_sel)\n",
    "X_train_boruta, X_test_boruta, Y_train_boruta, Y_test_boruta = train_test_split(X2_boruta_sel, Y2, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Nested CV results for all scores: \n",
      " {'fit_time': array([44.11364293, 46.92315698, 47.5888021 , 43.04875612, 45.40666294]), 'score_time': array([0.00383282, 0.00414491, 0.00374079, 0.00370193, 0.00381899]), 'test_accuracy': array([0.63333333, 0.74789916, 0.76470588, 0.68907563, 0.71428571]), 'test_balanced_accuracy': array([0.6753136 , 0.75193548, 0.75707576, 0.68487745, 0.72114122]), 'test_f1_weighted': array([0.63262374, 0.74186013, 0.75957142, 0.68307302, 0.70802666]), 'test_precision_weighted': array([0.67764661, 0.74333925, 0.76738782, 0.69472989, 0.707024  ]), 'test_recall_weighted': array([0.63333333, 0.74789916, 0.76470588, 0.68907563, 0.71428571])} \n",
      "\n",
      "KNN Accuracy Nested CV Average 0.709859943977591\n",
      "KNN Balanced Accuracy Nested CV Average 0.7180687033708228\n",
      "KNN F1 Nested CV Average 0.7050309936330413\n",
      "KNN Precision Nested CV Average 0.7180255144535623\n",
      "KNN Recall Nested CV Average 0.709859943977591\n",
      "Best Parameters: \n",
      "OrderedDict([('metric', 'manhattan'), ('n_neighbors', 7), ('weights', 'distance')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "KNN Train accuracy: 1.0 Test accuracy: 0.65\n",
      "KNN Train balanced accuracy: 1.0 Test balanced accuracy: 0.6837017415661917\n",
      "KNN Train F1 1.0 Test F1: 0.6484390546034381\n",
      "KNN Train recall: 1.0 Test recall: 0.65\n",
      "KNN Train precision: 1.0 Test precision: 0.6714436758435298\n",
      "\n",
      "\n",
      "SVC Nested CV results for all scores: \n",
      " {'fit_time': array([42.54427075, 46.5160501 , 42.27585888, 42.00756979, 43.10387301]), 'score_time': array([0.00562215, 0.00596786, 0.00587606, 0.00621843, 0.00596499]), 'test_accuracy': array([0.54166667, 0.68907563, 0.65546218, 0.59663866, 0.67226891]), 'test_balanced_accuracy': array([0.58736756, 0.67815668, 0.6456502 , 0.57750817, 0.677168  ]), 'test_f1_weighted': array([0.53507818, 0.69074207, 0.65443271, 0.61386465, 0.66870116]), 'test_precision_weighted': array([0.56576036, 0.71639807, 0.65573421, 0.64807771, 0.6665223 ]), 'test_recall_weighted': array([0.54166667, 0.68907563, 0.65546218, 0.59663866, 0.67226891])} \n",
      "\n",
      "SVC Accuracy Nested CV Average 0.6310224089635854\n",
      "SVC Balanced Accuracy Nested CV Average 0.6331701207353915\n",
      "SVC F1 Nested CV Average 0.6325637552762134\n",
      "SVC Precision Nested CV Average 0.6504985305037828\n",
      "SVC Recall Nested CV Average 0.6310224089635854\n",
      "Best Parameters: \n",
      "OrderedDict([('C', 1000.0), ('gamma', 'scale'), ('kernel', 'rbf')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "SVC Train accuracy: 0.8319327731092437 Test accuracy: 0.55\n",
      "SVC Train balanced accuracy: 0.8272097952261631 Test balanced accuracy: 0.5982371209353305\n",
      "SVC Train F1 0.8323826331071458 Test F1: 0.5430186600155719\n",
      "SVC Train recall: 0.8319327731092437 Test recall: 0.55\n",
      "SVC Train precision: 0.8348625844512294 Test precision: 0.5761166905026749\n",
      "\n",
      "\n",
      "LR Nested CV results for all scores: \n",
      " {'fit_time': array([41.40805101, 44.26400185, 44.05717111, 41.41599798, 44.08532405]), 'score_time': array([0.00270987, 0.00270391, 0.00286698, 0.00268793, 0.00286293]), 'test_accuracy': array([0.44166667, 0.43697479, 0.47058824, 0.5210084 , 0.51260504]), 'test_balanced_accuracy': array([0.49809706, 0.45506912, 0.45873823, 0.53232026, 0.52102319]), 'test_f1_weighted': array([0.40687853, 0.41022443, 0.46596518, 0.50470481, 0.49348773]), 'test_precision_weighted': array([0.52888889, 0.42486187, 0.46245809, 0.53579531, 0.48524869]), 'test_recall_weighted': array([0.44166667, 0.43697479, 0.47058824, 0.5210084 , 0.51260504])} \n",
      "\n",
      "LR Accuracy Nested CV Average 0.4765686274509804\n",
      "LR Balanced Accuracy Nested CV Average 0.49304957546903483\n",
      "LR F1 Nested CV Average 0.45625213628502415\n",
      "LR Precision Nested CV Average 0.48745057117343515\n",
      "LR Recall Nested CV Average 0.4765686274509804\n",
      "Best Parameters: \n",
      "OrderedDict([('C', 0.5), ('max_iter', 1000), ('penalty', 'l1')])\n",
      "\n",
      "Non-nested CV Results:\n",
      "LR Train accuracy: 0.5042016806722689 Test accuracy: 0.4166666666666667\n",
      "LR Train balanced accuracy: 0.49517850491476556 Test balanced accuracy: 0.4700858604311289\n",
      "LR Train F1 0.45814589670379435 Test F1: 0.36260675776662754\n",
      "LR Train recall: 0.5042016806722689 Test recall: 0.4166666666666667\n",
      "LR Train precision: 0.5120689186492283 Test precision: 0.3966329564858977\n",
      "\n",
      "\n",
      "All balanced accuracy results: [array([0.79708623, 0.76857143, 0.72810324, 0.74244281, 0.71733631]), array([0.77399221, 0.7925    , 0.7856672 , 0.80249183, 0.76949405]), array([0.66439837, 0.64167051, 0.64079365, 0.69446895, 0.58148348]), array([0.67418707, 0.76050691, 0.7646665 , 0.69735294, 0.70189091]), array([0.60274327, 0.6887212 , 0.66200099, 0.63201797, 0.62770936]), array([0.68609183, 0.78300691, 0.73808347, 0.71164216, 0.71855757]), array([0.55784923, 0.54672811, 0.57529424, 0.54607026, 0.53434165]), array([0.58009073, 0.55616359, 0.59901402, 0.52132353, 0.62269345]), array([0.6753136 , 0.75193548, 0.75707576, 0.68487745, 0.72114122]), array([0.58736756, 0.65682028, 0.6456502 , 0.57750817, 0.66883467]), array([0.49809706, 0.45506912, 0.45873823, 0.53232026, 0.52102319])]\n"
     ]
    }
   ],
   "source": [
    "for name, model in othermodels:\n",
    "    nested_cv_results = model_selection.cross_validate(model, X2_boruta_sel , Y2, cv=outer_cv, scoring=scoring, error_score=\"raise\")\n",
    "    nested_cv_results2 = model_selection.cross_val_score(model, X2_boruta_sel , Y2, cv=outer_cv, scoring='balanced_accuracy', error_score=\"raise\")\n",
    "    results.append(nested_cv_results2)\n",
    "    names.append(name)\n",
    "    print(name, 'Nested CV results for all scores:', '\\n', nested_cv_results, '\\n')\n",
    "    print(name, 'Accuracy Nested CV Average', np.mean(nested_cv_results['test_accuracy']))\n",
    "    print(name, 'Balanced Accuracy Nested CV Average', np.mean(nested_cv_results['test_balanced_accuracy'] ))\n",
    "    print(name, 'F1 Nested CV Average', np.mean(nested_cv_results['test_f1_weighted'] ))\n",
    "    print(name, 'Precision Nested CV Average', np.mean(nested_cv_results['test_precision_weighted'] ))\n",
    "    print(name, 'Recall Nested CV Average', np.mean(nested_cv_results['test_recall_weighted'] ))\n",
    "    model.fit(X_train_boruta, Y_train_boruta)\n",
    "    print(\"Best Parameters: \\n{}\\n\".format(model.best_params_))\n",
    "    print('Non-nested CV Results:')\n",
    "    y_pred_train = model.predict(X_train_boruta)\n",
    "    y_pred = model.predict(X_test_boruta)\n",
    "    print(name, 'Train accuracy:', accuracy_score(Y_train_boruta, y_pred_train), 'Test accuracy:', accuracy_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train balanced accuracy:', balanced_accuracy_score(Y_train, y_pred_train), 'Test balanced accuracy:', balanced_accuracy_score(Y_test_boruta, y_pred))\n",
    "    print(name, 'Train F1', f1_score(Y_train_boruta, y_pred_train, average='weighted'), 'Test F1:', f1_score(Y_test_boruta, y_pred, average='weighted'))\n",
    "    print(name, 'Train recall:', recall_score(Y_train_boruta, y_pred_train, average='weighted'),'Test recall:', recall_score(Y_test_boruta, y_pred,average='weighted'))\n",
    "    print(name, 'Train precision:', precision_score(Y_train_boruta, y_pred_train,average='weighted'), 'Test precision:', precision_score(Y_test_boruta, y_pred,average='weighted'))\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "print('All balanced accuracy results:', results)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier(random_state=seed, num_class=3, objective='multi:softmax', eval_metric='mlogloss', learning_rate=0.49999999999999994,\n",
    "                           max_depth=3, n_estimators=32, reg_alpha=1, reg_lambda=1) \n",
    "\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=seed, criterion='friedman_mse', learning_rate=0.28483530005634594, max_depth=4, max_features='sqrt',\n",
    "                               n_estimators=41)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=seed, criterion='gini', max_depth=4, max_features='auto', n_estimators=25)\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=seed, criterion='entropy', max_depth=4, max_features='sqrt')\n",
    "\n",
    "extra = ExtraTreesClassifier(random_state=seed, criterion='entropy', max_depth=4, max_features='sqrt', n_estimators=50)\n",
    "\n",
    "knn = KNeighborsClassifier(metric='manhattan', n_neighbors=7, weights='distance')\n",
    "\n",
    "svm = SVC(C=1000, gamma='scale', kernel='rbf')\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear',multi_class='auto',random_state=seed, C=0.5, max_iter=1000, penalty='l1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.83      0.57      0.68        42\n",
      "    probable       0.50      0.48      0.49        23\n",
      "    possible       0.52      0.68      0.59        34\n",
      "least likely       0.84      1.00      0.91        21\n",
      "\n",
      "    accuracy                           0.66       120\n",
      "   macro avg       0.67      0.68      0.67       120\n",
      "weighted avg       0.68      0.66      0.66       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['most likely', 'probable', 'possible', 'least likely']\n",
    "xgb.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(xgb.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.79      0.55      0.65        42\n",
      "    probable       0.48      0.52      0.50        23\n",
      "    possible       0.48      0.59      0.53        34\n",
      "least likely       0.88      1.00      0.93        21\n",
      "\n",
      "    accuracy                           0.63       120\n",
      "   macro avg       0.66      0.66      0.65       120\n",
      "weighted avg       0.66      0.63      0.64       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(gb.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.74      0.40      0.52        42\n",
      "    probable       0.36      0.57      0.44        23\n",
      "    possible       0.53      0.59      0.56        34\n",
      "least likely       0.91      1.00      0.95        21\n",
      "\n",
      "    accuracy                           0.59       120\n",
      "   macro avg       0.63      0.64      0.62       120\n",
      "weighted avg       0.64      0.59      0.59       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(rf.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.57      0.19      0.29        42\n",
      "    probable       0.24      0.22      0.23        23\n",
      "    possible       0.45      0.82      0.58        34\n",
      "least likely       0.91      1.00      0.95        21\n",
      "\n",
      "    accuracy                           0.52       120\n",
      "   macro avg       0.54      0.56      0.51       120\n",
      "weighted avg       0.53      0.52      0.48       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(dt.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.71      0.40      0.52        42\n",
      "    probable       0.40      0.78      0.53        23\n",
      "    possible       0.50      0.18      0.26        34\n",
      "least likely       0.54      1.00      0.70        21\n",
      "\n",
      "    accuracy                           0.52       120\n",
      "   macro avg       0.54      0.59      0.50       120\n",
      "weighted avg       0.56      0.52      0.48       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extra.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(extra.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.83      0.60      0.69        42\n",
      "    probable       0.38      0.39      0.38        23\n",
      "    possible       0.58      0.74      0.65        34\n",
      "least likely       0.87      0.95      0.91        21\n",
      "\n",
      "    accuracy                           0.66       120\n",
      "   macro avg       0.66      0.67      0.66       120\n",
      "weighted avg       0.68      0.66      0.66       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(knn.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.61      0.26      0.37        42\n",
      "    probable       0.25      0.65      0.36        23\n",
      "    possible       0.50      0.12      0.19        34\n",
      "least likely       0.48      0.76      0.59        21\n",
      "\n",
      "    accuracy                           0.38       120\n",
      "   macro avg       0.46      0.45      0.38       120\n",
      "weighted avg       0.49      0.38      0.35       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(svm.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " most likely       0.62      0.50      0.55        42\n",
      "    probable       0.32      0.70      0.44        23\n",
      "    possible       1.00      0.06      0.11        34\n",
      "least likely       0.56      0.90      0.69        21\n",
      "\n",
      "    accuracy                           0.48       120\n",
      "   macro avg       0.62      0.54      0.45       120\n",
      "weighted avg       0.66      0.48      0.43       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train_boruta, Y_train_boruta)\n",
    "predictions = list(lr.predict(X_test_boruta))\n",
    "print(classification_report(Y_test_boruta, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
